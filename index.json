[{"content":"2023亚运会电竞门票民购买指南（报名+抽签） 杭州亚运会电子竞技项目门票于8月14日陆续启动销售，门票实名登记。杭州亚运会电子竞技项目以报名抽签，中签支付的形式对公众销售\n杭州亚运会电子竞技项目以报名抽签，中签支付的形式对公众销售，包括梦三国2、DOTA2、王者荣耀亚运版本、FIFAOnline4、和平精英亚运版本、街霸V、英雄联盟7个小项全部可售场次。\n根据竞赛日程安排，上述7个项目将分4批次启动报名，每个批次的报名、抽签、支付时间不同，具体安排如下：\n电子竞技项目报名抽签工作在杭州市国立公证处监督下，通过系统随机抽签、订单中签的方式进行，系统不设任何加权抽签系数。\n报名阶段 报名渠道:杭州亚运会公众售票官方网站PC端或H5页面、智能亚运一站通·票务通（点击进入选择项目进行报名）。 用户报名申请单需如实提交以下内容:姓名、证件类型、证件号。 报名规则:在有效报名时间内，注册用户仅可成功提交同一场次1个报名申请单，且报名时间内可随时取消报名申请单，最多可取消同一场次报名申请单10次。每个申请单最多包含2名观赛人，每一名观赛人每一场次只允许成功报名一次。单场次报名申请单如达到200万个则将提前截止报名，截止后不可再提交报名申请单。 调剂规则:用户可选择是否接受调剂。如未能中签首选票档，在调剂票档有库存时系统将自动调剂至调剂票档进行抽签。 通知结果阶段 抽签结果告知方式 :用户可在“用户中心-我的报名”中查看抽签结果。\n支付阶段 用户在“用户中心-我的报名”确认支付后，已完成支付报名单可在“我的订单”查询门票订单信息。用户在报名单支付有效期内如需放弃门票可随时点击“放弃购买资格，或在支付阶段支付截止时间前未支付也视为放弃门票。\n出票及配送阶段 配座规则:根据订单支付时间先后顺序进行配座出票，含多张门票的订单尽量满足连座。 出票方式:电子竞技项目门票配座完成出票后，选择电子票的用户可在票夹中查看具体门票信息，选择纸质票的用户可在“我的订单”页查看门票信息。 门票购票规则 购票要求:购票人需年满18周岁，18周岁以下应在法定代理人陪同下购票。购票时需填写与门票数量一一对应的实名制信息。 实名制购票及入场:用户需携带门票(纸质票或电子票) 及购票时填写的有效身份证件入场。 不支持转售及转送:电子竞技项目门票为报名抽签项目，电子票与纸质票订单和门票均不支持转售及转送。 门票退票规则 所购门票一旦售出，除杭州亚组委另有规定或","permalink":"https://test.jobcher.com/2023%E4%BA%9A%E8%BF%90%E4%BC%9A%E7%94%B5%E7%AB%9E%E9%97%A8%E7%A5%A8%E6%B0%91%E8%B4%AD%E4%B9%B0%E6%8C%87%E5%8D%97%E6%8A%A5%E5%90%8D-%E6%8A%BD%E7%AD%BE.html","summary":"2023亚运会电竞门票民购买指南（报名+抽签） 杭州亚运会电子竞技项目门票于8月14日陆续启动销售，门票实名登记。杭州亚运会电子竞技项目以报名抽签，中签支付的形式对公众销售\n杭州亚运会电子竞技项目以报名抽签，中签支付的形式对公众销售，包括梦三国2、DOTA2、王者荣耀亚运版本、FIFAOnline4、和平精英亚运版本、街霸V、英雄联盟7个小项全部可售场次。\n根据竞赛日程安排，上述7个项目将分4批次启动报名，每个批次的报名、抽签、支付时间不同，具体安排如下：\n电子竞技项目报名抽签工作在杭州市国立公证处监督下，通过系统随机抽签、订单中签的方式进行，系统不设任何加权抽签系数。\n报名阶段 报名渠道:杭州亚运会公众售票官方网站PC端或H5页面、智能亚运一站通·票务通（点击进入选择项目进行报名）。 用户报名申请单需如实提交以下内容:姓名、证件类型、证件号。 报名规则:在有效报名时间内，注册用户仅可成功提交同一场次1个报名申请单，且报名时间内可随时取消报名申请单，最多可取消同一场次报名申请单10次。每个申请单最多包含2名观赛人，每一名观赛人每一场次只允许成功报名一次。单场次报名申请单如达到200万个则将提前截止报名，截止后不可再提交报名申请单。 调剂规则:用户可选择是否接受调剂。如未能中签首选票档，在调剂票档有库存时系统将自动调剂至调剂票档进行抽签。 通知结果阶段 抽签结果告知方式 :用户可在“用户中心-我的报名”中查看抽签结果。\n支付阶段 用户在“用户中心-我的报名”确认支付后，已完成支付报名单可在“我的订单”查询门票订单信息。用户在报名单支付有效期内如需放弃门票可随时点击“放弃购买资格，或在支付阶段支付截止时间前未支付也视为放弃门票。\n出票及配送阶段 配座规则:根据订单支付时间先后顺序进行配座出票，含多张门票的订单尽量满足连座。 出票方式:电子竞技项目门票配座完成出票后，选择电子票的用户可在票夹中查看具体门票信息，选择纸质票的用户可在“我的订单”页查看门票信息。 门票购票规则 购票要求:购票人需年满18周岁，18周岁以下应在法定代理人陪同下购票。购票时需填写与门票数量一一对应的实名制信息。 实名制购票及入场:用户需携带门票(纸质票或电子票) 及购票时填写的有效身份证件入场。 不支持转售及转送:电子竞技项目门票为报名抽签项目，电子票与纸质票订单和门票均不支持转售及转送。 门票退票规则 所购门票一旦售出，除杭州亚组委另有规定或","title":"2023亚运会电竞门票民购买指南（报名+抽签）"},{"content":"Vue3 + vite + nginx项目部署后404问题 vue3 + vite + nginx\n在服务器上部署后打开首页都没问题，打开其他路径全部 404。\nnginx 报错日志：No such file or directory\n其实查看 build 后的dist文件夹可以发现，只有一个index.html，当你访问别的路径时nignx查找不到所以就报错了\n解决方案 在 nginx.conf 中添加: try_files $uri $uri/ /index.html;\nserver { listen 80; server_name localhost; location / { root /dist; index index.html index.htm; # 在配置文件的此处加上这句话 try_files $uri $uri/ /index.html; } } 总结 其实上述改动就是告诉 nignx 找不到文件的时候就访问 index.html 就可以了。\n究其原因其实就是是 vue3 的 router 使用了history模式，该模式与之前hash模式的具体区别可以自行百度一下，不在此赘述。\n","permalink":"https://test.jobcher.com/vue3--vite--nginx%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E5%90%8E404%E9%97%AE%E9%A2%98.html","summary":"Vue3 + vite + nginx项目部署后404问题 vue3 + vite + nginx\n在服务器上部署后打开首页都没问题，打开其他路径全部 404。\nnginx 报错日志：No such file or directory\n其实查看 build 后的dist文件夹可以发现，只有一个index.html，当你访问别的路径时nignx查找不到所以就报错了\n解决方案 在 nginx.conf 中添加: try_files $uri $uri/ /index.html;\nserver { listen 80; server_name localhost; location / { root /dist; index index.html index.htm; # 在配置文件的此处加上这句话 try_files $uri $uri/ /index.html; } } 总结 其实上述改动就是告诉 nignx 找不到文件的时候就访问 index.html 就可以了。\n究其原因其实就是是 vue3 的 router 使用了history模式，该模式与之前hash模式的具体区别可以自行百度一下，不在此赘述。","title":"Vue3 + vite + nginx项目部署后404问题"},{"content":"大麦抢票辅助软件(福利 TFBOYS十年之约演唱会 2023 全机位 视频) 只限android手机！IOS手机不支持！\nDaMaiHelper是一款大麦抢票辅助软件（只抢待开抢中的），软件原理是抓取页面ui控件id，通过模拟点击实现的大麦辅助抢票，软件需要开启相应的权限，如果页面渲染太慢，就会抓取失败导致点击超时无效，所以可以手动辅助点击，该软件只能起到辅助效果，帮忙快速点击，一定要提前选好场次、价格还有观影人，收藏到想看。\n项目地址\n软件下载\n使用教程 先去演唱会主页预选好场次、价格还有观演人，点击想看 （可选）手机后台杀掉大麦app任务 打开辅助app，给于对应权限 （可选）输入歌手名字，默认五月天 点击开抢按钮即可 如果点击开抢后，页面未开始自动跳转，可手动杀死大麦，再次切到辅助app点击开抢 如果想终止辅助app，点击右上角悬浮窗\u0026amp;lt;点击停止\u0026amp;gt;即可 福利 TFBOYS十年之约演唱会 2023 全机位\n百度网盘下载 链接: https://pan.baidu.com/s/1mry1Mib5TSAuTJWpasoG-g\n提取码: icep\n","permalink":"https://test.jobcher.com/%E5%A4%A7%E9%BA%A6%E6%8A%A2%E7%A5%A8%E8%BE%85%E5%8A%A9%E8%BD%AF%E4%BB%B6%E7%A6%8F%E5%88%A9-tfboys%E5%8D%81%E5%B9%B4%E4%B9%8B%E7%BA%A6%E6%BC%94%E5%94%B1%E4%BC%9A-2023-%E5%85%A8%E6%9C%BA%E4%BD%8D-%E8%A7%86%E9%A2%91.html","summary":"大麦抢票辅助软件(福利 TFBOYS十年之约演唱会 2023 全机位 视频) 只限android手机！IOS手机不支持！\nDaMaiHelper是一款大麦抢票辅助软件（只抢待开抢中的），软件原理是抓取页面ui控件id，通过模拟点击实现的大麦辅助抢票，软件需要开启相应的权限，如果页面渲染太慢，就会抓取失败导致点击超时无效，所以可以手动辅助点击，该软件只能起到辅助效果，帮忙快速点击，一定要提前选好场次、价格还有观影人，收藏到想看。\n项目地址\n软件下载\n使用教程 先去演唱会主页预选好场次、价格还有观演人，点击想看 （可选）手机后台杀掉大麦app任务 打开辅助app，给于对应权限 （可选）输入歌手名字，默认五月天 点击开抢按钮即可 如果点击开抢后，页面未开始自动跳转，可手动杀死大麦，再次切到辅助app点击开抢 如果想终止辅助app，点击右上角悬浮窗\u0026lt;点击停止\u0026gt;即可 福利 TFBOYS十年之约演唱会 2023 全机位\n百度网盘下载 链接: https://pan.baidu.com/s/1mry1Mib5TSAuTJWpasoG-g\n提取码: icep","title":"大麦抢票辅助软件(福利 TFBOYS十年之约演唱会 2023 全机位 视频)"},{"content":"黑群晖最新安装教程 我这里拿蜗牛星际举例讲解，如何安装群晖最新引导文件，如何正常使用黑群晖。\n准备 黑群晖设备一台 电源线 hdmi 或者其他视频线 有线鼠标 有线键盘 显示器 8g 以上U盘 一块1T以上硬盘 开始安装 1. 制作U盘启动器 下载 大白菜U盘制作器 https://www.dabaicai.com/\n1、打开大白菜超级U盘装机工具，点击主界面的【U盘启动】模块，然后选择【默认模式】。\n2、在【请选择】后面选择需要制作启动的设备（插入的USB设备，一般会默认读取该设备）。\n3、模式选择【USB-HDD】，格式选择【NTFS】，然后点击【一键制作USB启动盘】。\n4、在点击一键制作后会弹出一个关于【U盘数据删除且不可恢复】的窗口，选择【是】。\n2. 引导文件复制 开始前先拔掉前面4个盘位的硬盘，以防写错盘导致数据丢失。\n1、载写盘软件和群晖引导文件，然后二个文件复制到U盘上\n引导文件下载链接: https://pan.baidu.com/s/1F-Mva0AuEehUNk4q19QyxA\n提取码: amf3\n复制到U盘!\n3. U盘启动黑群晖，写入文件 开始前先拔掉前面4个盘位的硬盘，以防写错盘导致数据丢失。\n1、大白菜U盘启动,插上U盘开机自检页面 按F11或F7（根据机型不同快捷按键不同），选U盘启动\n2、桌面找到 分区工具DiskGenius\n3、点选 第一个硬盘 即便是内置的16G硬盘，右键选删除所有分区\n4、保存更改\n5、删除分区完毕后 打开此电脑 找 默认的第一个分区里面的写盘工具\n6、选择写盘工具软件 打开\n7、全部保存默认参数，只需要找到群晖引导文件 打开\n8、找到U盘上的群晖引导文件IMG，然后点 右下角的Start 按钮开始写入\n写入完毕的 提示，此时就写入完成了，拔掉U盘重启系统即可。\n4. 重启设备后安装DSM系统 这里为了保证系统稳定性，使用DSM6.2.3系统，我们这边使用DS918+4盘符\n1、下载群晖助手软件和系统文件\nSynology Assistant:","permalink":"https://test.jobcher.com/%E9%BB%91%E7%BE%A4%E6%99%96%E6%9C%80%E6%96%B0%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.html","summary":"黑群晖最新安装教程 我这里拿蜗牛星际举例讲解，如何安装群晖最新引导文件，如何正常使用黑群晖。\n准备 黑群晖设备一台 电源线 hdmi 或者其他视频线 有线鼠标 有线键盘 显示器 8g 以上U盘 一块1T以上硬盘 开始安装 1. 制作U盘启动器 下载 大白菜U盘制作器 https://www.dabaicai.com/\n1、打开大白菜超级U盘装机工具，点击主界面的【U盘启动】模块，然后选择【默认模式】。\n2、在【请选择】后面选择需要制作启动的设备（插入的USB设备，一般会默认读取该设备）。\n3、模式选择【USB-HDD】，格式选择【NTFS】，然后点击【一键制作USB启动盘】。\n4、在点击一键制作后会弹出一个关于【U盘数据删除且不可恢复】的窗口，选择【是】。\n2. 引导文件复制 开始前先拔掉前面4个盘位的硬盘，以防写错盘导致数据丢失。\n1、载写盘软件和群晖引导文件，然后二个文件复制到U盘上\n引导文件下载链接: https://pan.baidu.com/s/1F-Mva0AuEehUNk4q19QyxA\n提取码: amf3\n复制到U盘!\n3. U盘启动黑群晖，写入文件 开始前先拔掉前面4个盘位的硬盘，以防写错盘导致数据丢失。\n1、大白菜U盘启动,插上U盘开机自检页面 按F11或F7（根据机型不同快捷按键不同），选U盘启动\n2、桌面找到 分区工具DiskGenius\n3、点选 第一个硬盘 即便是内置的16G硬盘，右键选删除所有分区\n4、保存更改\n5、删除分区完毕后 打开此电脑 找 默认的第一个分区里面的写盘工具\n6、选择写盘工具软件 打开\n7、全部保存默认参数，只需要找到群晖引导文件 打开\n8、找到U盘上的群晖引导文件IMG，然后点 右下角的Start 按钮开始写入\n写入完毕的 提示，此时就写入完成了，拔掉U盘重启系统即可。\n4. 重启设备后安装DSM系统 这里为了保证系统稳定性，使用DSM6.2.3系统，我们这边使用DS918+4盘符\n1、下载群晖助手软件和系统文件\nSynology Assistant:","title":"黑群晖最新安装教程"},{"content":"背景 CocoaPods 是OS X和IOS 下的第三类库管理工具，通过CocoaPods工具我们可以为项目添加被称为Pods的依赖库\n检查环境 ruby -v gem -v 出现异常问题 /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/universal-darwin22/rbconfig.rb:21: warning: Insecure world writable dir /opt/homebrew/bin in PATH, mode 040777\n该警告信息表明在你的PATH环境变量中包含了一个“不安全可写”（Insecure world writable）的目录/opt/homebrew/bin。这可能会导致潜在的安全问题。\n为了解决这个警告，你需要修复/opt/homebrew/bin目录的权限，以使其不再被标记为“不安全可写”。\n解决问题 chmod 755 /opt/homebrew/bin chmod 755 /opt/homebrew chmod 755 /opt/homebrew/sbin 安装cocoapods 输入安装命令\nsudo gem install cocoapods 出现异常问题 ERROR: While executing gem \u0026amp;hellip; (Gem::FilePermissionError) You don\u0026amp;rsquo;t have write permissions for the /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0 directory. /Library/Ruby/Site/2.6.0/rubygems/installer.rb:714:in verify_gem_home\u0026#39; /Library/Ruby/Site/2.6.0/rubygems/installer.rb:904:in pre_install_checks\u0026#39; ……\n在 macOS 系统中，系统的Ruby目录通常是受保护的，并且普通用户没有对这些目录进行写操作的权限。为了解决这个问题，你应该避免在系统级别的Ruby目录中进行Gem的安装。相反，你应该使用用户级别的Gem安装目录。\n解","permalink":"https://test.jobcher.com/cocoapods-%E5%AE%89%E8%A3%85%E5%8F%8A%E7%A2%B0%E5%88%B0%E9%97%AE%E9%A2%98.html","summary":"背景 CocoaPods 是OS X和IOS 下的第三类库管理工具，通过CocoaPods工具我们可以为项目添加被称为Pods的依赖库\n检查环境 ruby -v gem -v 出现异常问题 /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/universal-darwin22/rbconfig.rb:21: warning: Insecure world writable dir /opt/homebrew/bin in PATH, mode 040777\n该警告信息表明在你的PATH环境变量中包含了一个“不安全可写”（Insecure world writable）的目录/opt/homebrew/bin。这可能会导致潜在的安全问题。\n为了解决这个警告，你需要修复/opt/homebrew/bin目录的权限，以使其不再被标记为“不安全可写”。\n解决问题 chmod 755 /opt/homebrew/bin chmod 755 /opt/homebrew chmod 755 /opt/homebrew/sbin 安装cocoapods 输入安装命令\nsudo gem install cocoapods 出现异常问题 ERROR: While executing gem \u0026hellip; (Gem::FilePermissionError) You don\u0026rsquo;t have write permissions for the /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0 directory. /Library/Ruby/Site/2.6.0/rubygems/installer.rb:714:in verify_gem_home' /Library/Ruby/Site/2.6.0/rubygems/installer.rb:904:in pre_install_checks' ……\n在 macOS 系统中，系统的Ruby目录通常是受保护的，并且普通用户没有对这些目录进行写操作的权限。为了解决这个问题，你应该避免在系统级别的Ruby目录中进行Gem的安装。相反，你应该使用用户级别的Gem安装目录。\n解","title":"CocoaPods 安装及碰到问题"},{"content":"基础配置 三台环境为centos7.9，以下配置需要在每台机器上执行\n配置hosts解析 cat \u0026amp;gt;\u0026amp;gt; /etc/hosts \u0026amp;lt;\u0026amp;lt;EOF 192.168.2.23 node1 192.168.2.24 node2 192.168.2.25 node3 EOF 关闭防火墙和selinux systemctl stop firewalld \u0026amp;amp;\u0026amp;amp; systemctl disable firewalld setenforce 0 \u0026amp;amp;\u0026amp;amp; sed -i \u0026amp;#39;s/SELINUX=enforcing/SELINUX=disabled/g\u0026amp;#39; /etc/selinux/config 分别在三个节点设置主机名 hostnamectl set-hostname node1 hostnamectl set-hostname node2 hostnamectl set-hostname node3 配置主机时间同步 systemctl restart chronyd.service \u0026amp;amp;\u0026amp;amp; systemctl enable chronyd.service 配置免密登录 ssh-keygen ssh-copy-id -i .ssh/id_rsa.pub node1 ssh-copy-id -i .ssh/id_rsa.pub node2 ssh-copy-id -i .ssh/id_rsa.pub node3 安装pip和ansible、git yum install python-pip ansible git -y 部署ceph集群 克隆存储库 这里我选择安装的是ceph nautilus版本\ngit clone https://github.com/ceph/ceph-ansible.git cd ceph-ansible git checkout stable-4.0 安装ansible依赖包 pip install --upgrade pip pip install -r requirements.txt 修改hosts文件，添加安装的节点 cat \u0026amp;gt;\u0026amp;gt; /etc/ansible/hosts \u0026amp;lt;\u0026amp;lt;EOF [mons] node1 node2 node3 [osds] node1 node2 node3 [mgrs] node1","permalink":"https://test.jobcher.com/ansible%E9%83%A8%E7%BD%B2ceph%E9%9B%86%E7%BE%A4.html","summary":"基础配置 三台环境为centos7.9，以下配置需要在每台机器上执行\n配置hosts解析 cat \u0026gt;\u0026gt; /etc/hosts \u0026lt;\u0026lt;EOF 192.168.2.23 node1 192.168.2.24 node2 192.168.2.25 node3 EOF 关闭防火墙和selinux systemctl stop firewalld \u0026amp;\u0026amp; systemctl disable firewalld setenforce 0 \u0026amp;\u0026amp; sed -i \u0026#39;s/SELINUX=enforcing/SELINUX=disabled/g\u0026#39; /etc/selinux/config 分别在三个节点设置主机名 hostnamectl set-hostname node1 hostnamectl set-hostname node2 hostnamectl set-hostname node3 配置主机时间同步 systemctl restart chronyd.service \u0026amp;\u0026amp; systemctl enable chronyd.service 配置免密登录 ssh-keygen ssh-copy-id -i .ssh/id_rsa.pub node1 ssh-copy-id -i .ssh/id_rsa.pub node2 ssh-copy-id -i .ssh/id_rsa.pub node3 安装pip和ansible、git yum install python-pip ansible git -y 部署ceph集群 克隆存储库 这里我选择安装的是ceph nautilus版本","title":"Ansible部署ceph集群"},{"content":"最好的微信朋友圈集赞神器-集赞2.0 奶茶店活动，朋友圈集满50个赞，送一杯奶茶。 饭店新开张，朋友圈集满98个赞，全场7折优惠。 旅游景点拉人气，朋友圈集满60个赞，送门票。\n还在为这些恼人的朋友圈集赞发愁吗？ 还在为拿着其他地方生成的集赞图片，怕被发现而胆战心惊吗？ 翻遍通讯录，求着好友帮忙点赞。还是不够数？\n现在“集赞”发布，1比1还原微信，轻松设置点赞数，再也不用担心点赞数量，大大方方展示，不惧查验，轻松薅羊毛。 应付生活中各种需要转发点赞场景，体验效果绝非是那种仅仅生成一张点赞图片能比的。\n如果你有这样的烦恼，我推荐你试试这款免费的微信朋友圈集赞神器，简单体验了一下，发现这款工具高度还原了一个整个微信界面ui，现在“集赞2.0 ”发布，逻辑重构，去除一天只能发布一条朋友圈的限制，删除“三连”功能，现在可以无限制的发布，1比1还原微信，轻松设置点赞数，再也不用担心点赞数量。\n集赞神器使用帮助页面：https://blog.itakeo.com/help\n","permalink":"https://test.jobcher.com/%E6%9C%80%E5%A5%BD%E7%9A%84%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B%E5%9C%88%E9%9B%86%E8%B5%9E%E7%A5%9E%E5%99%A8-%E7%A6%8F%E5%88%A9%E6%8E%A8%E8%8D%90.html","summary":"最好的微信朋友圈集赞神器-集赞2.0 奶茶店活动，朋友圈集满50个赞，送一杯奶茶。 饭店新开张，朋友圈集满98个赞，全场7折优惠。 旅游景点拉人气，朋友圈集满60个赞，送门票。\n还在为这些恼人的朋友圈集赞发愁吗？ 还在为拿着其他地方生成的集赞图片，怕被发现而胆战心惊吗？ 翻遍通讯录，求着好友帮忙点赞。还是不够数？\n现在“集赞”发布，1比1还原微信，轻松设置点赞数，再也不用担心点赞数量，大大方方展示，不惧查验，轻松薅羊毛。 应付生活中各种需要转发点赞场景，体验效果绝非是那种仅仅生成一张点赞图片能比的。\n如果你有这样的烦恼，我推荐你试试这款免费的微信朋友圈集赞神器，简单体验了一下，发现这款工具高度还原了一个整个微信界面ui，现在“集赞2.0 ”发布，逻辑重构，去除一天只能发布一条朋友圈的限制，删除“三连”功能，现在可以无限制的发布，1比1还原微信，轻松设置点赞数，再也不用担心点赞数量。\n集赞神器使用帮助页面：https://blog.itakeo.com/help","title":"最好的微信朋友圈集赞神器-福利推荐"},{"content":"紧接上文，我们继续探索midjourney prompt，这次我们来看看midjourney prompt的基础用法。\nmidjourney 参数使用 参数是添加到提示中的选项，用于更改图像的生成方式。参数可以更改图像的长宽比、在中途模型版本之间切换、更改使用的 Upscaler 等等。参数始终添加到提示的末尾。您可以向每个提示添加多个参数\n许多 Apple 设备会自动将双连字符 (\u0026amp;ndash;) 更改为长破折号 (—)。midjourney接受两者！\n基础参数列表 参数 描述 \u0026amp;ndash;aspect, \u0026amp;ndash;ar 更改生成图像的长宽比。 \u0026amp;ndash;chaos \u0026amp;lt;nummber 8-100\u0026amp;gt; 更改生成图像的混乱程度。 \u0026amp;ndash;fast 使用快速模式运行单个作业 \u0026amp;ndash;iw \u0026amp;lt;0-2\u0026amp;gt; 设置相对于文本粗细的图像提示粗细。默认值为 1。 \u0026amp;ndash;no 负面提示, --no plant 将生成没有植物的图像。 \u0026amp;ndash;quality \u0026amp;lt;.25, .5 ,1\u0026amp;gt;, \u0026amp;ndash;q \u0026amp;lt;.25, .5, 1\u0026amp;gt; 您想要花费多少渲染质量时间。默认值为 1。值越高，使用的 GPU 分钟数越多；较低的值使用较少 \u0026amp;ndash;repeat \u0026amp;lt;1-40\u0026amp;gt;, \u0026amp;ndash;r \u0026amp;lt;1-40\u0026amp;gt; 从单个提示创建多个作业。 --repeat 对于快速重新运行作业多次很有用。 \u0026amp;ndash;seed \u0026amp;lt;integer between 0–4294967295\u0026amp;gt; Midjourney 机器人使用种子号来创建视觉噪声场（如电视静态），作为生成初始图像网格的起点。种子数是为每个图像随机生成的，但可以使用 --seed 或 --sameseed 参数指定。使用相同的种子编号和提示将产生相似的结局图像。 \u0026amp;ndash;stop \u0026amp;lt;integer between 10–100\u0026amp;gt; 使用 \u0026amp;ndash;stop 参数在流程中途完成作业。以较早的百分比停止作业可能会产生更模糊、不太详细的结果。 \u0026amp;ndash;tile 参数生成可用作重复图块以创建无缝图案的图像。 \u0026amp;ndash;Turbo 使用 Turbo 模式运行单个作业。 \u0026amp;ndash;Weird \u0026amp;lt;number 0-3000\u0026amp;gt;","permalink":"https://test.jobcher.com/%E6%8E%A2%E7%B4%A2midjourney%E4%BA%8Cmidjourney-prompt%E5%88%9D%E4%BD%93%E9%AA%8C.html","summary":"紧接上文，我们继续探索midjourney prompt，这次我们来看看midjourney prompt的基础用法。\nmidjourney 参数使用 参数是添加到提示中的选项，用于更改图像的生成方式。参数可以更改图像的长宽比、在中途模型版本之间切换、更改使用的 Upscaler 等等。参数始终添加到提示的末尾。您可以向每个提示添加多个参数\n许多 Apple 设备会自动将双连字符 (\u0026ndash;) 更改为长破折号 (—)。midjourney接受两者！\n基础参数列表 参数 描述 \u0026ndash;aspect, \u0026ndash;ar 更改生成图像的长宽比。 \u0026ndash;chaos \u0026lt;nummber 8-100\u0026gt; 更改生成图像的混乱程度。 \u0026ndash;fast 使用快速模式运行单个作业 \u0026ndash;iw \u0026lt;0-2\u0026gt; 设置相对于文本粗细的图像提示粗细。默认值为 1。 \u0026ndash;no 负面提示, --no plant 将生成没有植物的图像。 \u0026ndash;quality \u0026lt;.25, .5 ,1\u0026gt;, \u0026ndash;q \u0026lt;.25, .5, 1\u0026gt; 您想要花费多少渲染质量时间。默认值为 1。值越高，使用的 GPU 分钟数越多；较低的值使用较少 \u0026ndash;repeat \u0026lt;1-40\u0026gt;, \u0026ndash;r \u0026lt;1-40\u0026gt; 从单个提示创建多个作业。 --repeat 对于快速重新运行作业多次很有用。 \u0026ndash;seed \u0026lt;integer between 0–4294967295\u0026gt; Midjourney 机器人使用种子号来创建视觉噪声场（如电视静态），作为生成初始图像网格的起点。种子数是为每个图像随机生成的，但可以使用 --seed 或 --sameseed 参数指定。使用相同的种子编号和提示将产生相似的结局图像。 \u0026ndash;stop \u0026lt;integer between 10–100\u0026gt; 使用 \u0026ndash;stop 参数在流程中途完成作业。以较早的百分比停止作业可能会产生更模糊、不太详细的结果。 \u0026ndash;tile 参数生成可用作重复图块以创建无缝图案的图像。 \u0026ndash;Turbo 使用 Turbo 模式运行单个作业。 \u0026ndash;Weird \u0026lt;number 0-3000\u0026gt;","title":"探索midjourney(二)：midjourney prompt初体验"},{"content":"人工智能（AI）的快速发展为我们带来了许多令人兴奋的技术创新。其中一项令人瞩目的成果是人工智能生成图像软件，它通过机器学习和深度学习算法，能够创造出惊人逼真的图像。在本文中，我将分享我的旅程，探索这项令人着迷的技术，并展示它的潜力与魅力。这个系列我会长期更新下去\nmidjourney是什么？ midjourney是一个人工智能生成图像软件，它可以生成惊人逼真的图像。它的工作原理是：它通过机器学习和深度学习算法，学习了大量的图像数据，然后通过这些数据，生成惊人逼真的图像。\nmidjourney的使用 midjourney的使用非常简单，你只需要在这里注册并订阅输入你想要生成的图像的描述，然后点击生成按钮，midjourney就会生成一个惊人逼真的图像。\n需要付费订阅，偶尔有放开免费体验的时候，可以去试试\nmidjourney的demo 下面是我使用midjourney生成的一些惊人逼真的图像。我会为大家推荐一下我最喜欢的几张图像。\n1. 数字墙纸，抽象艺术，曲线流畅，紫色，粉色和蓝色，32k超高清，微妙的渐变，充满活力的，夸张的场景，Dariusz Klimczak，新地形，红移，深弯曲，超细节 digital wallpaper, abstract art, in the style of smooth curves, purple and pink and blue, 32k uhd, subtle gradients, vibrant, exaggerated scenes, dariusz klimczak, new topographics, redshift, deep curving, hyper-detailed 2. 白色背景线条灰色卡通贴纸，一名宇航员坐在漂浮在太空中的沙发上看电视。背景中有星星和月亮。 white background linework greyscale cartoon sticker of an astronaut watching Television while sitting on a couch that is floating in space. Stars and moon in the background. 3. 以毕加索为灵感的油画和山水照片的双重曝光 Double exposure of a painting inspired by Picasso","permalink":"https://test.jobcher.com/%E6%8E%A2%E7%B4%A2midjourney%E4%B8%80%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E8%BD%AF%E4%BB%B6%E7%9A%84%E6%83%8A%E4%BA%BA%E4%B9%8B%E6%97%85.html","summary":"人工智能（AI）的快速发展为我们带来了许多令人兴奋的技术创新。其中一项令人瞩目的成果是人工智能生成图像软件，它通过机器学习和深度学习算法，能够创造出惊人逼真的图像。在本文中，我将分享我的旅程，探索这项令人着迷的技术，并展示它的潜力与魅力。这个系列我会长期更新下去\nmidjourney是什么？ midjourney是一个人工智能生成图像软件，它可以生成惊人逼真的图像。它的工作原理是：它通过机器学习和深度学习算法，学习了大量的图像数据，然后通过这些数据，生成惊人逼真的图像。\nmidjourney的使用 midjourney的使用非常简单，你只需要在这里注册并订阅输入你想要生成的图像的描述，然后点击生成按钮，midjourney就会生成一个惊人逼真的图像。\n需要付费订阅，偶尔有放开免费体验的时候，可以去试试\nmidjourney的demo 下面是我使用midjourney生成的一些惊人逼真的图像。我会为大家推荐一下我最喜欢的几张图像。\n1. 数字墙纸，抽象艺术，曲线流畅，紫色，粉色和蓝色，32k超高清，微妙的渐变，充满活力的，夸张的场景，Dariusz Klimczak，新地形，红移，深弯曲，超细节 digital wallpaper, abstract art, in the style of smooth curves, purple and pink and blue, 32k uhd, subtle gradients, vibrant, exaggerated scenes, dariusz klimczak, new topographics, redshift, deep curving, hyper-detailed 2. 白色背景线条灰色卡通贴纸，一名宇航员坐在漂浮在太空中的沙发上看电视。背景中有星星和月亮。 white background linework greyscale cartoon sticker of an astronaut watching Television while sitting on a couch that is floating in space. Stars and moon in the background. 3.","title":"探索midjourney(一)：人工智能生成图像软件的惊人之旅"},{"content":"背景 很多同学在开发软件和测试软件的早期，都会遇到一个问题：如何快速的搭建一个测试环境。这个问题在开发软件的早期是非常棘手的，因为开发软件的早期，往往是没有任何的资源的。这个时候，我们就需要借助一些云资源来帮助我们快速的搭建一个测试环境。接下我会推荐一些云资源，希望能够帮助到大家。\n推荐 1.vercel vercel是一个提供托管服务的网站，它可以帮助我们快速的部署一个静态网站。它的优点是：免费、快速、简单。它的缺点是：只能部署静态网站。如果你的项目是一个静态网站，那么我强烈推荐你使用vercel。\n2。zeabur zeabur是一个帮助开发者一键部署自己的服务的平台，免费方案限制1个项目数量，1vCPU,内存512M，存储1GB 适合做文档和个人博客\n3.腾讯云 国内的良心云，但是现在也不太良心了，不太推荐了，毕竟没什么福利了，如果你是学生的话可以考虑买他们的轻量云来部署他们的服务\n总结 我随便推荐一下，建议大家可以先试用一下1和2的方案，希望能够帮助到大家，如果你有更好的推荐，欢迎在评论区留言。\n","permalink":"https://test.jobcher.com/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%8B-%E5%AE%B9%E5%99%A8%E4%BA%91%E8%B5%84%E6%BA%90.html","summary":"背景 很多同学在开发软件和测试软件的早期，都会遇到一个问题：如何快速的搭建一个测试环境。这个问题在开发软件的早期是非常棘手的，因为开发软件的早期，往往是没有任何的资源的。这个时候，我们就需要借助一些云资源来帮助我们快速的搭建一个测试环境。接下我会推荐一些云资源，希望能够帮助到大家。\n推荐 1.vercel vercel是一个提供托管服务的网站，它可以帮助我们快速的部署一个静态网站。它的优点是：免费、快速、简单。它的缺点是：只能部署静态网站。如果你的项目是一个静态网站，那么我强烈推荐你使用vercel。\n2。zeabur zeabur是一个帮助开发者一键部署自己的服务的平台，免费方案限制1个项目数量，1vCPU,内存512M，存储1GB 适合做文档和个人博客\n3.腾讯云 国内的良心云，但是现在也不太良心了，不太推荐了，毕竟没什么福利了，如果你是学生的话可以考虑买他们的轻量云来部署他们的服务\n总结 我随便推荐一下，建议大家可以先试用一下1和2的方案，希望能够帮助到大家，如果你有更好的推荐，欢迎在评论区留言。","title":"推荐一下 容器云资源"},{"content":"背景 在人工智能领域，GPU 是必不可少的。在本文中，我们将介绍如何在服务器上安装和部署 NVIDIA GPU 的 docker\n安装 确保你的系统已经安装了NVIDIA驱动和Docker引擎。确保驱动版本与Docker引擎兼容。你还需要安装nvidia-docker2软件包，它是NVIDIA Docker的一个插件。可以在https://github.com/NVIDIA/nvidia-docker上找到安装说明\n1.1 卸载旧版本的nvidia-docker(如果已安装) sudo apt-get remove nvidia-docker 1.2 添加nvidia-docker2仓库\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list 1.3 更新软件包列表和安装nvidia-docker2\nsudo apt-get update sudo apt-get install nvidia-docker2 1.4 重启Docker守护进程\nsudo systemctl restart docker 通过以下命令测试是否安装成功 docker run --gpus all nvidia/cuda:10.0-base nvidia-smi 如果安装成功，你将看到类似下面的输出 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 440.33.01 Driver Version: 440.33.01 CUDA Version: 10.2 | |-------------------------------+----------------------+----------------------+ | GPU","permalink":"https://test.jobcher.com/nvidia-gpu-%E7%9A%84-docker-%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2.html","summary":"背景 在人工智能领域，GPU 是必不可少的。在本文中，我们将介绍如何在服务器上安装和部署 NVIDIA GPU 的 docker\n安装 确保你的系统已经安装了NVIDIA驱动和Docker引擎。确保驱动版本与Docker引擎兼容。你还需要安装nvidia-docker2软件包，它是NVIDIA Docker的一个插件。可以在https://github.com/NVIDIA/nvidia-docker上找到安装说明\n1.1 卸载旧版本的nvidia-docker(如果已安装) sudo apt-get remove nvidia-docker 1.2 添加nvidia-docker2仓库\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list 1.3 更新软件包列表和安装nvidia-docker2\nsudo apt-get update sudo apt-get install nvidia-docker2 1.4 重启Docker守护进程\nsudo systemctl restart docker 通过以下命令测试是否安装成功 docker run --gpus all nvidia/cuda:10.0-base nvidia-smi 如果安装成功，你将看到类似下面的输出 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 440.33.01 Driver Version: 440.33.01 CUDA Version: 10.","title":"NVIDIA GPU 的 docker 安装和部署"},{"content":"背景 skywalking 是一个APM监控，在java和微服务领域非常流行。但是在python领域，skywalking的使用率并不高。本文将介绍如何安装和配置skywalking python agent。\nSkyWalking Python 代理实现了一个命令行界面，可用于在部署期间将代理附加到出色的应用程序，而无需更改任何应用程序代码，就像 SkyWalking Java 代理一样。\n安装skywalking python agent pip install apache-skywalking 运行 sw-python 以查看它是否可用，您需要按环境变量传递配置。\n配置skywalking python agent export SW_AGENT_NAME=服务名称 # 服务器地址 export SW_AGENT_COLLECTOR_BACKEND_SERVICES=127.0.0.1:11800 执行python程序 sw-python run -p python app.py 启用 CLI 调试模式，以便在启动应用程序时查看代理日志： sw-python -d run python app.py ","permalink":"https://test.jobcher.com/skywalking-python-agent-%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE.html","summary":"背景 skywalking 是一个APM监控，在java和微服务领域非常流行。但是在python领域，skywalking的使用率并不高。本文将介绍如何安装和配置skywalking python agent。\nSkyWalking Python 代理实现了一个命令行界面，可用于在部署期间将代理附加到出色的应用程序，而无需更改任何应用程序代码，就像 SkyWalking Java 代理一样。\n安装skywalking python agent pip install apache-skywalking 运行 sw-python 以查看它是否可用，您需要按环境变量传递配置。\n配置skywalking python agent export SW_AGENT_NAME=服务名称 # 服务器地址 export SW_AGENT_COLLECTOR_BACKEND_SERVICES=127.0.0.1:11800 执行python程序 sw-python run -p python app.py 启用 CLI 调试模式，以便在启动应用程序时查看代理日志： sw-python -d run python app.py ","title":"skywalking python agent 安装和配置"},{"content":"实现功能 Priming GPT4 for Midjourney V5 将每一步直接输入给chatgpt即可，记住要一步步输入\n第一步： Hello ，Today we are gonna create Images with a Diffusion model. I am gonna feed you some information about it. okey?\n第二步： This is how Midjourney work: Midjourney is another AI-powered tool that generates images from user prompts. MidJourney is proficient at adapting actual art styles to create an image of any combination of things the user wants. It excels at creating environments, especially fantasy and sci-fi scenes, with dramatic lighting that looks like rendered concept art from a video game. How does Midjourney work? Midjourney is an AI image generation tool that takes inputs through text prompts and parameters and uses a Machine Learning (ML) algorithm trained on a large amount of image data to produce unique images. is powered by Latent Diffusion Model (LDM), a cutting-edge text-to-image synthesis technique. Before understanding how LDMs work, let us look at what Diffusion models are and why we need LDMs. Diffusion models (DM) are","permalink":"https://test.jobcher.com/%E8%B0%83%E6%95%99chat-gpt%E7%94%9F%E6%88%90midjourney%E6%8F%90%E7%A4%BA%E8%AF%8D.html","summary":"实现功能 Priming GPT4 for Midjourney V5 将每一步直接输入给chatgpt即可，记住要一步步输入\n第一步： Hello ，Today we are gonna create Images with a Diffusion model. I am gonna feed you some information about it. okey?\n第二步： This is how Midjourney work: Midjourney is another AI-powered tool that generates images from user prompts. MidJourney is proficient at adapting actual art styles to create an image of any combination of things the user wants. It excels at creating environments, especially fantasy and sci-fi scenes, with dramatic lighting that looks like rendered concept art from a video game.","title":"调教Chat GPT生成Midjourney提示词"},{"content":"背景 最近在做一个项目，项目的需求是这样的： spring-cloud有一个服务A，服务A有一个接口，接口的功能是根据传入的参数，返回一个字符串。但是服务响应非常的慢，大概需要4秒左右。这个响应速度是不能忍受的！但是这个服务的开发强行说要上线。我们有几个选项：\n1.不上线，但是这个服务的开发无法按期交付 2.上线，但是这个服务的响应速度太慢了，运维背锅 3.劝说服务的开发，让他们优化接口的响应速度\n相信大家都会选择第3个选择，那我们站在运维的角度如何劝说服务的开发呢？ 劝说 故障级联（Cascading Failures）：连接超时的服务可能会导致其他服务出现故障级联效应。这是因为微服务系统中的服务通常会相互调用和依赖。当一个服务连接超时时，其他依赖该服务的服务可能无法及时获取所需的数据或执行必要的操作，从而导致它们自身出现故障。\n响应时间延迟（Increased Response Time）：如果一个服务连接超时，它的调用方可能需要等待更长的时间来获取响应或超时处理。这会增加整个系统的响应时间，因为其他服务的请求也需要等待超时的服务返回结果。这可能会导致用户体验下降，甚至可能导致其他服务的性能问题。\n资源耗尽（Resource Exhaustion）：连接超时可能会导致调用方服务的资源耗尽。当一个服务长时间等待连接超时的服务时，它可能会保持与该服务的连接打开，消耗额外的内存和网络资源。这可能导致调用方服务的资源不足，无法为其他请求提供充足的资源，进而影响整个系统的性能。\n重试和失败处理（Retry and Failure Handling）：当一个服务连接超时时，调用方服务通常会尝试重新连接或执行其他失败处理机制。这可能导致调用方服务增加额外的负载，因为它需要多次尝试连接超时的服务。同时，如果没有适当的失败处理机制，连接超时的服务可能无法正确处理重试请求，导致进一步的问题。\n结论 综上所述，连接超时的服务对Spring Cloud微服务系统可能会带来级联故障、响应时间延迟、资源耗尽、重试和失败处理的问题，并增加监控和故障排除的成本。因此，及时发现和解决连接超时问题对于确保系统的稳定性和性能至关重要。希望领导能够听取意见，不要让运维背锅。\n","permalink":"https://test.jobcher.com/%E5%A6%82%E4%BD%95%E7%A4%BC%E8%B2%8C%E5%9B%9E%E7%BB%9D%E4%B8%8D%E5%90%88%E7%90%86%E7%9A%84%E9%9C%80%E6%B1%82.html","summary":"背景 最近在做一个项目，项目的需求是这样的： spring-cloud有一个服务A，服务A有一个接口，接口的功能是根据传入的参数，返回一个字符串。但是服务响应非常的慢，大概需要4秒左右。这个响应速度是不能忍受的！但是这个服务的开发强行说要上线。我们有几个选项：\n1.不上线，但是这个服务的开发无法按期交付 2.上线，但是这个服务的响应速度太慢了，运维背锅 3.劝说服务的开发，让他们优化接口的响应速度\n相信大家都会选择第3个选择，那我们站在运维的角度如何劝说服务的开发呢？ 劝说 故障级联（Cascading Failures）：连接超时的服务可能会导致其他服务出现故障级联效应。这是因为微服务系统中的服务通常会相互调用和依赖。当一个服务连接超时时，其他依赖该服务的服务可能无法及时获取所需的数据或执行必要的操作，从而导致它们自身出现故障。\n响应时间延迟（Increased Response Time）：如果一个服务连接超时，它的调用方可能需要等待更长的时间来获取响应或超时处理。这会增加整个系统的响应时间，因为其他服务的请求也需要等待超时的服务返回结果。这可能会导致用户体验下降，甚至可能导致其他服务的性能问题。\n资源耗尽（Resource Exhaustion）：连接超时可能会导致调用方服务的资源耗尽。当一个服务长时间等待连接超时的服务时，它可能会保持与该服务的连接打开，消耗额外的内存和网络资源。这可能导致调用方服务的资源不足，无法为其他请求提供充足的资源，进而影响整个系统的性能。\n重试和失败处理（Retry and Failure Handling）：当一个服务连接超时时，调用方服务通常会尝试重新连接或执行其他失败处理机制。这可能导致调用方服务增加额外的负载，因为它需要多次尝试连接超时的服务。同时，如果没有适当的失败处理机制，连接超时的服务可能无法正确处理重试请求，导致进一步的问题。\n结论 综上所述，连接超时的服务对Spring Cloud微服务系统可能会带来级联故障、响应时间延迟、资源耗尽、重试和失败处理的问题，并增加监控和故障排除的成本。因此，及时发现和解决连接超时问题对于确保系统的稳定性和性能至关重要。希望领导能够听取意见，不要让运维背锅。","title":"如何礼貌回绝不合理的需求"},{"content":"在windows上安装appium Appium 主要用于软件测试自动化领域，以帮助确定给定应用程序的功能是否按预期工作。与其他类型的软件测试相比，UI 自动化允许测试人员编写代码，在应用程序的实际 UI 中演练用户方案，尽可能模拟现实世界中发生的情况，同时实现自动化的各种好处，包括速度、规模和一致性。\n安装nodejs Appium是基于Node.js构建的,所以首先需要安装Node.js\n下载地址：https://nodejs.org/en/download/\n下载并安装，验证是否安装成功\nnode -v 安装appium 安装Appium。在命令提示符下运行:\nnpm install -g appium 安装appium-doctor 安装appium-doctor。在命令提示符下运行:\nnpm install -g appium-doctor 安装appium-desktop 安装appium-desktop。在命令提示符下运行:\nnpm install -g appium-desktop 安装jdk 下载地址：https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html 下载并安装，验证是否安装成功\njava -version 安装android-sdk 下载地址：https://developer.android.com/studio 下载并安装，验证是否安装成功\nadb version 配置环境变量 在系统环境变量中添加以下变量\nANDROID_HOME = D:\\Android\\sdk JAVA_HOME = C:\\Program Files\\Java\\jdk1.8.0_311 Path = %ANDROID_HOME%\\platform-tools;%ANDROID_HOME%\\tools;%JAVA_HOME%\\bin 验证是否配置成功\nappium-doctor 启动appium appium 启动appium-desktop appium-desktop 测试脚本 创建测试脚本test.py\nfrom appium import webdriver import time desired_caps = {} desired_caps[\u0026amp;#39;platformName\u0026amp;#39;] =","permalink":"https://test.jobcher.com/%E5%9C%A8windows%E4%B8%8A%E5%AE%89%E8%A3%85appium.html","summary":"在windows上安装appium Appium 主要用于软件测试自动化领域，以帮助确定给定应用程序的功能是否按预期工作。与其他类型的软件测试相比，UI 自动化允许测试人员编写代码，在应用程序的实际 UI 中演练用户方案，尽可能模拟现实世界中发生的情况，同时实现自动化的各种好处，包括速度、规模和一致性。\n安装nodejs Appium是基于Node.js构建的,所以首先需要安装Node.js\n下载地址：https://nodejs.org/en/download/\n下载并安装，验证是否安装成功\nnode -v 安装appium 安装Appium。在命令提示符下运行:\nnpm install -g appium 安装appium-doctor 安装appium-doctor。在命令提示符下运行:\nnpm install -g appium-doctor 安装appium-desktop 安装appium-desktop。在命令提示符下运行:\nnpm install -g appium-desktop 安装jdk 下载地址：https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html 下载并安装，验证是否安装成功\njava -version 安装android-sdk 下载地址：https://developer.android.com/studio 下载并安装，验证是否安装成功\nadb version 配置环境变量 在系统环境变量中添加以下变量\nANDROID_HOME = D:\\Android\\sdk JAVA_HOME = C:\\Program Files\\Java\\jdk1.8.0_311 Path = %ANDROID_HOME%\\platform-tools;%ANDROID_HOME%\\tools;%JAVA_HOME%\\bin 验证是否配置成功\nappium-doctor 启动appium appium 启动appium-desktop appium-desktop 测试脚本 创建测试脚本test.py\nfrom appium import webdriver import time desired_caps = {} desired_caps[\u0026#39;platformName\u0026#39;] =","title":"在windows上安装appium"},{"content":"nginx 自编译 nginx官网\n下载nginx-\u0026amp;gt;Configure-\u0026amp;gt;编译-\u0026amp;gt;安装\n下载nginx wget https://nginx.org/download/nginx-1.24.0.tar.gz 解压目录\ntar -zxvf nginx-1.24.0.tar.gz 编译最新的 nginx,并备份旧的二进制文件 cd nginx-1.24.0 ./configure \u0026amp;amp;\u0026amp;amp; make mv /path/to/nginx /path/to/nginx.bak 覆盖旧的二进制文件 cp /path/to/nginx /path/to/nginx 执行平滑重启 nginx -s reopen 观察nginx服务是否有中断,如果正常则删除备份文件 rm /path/to/nginx.bak ","permalink":"https://test.jobcher.com/nginx-%E9%85%8D%E7%BD%AE%E5%92%8C%E7%BC%96%E8%AF%91.html","summary":"nginx 自编译 nginx官网\n下载nginx-\u0026gt;Configure-\u0026gt;编译-\u0026gt;安装\n下载nginx wget https://nginx.org/download/nginx-1.24.0.tar.gz 解压目录\ntar -zxvf nginx-1.24.0.tar.gz 编译最新的 nginx,并备份旧的二进制文件 cd nginx-1.24.0 ./configure \u0026amp;\u0026amp; make mv /path/to/nginx /path/to/nginx.bak 覆盖旧的二进制文件 cp /path/to/nginx /path/to/nginx 执行平滑重启 nginx -s reopen 观察nginx服务是否有中断,如果正常则删除备份文件 rm /path/to/nginx.bak ","title":"nginx 配置和编译"},{"content":"演示代理 前缀 https://github.jobcher.com/gh/ 下载仓库 git clone https://github.jobcher.com/gh/\u0026amp;lt;你要下载的GitHub地址\u0026amp;gt; #例子 git clone https://github.jobcher.com/gh/https://github.com/jobcher/blog.git 部署 复制js到cloudflare worker\n\u0026amp;#39;use strict\u0026amp;#39; /** * static files (404.html, sw.js, conf.js) */ const ASSET_URL = \u0026amp;#39;https://jobcher.github.io/\u0026amp;#39; // 前缀，如果自定义路由为example.com/gh/*，将PREFIX改为 \u0026amp;#39;/gh/\u0026amp;#39;，注意，少一个杠都会错！ const PREFIX = \u0026amp;#39;/gh/\u0026amp;#39; // 分支文件使用jsDelivr镜像的开关，0为关闭，默认关闭 const Config = { jsdelivr: 0 } const whiteList = [] // 白名单，路径里面有包含字符的才会通过，e.g. [\u0026amp;#39;/username/\u0026amp;#39;] /** @type {RequestInit} */ const PREFLIGHT_INIT = { status: 204, headers: new Headers({ \u0026amp;#39;access-control-allow-origin\u0026amp;#39;: \u0026amp;#39;*\u0026amp;#39;, \u0026amp;#39;access-control-allow-methods\u0026amp;#39;: \u0026amp;#39;GET,POST,PUT,PATCH,TRACE,DELETE,HEAD,OPTIONS\u0026amp;#39;, \u0026amp;#39;access-control-max-age\u0026amp;#39;: \u0026amp;#39;1728000\u0026amp;#39;, }), } const exp1 = /^(?:https?:\\/\\/)?github\\.com\\/.+?\\/.+?\\/(?:releases|archive)\\/.*$/i const exp2 = /^(?:https?:\\/\\/)?github\\.com\\/.+?\\/.+?\\/(?:blob|raw)\\/.*$/i","permalink":"https://test.jobcher.com/github-%E5%9B%BD%E5%86%85%E4%BB%A3%E7%90%86%E8%AE%BF%E9%97%AE%E4%B8%8B%E8%BD%BD.html","summary":"演示代理 前缀 https://github.jobcher.com/gh/ 下载仓库 git clone https://github.jobcher.com/gh/\u0026lt;你要下载的GitHub地址\u0026gt; #例子 git clone https://github.jobcher.com/gh/https://github.com/jobcher/blog.git 部署 复制js到cloudflare worker\n\u0026#39;use strict\u0026#39; /** * static files (404.html, sw.js, conf.js) */ const ASSET_URL = \u0026#39;https://jobcher.github.io/\u0026#39; // 前缀，如果自定义路由为example.com/gh/*，将PREFIX改为 \u0026#39;/gh/\u0026#39;，注意，少一个杠都会错！ const PREFIX = \u0026#39;/gh/\u0026#39; // 分支文件使用jsDelivr镜像的开关，0为关闭，默认关闭 const Config = { jsdelivr: 0 } const whiteList = [] // 白名单，路径里面有包含字符的才会通过，e.g. [\u0026#39;/username/\u0026#39;] /** @type {RequestInit} */ const PREFLIGHT_INIT = { status: 204, headers: new Headers({ \u0026#39;access-control-allow-origin\u0026#39;: \u0026#39;*\u0026#39;, \u0026#39;access-control-allow-methods\u0026#39;: \u0026#39;GET,POST,PUT,PATCH,TRACE,DELETE,HEAD,OPTIONS\u0026#39;, \u0026#39;access-control-max-age\u0026#39;: \u0026#39;1728000\u0026#39;, }), } const exp1 = /^(?","title":"github 国内代理访问下载"},{"content":"使用scrapy-redis实现增量爬取 Scrapy-Redis是Scrapy框架的一个插件，可以使用Redis实现Scrapy的分布式爬虫。它使用Redis作为分布式队列，可以轻松地将爬虫分布在多个机器上。同时，它还提供了一些功能，如去重、持久化、增量爬取等。\n要使用Scrapy-Redis实现增量爬取，可以采取以下步骤： 在Scrapy项目中安装Scrapy-Redis插件。可以使用pip安装：pip install scrapy-redis 在Scrapy的settings.py中添加如下配置： # 使用Redis调度器 SCHEDULER = \u0026amp;#34;scrapy_redis.scheduler.Scheduler\u0026amp;#34; # 使用Redis去重过滤器 DUPEFILTER_CLASS = \u0026amp;#34;scrapy_redis.dupefilter.RFPDupeFilter\u0026amp;#34; # 允许暂停、恢复爬取 SCHEDULER_PERSIST = True 将Spider的爬取链接放入Redis队列中。可以在Spider中重载start_requests()方法，从Redis队列中获取链接开始爬取。 import scrapy from scrapy_redis.spiders import RedisSpider class MySpider(RedisSpider): name = \u0026amp;#39;myspider\u0026amp;#39; redis_key = \u0026amp;#39;myspider:start_urls\u0026amp;#39; def parse(self, response): # 处理响应 pass 在Spider中实现增量爬取。可以通过重载Spider中的start_requests()方法或者使用SpiderMiddleware来实现增量爬取。这里提供一种通过修改Redis队列来实现增量爬取的方法。 import scrapy import redis from scrapy_redis.spiders import RedisSpider from scrapy.utils.project import get_project_settings class MySpider(RedisSpider): name = \u0026amp;#39;myspider\u0026amp;#39; redis_key =","permalink":"https://test.jobcher.com/%E4%BD%BF%E7%94%A8scrapy-redis%E5%AE%9E%E7%8E%B0%E5%A2%9E%E9%87%8F%E7%88%AC%E5%8F%96.html","summary":"使用scrapy-redis实现增量爬取 Scrapy-Redis是Scrapy框架的一个插件，可以使用Redis实现Scrapy的分布式爬虫。它使用Redis作为分布式队列，可以轻松地将爬虫分布在多个机器上。同时，它还提供了一些功能，如去重、持久化、增量爬取等。\n要使用Scrapy-Redis实现增量爬取，可以采取以下步骤： 在Scrapy项目中安装Scrapy-Redis插件。可以使用pip安装：pip install scrapy-redis 在Scrapy的settings.py中添加如下配置： # 使用Redis调度器 SCHEDULER = \u0026#34;scrapy_redis.scheduler.Scheduler\u0026#34; # 使用Redis去重过滤器 DUPEFILTER_CLASS = \u0026#34;scrapy_redis.dupefilter.RFPDupeFilter\u0026#34; # 允许暂停、恢复爬取 SCHEDULER_PERSIST = True 将Spider的爬取链接放入Redis队列中。可以在Spider中重载start_requests()方法，从Redis队列中获取链接开始爬取。 import scrapy from scrapy_redis.spiders import RedisSpider class MySpider(RedisSpider): name = \u0026#39;myspider\u0026#39; redis_key = \u0026#39;myspider:start_urls\u0026#39; def parse(self, response): # 处理响应 pass 在Spider中实现增量爬取。可以通过重载Spider中的start_requests()方法或者使用SpiderMiddleware来实现增量爬取。这里提供一种通过修改Redis队列来实现增量爬取的方法。 import scrapy import redis from scrapy_redis.spiders import RedisSpider from scrapy.utils.project import get_project_settings class MySpider(RedisSpider): name = \u0026#39;myspider\u0026#39; redis_key =","title":"使用scrapy-redis实现增量爬取"},{"content":"打工人周报：记录每周值得分享的内容,周四发布,`第八期`欢迎关注。 资讯动态 1. OpenAI公布最新版本GPT-4 称其能在SAT考试中击败90%考生 3月14日，人工智能研究公司OpenAI公布了其大型语言模型的最新版本——GPT-4，并表示模型在许多专业测试中表现出“人类水平的性能”。\n据悉，OpenAI于2020年发布了GPT-3（生成型预训练变换模型3），并将其与GPT-3.5分别用于创建Dall-E和聊天机器人ChatGPT，这两款产品极大地吸引了公众的关注，并刺激其他科技公司更积极地追求人工智能（AI）。\nOpenAI周二表示，在内部评估中，GPT-4产生正确回应的可能性要比GPT-3.5高出40%。而且GPT-4是多模态的，同时支持文本和图像输入功能。OpenAI称，GPT-4在模拟律师资格考试的成绩在考生中排名前10%左右，在SAT阅读考试中排名前7%左右，在SAT数学考试中排名前11%左右。据合作方爆料，新版必应搜索引擎也将使用GPT-4。（财联社）\n2. 戴尔PC将离开中国 完整时间表曝光 3月14日，有媒体曝光了戴尔所谓“去中化”的全套剧本和时间表，从上游IC采购到中下游周边再到整机组装，都有明确的安排。根据计划，戴尔预计从2025年开始，首先在中下游供应链中排除中国内地制造，并优先在美国内需市场上进行转变。比如笔记本，戴尔计划到2025年，在美国市场上销售的产品，60％必须在中国内地之外的地区生产，2027年则达到100％。IC零组件采购方面，戴尔计划从2026年开始，分阶段离开中国。（快科技）\n3. 腾讯会议再次调整：将取消免费300人不限时会议 3月14日，腾讯会议发布调整说明：4月4日起逐步取消免费用户“300人不限时会议”使用权限，单场会议最高人数和时长调整为100人/60分钟。与此同时，会员服务也有部分调整。\n4. 华为手表将率先支持卫星通信 3月14日，据华为发布的海报猜测，新系列华为手表将支持卫星通信。短时间内卫星通信技术不仅实现了从实验室到商用的演进，还将实现手机到手表的技术攻坚突破，卫星通信技术或将成为智能穿戴行业的技术新趋势。据了解，即将发布的华为WATCH Ultimate还将支持“上山下海”的全新体验。\n5. 谷歌在Gmail等办公应用中引入AI技术：可自动生成所需内容 谷歌宣布，将进一步在其产品中引入人工智能（AI）技术，这一次将把它整合到Gmail电子邮件","permalink":"https://test.jobcher.com/%E6%89%93%E5%B7%A5%E4%BA%BA%E5%91%A8%E6%8A%A5%E7%AC%AC%E5%85%AB%E6%9C%9F.html","summary":"打工人周报：记录每周值得分享的内容,周四发布,`第八期`欢迎关注。 资讯动态 1. OpenAI公布最新版本GPT-4 称其能在SAT考试中击败90%考生 3月14日，人工智能研究公司OpenAI公布了其大型语言模型的最新版本——GPT-4，并表示模型在许多专业测试中表现出“人类水平的性能”。\n据悉，OpenAI于2020年发布了GPT-3（生成型预训练变换模型3），并将其与GPT-3.5分别用于创建Dall-E和聊天机器人ChatGPT，这两款产品极大地吸引了公众的关注，并刺激其他科技公司更积极地追求人工智能（AI）。\nOpenAI周二表示，在内部评估中，GPT-4产生正确回应的可能性要比GPT-3.5高出40%。而且GPT-4是多模态的，同时支持文本和图像输入功能。OpenAI称，GPT-4在模拟律师资格考试的成绩在考生中排名前10%左右，在SAT阅读考试中排名前7%左右，在SAT数学考试中排名前11%左右。据合作方爆料，新版必应搜索引擎也将使用GPT-4。（财联社）\n2. 戴尔PC将离开中国 完整时间表曝光 3月14日，有媒体曝光了戴尔所谓“去中化”的全套剧本和时间表，从上游IC采购到中下游周边再到整机组装，都有明确的安排。根据计划，戴尔预计从2025年开始，首先在中下游供应链中排除中国内地制造，并优先在美国内需市场上进行转变。比如笔记本，戴尔计划到2025年，在美国市场上销售的产品，60％必须在中国内地之外的地区生产，2027年则达到100％。IC零组件采购方面，戴尔计划从2026年开始，分阶段离开中国。（快科技）\n3. 腾讯会议再次调整：将取消免费300人不限时会议 3月14日，腾讯会议发布调整说明：4月4日起逐步取消免费用户“300人不限时会议”使用权限，单场会议最高人数和时长调整为100人/60分钟。与此同时，会员服务也有部分调整。\n4. 华为手表将率先支持卫星通信 3月14日，据华为发布的海报猜测，新系列华为手表将支持卫星通信。短时间内卫星通信技术不仅实现了从实验室到商用的演进，还将实现手机到手表的技术攻坚突破，卫星通信技术或将成为智能穿戴行业的技术新趋势。据了解，即将发布的华为WATCH Ultimate还将支持“上山下海”的全新体验。\n5. 谷歌在Gmail等办公应用中引入AI技术：可自动生成所需内容 谷歌宣布，将进一步在其产品中引入人工智能（AI）技术，这一次将把它整合到Gmail电子邮件","title":"打工人周报（第八期）"},{"content":"打工人周报：记录每周值得分享的内容,周四发布,`第七期`欢迎关注。 资讯动态 1. 特斯拉因石子故障维修需花14万，特斯拉回应：电池价位占总价一半，都是明码标价 江西南昌董女士反映自己开特斯拉出门因碾压到路上小石子，石子弹射到车辆空气管致故障。行驶中发现行驶灯故障并出现无法加速情况。董女士将其送往维修中心。经过检测鉴定为电池故障需更换电池，费用大约需要14万元。高额的维修更换费用让董女士难以接受，目前该车辆正在走流程当中。据特斯拉官方回应称：电池价格占到车辆总价的一半，因为电池相对很重要，它的价格都是官方明码标价。（知未）\n2. 中文在线：国内首个科幻主题元宇宙RESTART将于本月进行首期功能模块上线 3月8日，中文在线在互动平台表示，公司目前已上线3款AIGC产品，分别为AI主播、AI绘画和AI文字创作功能。此外，根据公司自有IP打造的国内首个科幻主题元宇宙RESTART（重启宇宙）将于本月进行首期功能模块上线。同时，公司在国内和国外的不同应用产品上进行AIGC技术测试，推动业务合作。（界面新闻）\n3. 上海宜家回应禁止在仓库拍照：若影响其他客户体验将制止 近日，有网友发现在宜家大仓库区域不允许拍照。上海某门店客服称“一般的情况下，我们是让每个顾客满意，如果只是拿出手机随意拍两张是无所谓的。但是有的人，一些网店的人他们会拿着自己的箱子，服装来拍，影响到了其他客户的体验，在我们没法判断顾客进来是否会影响到他人的情况下，我们一般是不允许拍照的。”（新闻晨报）\n4. 特斯拉在美遭监管机构调查：Model Y方向盘在驾驶过程中脱落 3月8日，美国国家公路交通安全管理局（NHTSA）表示，在接到两起投诉后，已开始对特斯拉Model Y电动汽车的方向盘脱落问题展开调查。NHTSA称，已经接到两起事故投诉，车主在驾驶2023年生产的Model Y SUV电动汽车时，车轮竟然脱离了转向柱，即方向盘脱落。这主要是因为，受影响车辆在没安装固定螺栓（用于固定方向盘）的情况下就交付给了车主。（新浪科技）\n5. 美科学家团队重提“室温超导” 美国物理学会网站显示，罗切斯特大学物理学家蓝戈·迪亚兹举办了题为“静态超导实验”的报告会议，报告会现场爆棚，会议摘要显示，迪亚兹团队开发的新材料可以在更宽松的环境条件下表现出超导性。据报道，该团队在最新的实验中研发了一种由氢、氮和镥制成的材料，“它似乎可以在约21摄氏度的温度以及10千帕的压力下进","permalink":"https://test.jobcher.com/%E6%89%93%E5%B7%A5%E4%BA%BA%E5%91%A8%E6%8A%A5%E7%AC%AC%E4%B8%83%E6%9C%9F.html","summary":"打工人周报：记录每周值得分享的内容,周四发布,`第七期`欢迎关注。 资讯动态 1. 特斯拉因石子故障维修需花14万，特斯拉回应：电池价位占总价一半，都是明码标价 江西南昌董女士反映自己开特斯拉出门因碾压到路上小石子，石子弹射到车辆空气管致故障。行驶中发现行驶灯故障并出现无法加速情况。董女士将其送往维修中心。经过检测鉴定为电池故障需更换电池，费用大约需要14万元。高额的维修更换费用让董女士难以接受，目前该车辆正在走流程当中。据特斯拉官方回应称：电池价格占到车辆总价的一半，因为电池相对很重要，它的价格都是官方明码标价。（知未）\n2. 中文在线：国内首个科幻主题元宇宙RESTART将于本月进行首期功能模块上线 3月8日，中文在线在互动平台表示，公司目前已上线3款AIGC产品，分别为AI主播、AI绘画和AI文字创作功能。此外，根据公司自有IP打造的国内首个科幻主题元宇宙RESTART（重启宇宙）将于本月进行首期功能模块上线。同时，公司在国内和国外的不同应用产品上进行AIGC技术测试，推动业务合作。（界面新闻）\n3. 上海宜家回应禁止在仓库拍照：若影响其他客户体验将制止 近日，有网友发现在宜家大仓库区域不允许拍照。上海某门店客服称“一般的情况下，我们是让每个顾客满意，如果只是拿出手机随意拍两张是无所谓的。但是有的人，一些网店的人他们会拿着自己的箱子，服装来拍，影响到了其他客户的体验，在我们没法判断顾客进来是否会影响到他人的情况下，我们一般是不允许拍照的。”（新闻晨报）\n4. 特斯拉在美遭监管机构调查：Model Y方向盘在驾驶过程中脱落 3月8日，美国国家公路交通安全管理局（NHTSA）表示，在接到两起投诉后，已开始对特斯拉Model Y电动汽车的方向盘脱落问题展开调查。NHTSA称，已经接到两起事故投诉，车主在驾驶2023年生产的Model Y SUV电动汽车时，车轮竟然脱离了转向柱，即方向盘脱落。这主要是因为，受影响车辆在没安装固定螺栓（用于固定方向盘）的情况下就交付给了车主。（新浪科技）\n5. 美科学家团队重提“室温超导” 美国物理学会网站显示，罗切斯特大学物理学家蓝戈·迪亚兹举办了题为“静态超导实验”的报告会议，报告会现场爆棚，会议摘要显示，迪亚兹团队开发的新材料可以在更宽松的环境条件下表现出超导性。据报道，该团队在最新的实验中研发了一种由氢、氮和镥制成的材料，“它似乎可以在约21摄氏度的温度以及10千帕的压力下进","title":"打工人周报（第七期）"},{"content":"🧠ChatGPT 中文使用指南 ChatGPT是由OpenAI训练的一款大型语言模型，能够生成类人文本。\n国内中文版 它能够生成类似于人类写作的文本。您只需要给出提示或提出问题，它就可以生成你想要的东西。\n在此页面中，您将找到可与 ChatGPT 一起使用的各种提示。\n它能干什么? 包括但不限于：\n类别 描述 学术论文 它可以写各种类型的学术论文，包括科技论文、文学论文、社科论文等。它可以帮助你进行研究、分析、组织思路并编写出符合学术标准的论文。 创意写作 它可以写小说、故事、剧本、诗歌等创意性的文学作品，能够在描述情节和角色方面提供帮助。 内容创作 它可以写SEO文章、博客文章、社交媒体帖子、产品描述等各种类型的内容创作。它能够为你提供有趣、独特、易读的内容，帮助你吸引读者和提升品牌知名度。 商业写作 它可以帮助你编写商业计划书、市场调研报告、营销策略、商业简报、销售信件等。它可以用清晰、精炼的语言向你的潜在客户或投资者传达你的信息。 学术编辑 它可以帮助你进行学术论文、研究报告、学位论文等的编辑和校对工作，确保文本的正确性、一致性和完整性，并提供改进建议。 翻译 它可以进行英语和中文之间的翻译工作，包括但不限于学术文献、商业文档、网站内容、软件界面等。它可以保证翻译的准确性和专业性。 数据分析 它可以帮助你进行各种类型的数据分析，包括统计分析、文本分析、数据可视化等。它可以使用Python、R等工具来分析你的数据，并提供数据报告和可视化结果。 技术文档 它可以编写各种类型的技术文档，包括用户手册、技术规范、API文档、代码注释等。它可以使用清晰、准确、易懂的语言描述你的技术产品和流程。 教育培训 它可以编写各种类型的教育培训材料，包括课程大纲、课件、教学指南、教育评估等。它可以帮助你设计课程内容和教学方法，并为你制定适合你目标受众的培训计划。 网站内容 它可以编写网站的各种类型内容，包括首页、关于我们、服务介绍、博客文章等。它可以根据你的品牌和目标读者为你提供优质、富有吸引力的内容。 研究咨询 它可以帮助你进行研究、提供咨询意见和建议。它可以进行文献综述、研究设计、数据分析等工作，为你提供高质量、可靠的研究结果和建议。 演讲稿 它可以帮助你编写演讲稿、PPT等，包括商业演讲、学术演讲、庆典致辞等。它可以根据你的主题、目标听众和场合为你编写一份有说服力、生动有趣的演讲稿。 个人陈述 它可以帮助你编写个人陈述，包","permalink":"https://test.jobcher.com/chatgpt-%E4%B8%AD%E6%96%87%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97.html","summary":"🧠ChatGPT 中文使用指南 ChatGPT是由OpenAI训练的一款大型语言模型，能够生成类人文本。\n国内中文版 它能够生成类似于人类写作的文本。您只需要给出提示或提出问题，它就可以生成你想要的东西。\n在此页面中，您将找到可与 ChatGPT 一起使用的各种提示。\n它能干什么? 包括但不限于：\n类别 描述 学术论文 它可以写各种类型的学术论文，包括科技论文、文学论文、社科论文等。它可以帮助你进行研究、分析、组织思路并编写出符合学术标准的论文。 创意写作 它可以写小说、故事、剧本、诗歌等创意性的文学作品，能够在描述情节和角色方面提供帮助。 内容创作 它可以写SEO文章、博客文章、社交媒体帖子、产品描述等各种类型的内容创作。它能够为你提供有趣、独特、易读的内容，帮助你吸引读者和提升品牌知名度。 商业写作 它可以帮助你编写商业计划书、市场调研报告、营销策略、商业简报、销售信件等。它可以用清晰、精炼的语言向你的潜在客户或投资者传达你的信息。 学术编辑 它可以帮助你进行学术论文、研究报告、学位论文等的编辑和校对工作，确保文本的正确性、一致性和完整性，并提供改进建议。 翻译 它可以进行英语和中文之间的翻译工作，包括但不限于学术文献、商业文档、网站内容、软件界面等。它可以保证翻译的准确性和专业性。 数据分析 它可以帮助你进行各种类型的数据分析，包括统计分析、文本分析、数据可视化等。它可以使用Python、R等工具来分析你的数据，并提供数据报告和可视化结果。 技术文档 它可以编写各种类型的技术文档，包括用户手册、技术规范、API文档、代码注释等。它可以使用清晰、准确、易懂的语言描述你的技术产品和流程。 教育培训 它可以编写各种类型的教育培训材料，包括课程大纲、课件、教学指南、教育评估等。它可以帮助你设计课程内容和教学方法，并为你制定适合你目标受众的培训计划。 网站内容 它可以编写网站的各种类型内容，包括首页、关于我们、服务介绍、博客文章等。它可以根据你的品牌和目标读者为你提供优质、富有吸引力的内容。 研究咨询 它可以帮助你进行研究、提供咨询意见和建议。它可以进行文献综述、研究设计、数据分析等工作，为你提供高质量、可靠的研究结果和建议。 演讲稿 它可以帮助你编写演讲稿、PPT等，包括商业演讲、学术演讲、庆典致辞等。它可以根据你的主题、目标听众和场合为你编写一份有说服力、生动有趣的演讲稿。 个人陈述 它可以帮助你编写个人陈述，包","title":"🧠ChatGPT 中文使用指南"},{"content":"打工人周报：记录每周值得分享的内容,周四发布,`第六期`欢迎关注。 资讯动态 1. 知乎推出“一起公考AI课”APP，再加码教育业务 近日，知乎上线了一款名为“一起公考AI课”的APP，是知乎教育旗下的职业教育品牌。据悉，该产品运用了AI教学技术，专门提供公务员考试课程内容。根据体验，“一起公考AI课”APP，当前主要提供“行测”的笔试内容，通过AI教学技术逐节解锁5大模块，覆盖192个知识点，部分课程服务需进行付费。（Tech星球）\n2. 苹果：今天起，iPhone等设备电池正式涨价 苹果官网显示，从3月1日起，苹果iPhone、iPad、Mac部分机型的换电池服务将正式涨价。其中，iPhone 14之前的所有iPhone机型保外电池服务费用将增加169元。所有MacBook Air机型的保外电池服务费用也将增加290元，而所有Macbook和MacBook Pro机型的保外电池服务费用将增加480元。此外，以下iPad机型的保外电池服务费用将增加149元。\n3. Snap推出ChatGPT驱动的聊天机器人 据报道，照片信息应用Snapchat的母公司Snap在表示，将推出一个由ChatGPT技术驱动的AI聊天机器人。当前，该公司正寻求进入热门的生成式AI领域。Snap表示，新的聊天机器人名为My AI，将提供给Snap的高级订阅Snapchat+的用户使用。Snap表示，在经过训练之后，My AI能够提供一种有趣和轻松的对话方式，并将能够提供创造性的想法，如为朋友的生日提供潜在的礼物，或为某个主题写一首诗。\n4. 小米无线AR眼镜探索版正式发布 在2023MWC世界移动通信大会上，小米正式发布小米无线AR眼镜探索版。该眼镜拥有三大创新：采用无线连接，手机与眼镜通信延迟低于3ms，全链路延迟低至50ms；采用自由曲面光学模组，实现了“视网膜级”显示；采用自研微手势交互。具体来说，佩戴小米无线AR眼镜探索版时，在日常使用一个应用的过程中，挑选一个应用并打开、滑动浏览页面、退出应用回到桌面，这些操作都可使用微手势交互，无需借助手机。\n5. 苹果RealityPro头显无需iPhone配合使用 在最新一期的Power On通讯中报道，最新测试版本的Reality Pro头显“将不需要iPhone来设置或使用”。这与过去的苹果设备相比是一个很大的变化，如Apple Watch，其最初需要iPhone来初始化设置。相","permalink":"https://test.jobcher.com/%E6%89%93%E5%B7%A5%E4%BA%BA%E5%91%A8%E6%8A%A5%E7%AC%AC%E5%85%AD%E6%9C%9F.html","summary":"打工人周报：记录每周值得分享的内容,周四发布,`第六期`欢迎关注。 资讯动态 1. 知乎推出“一起公考AI课”APP，再加码教育业务 近日，知乎上线了一款名为“一起公考AI课”的APP，是知乎教育旗下的职业教育品牌。据悉，该产品运用了AI教学技术，专门提供公务员考试课程内容。根据体验，“一起公考AI课”APP，当前主要提供“行测”的笔试内容，通过AI教学技术逐节解锁5大模块，覆盖192个知识点，部分课程服务需进行付费。（Tech星球）\n2. 苹果：今天起，iPhone等设备电池正式涨价 苹果官网显示，从3月1日起，苹果iPhone、iPad、Mac部分机型的换电池服务将正式涨价。其中，iPhone 14之前的所有iPhone机型保外电池服务费用将增加169元。所有MacBook Air机型的保外电池服务费用也将增加290元，而所有Macbook和MacBook Pro机型的保外电池服务费用将增加480元。此外，以下iPad机型的保外电池服务费用将增加149元。\n3. Snap推出ChatGPT驱动的聊天机器人 据报道，照片信息应用Snapchat的母公司Snap在表示，将推出一个由ChatGPT技术驱动的AI聊天机器人。当前，该公司正寻求进入热门的生成式AI领域。Snap表示，新的聊天机器人名为My AI，将提供给Snap的高级订阅Snapchat+的用户使用。Snap表示，在经过训练之后，My AI能够提供一种有趣和轻松的对话方式，并将能够提供创造性的想法，如为朋友的生日提供潜在的礼物，或为某个主题写一首诗。\n4. 小米无线AR眼镜探索版正式发布 在2023MWC世界移动通信大会上，小米正式发布小米无线AR眼镜探索版。该眼镜拥有三大创新：采用无线连接，手机与眼镜通信延迟低于3ms，全链路延迟低至50ms；采用自由曲面光学模组，实现了“视网膜级”显示；采用自研微手势交互。具体来说，佩戴小米无线AR眼镜探索版时，在日常使用一个应用的过程中，挑选一个应用并打开、滑动浏览页面、退出应用回到桌面，这些操作都可使用微手势交互，无需借助手机。\n5. 苹果RealityPro头显无需iPhone配合使用 在最新一期的Power On通讯中报道，最新测试版本的Reality Pro头显“将不需要iPhone来设置或使用”。这与过去的苹果设备相比是一个很大的变化，如Apple Watch，其最初需要iPhone来初始化设置。相","title":"打工人周报（第六期）"},{"content":"ChatGPT Plus开通教程攻略 鉴于免费的ChatGPT账号经常无响应或者响应慢，一些已经顺利注册到ChatGPT的推特用户私信我，问我怎么开通ChatGPT Plus，于是我收集了各大佬们的各种开通ChatGPT Plus的方法，挑一个比较简单的测试了一下，目前顺利开通了ChatGPT Plus，20美金一个月，想要体验的同学可以跟着试试，目前国内大部分的master或者visa信用卡都无法通过验证的，我也是使用网友推荐的Depay信用卡成功开通ChatGPT Plus的。\n而且这卡还可以绑定美区的Apple ID作为付款方式，虽然美区Apple ID可以使用支付宝或者购买礼品卡进行充值，况且我已经绑定了Paypal，这卡还可以绑定国内微信支付宝进行消费，挺不错的。ChatGPT Plus开通攻略\n1、硬性条件 如果你具有两个条件，那么可以试试这个方法，能够顺利开通到ChatGPT Plus。\nChatGPT账号 纯净可访问ChatGPT的网络（全局美国IP网络） 如果你没有可以在这里跟着注册一个：ChatGPT注册详细步骤攻略 亲测成功\n2、注册领取虚拟信用卡 首先，你得注册一个可以绑定ChatGPT付款的信用卡：邀请注册地址\n使用手机或者邮箱都可以，注册完下载app\niOS需要外区账号\n安卓用户直接下载apk安装即可\n下载安装完app，使用账号登录，点击申请卡，然后根据自己的情况进行选择卡片类型\n免费开卡需要进行KYC验证 免KYC信息认证的需要支付10USDT 我选择的是免费开卡-标准卡，根据提示提交信息进行认证即可（大佬可以直接充钱免认证，看个人）\n3、钱包充值 目前激活该卡片需要充值USDT，而且仅支持USDT-TRC20方式进行充值\n我不是高级玩家，可以通过OKX、Bitop等等交易市场进行USDT-TRC20充值即可\n或者身边有朋友有的，直接转到你钱包也可，A姐使用的是OKX，\n不过发现我是新账号，需要7天才可以提币（不知道是不是针对我的，我也是小白）\n于是没有等，喊朋友直接转到我钱包了，身边没有朋友使用的，可以使用OKX试试\n开通ChatGPT需要20美元，其中转账或者兑换会有点汇率或者手续费\n充值25USDT够了，我充值了30USDT，开通完剩余8USDT多一点\n4、激活信用卡 等待到账号，点击充值，然后把收到的USDT充值到卡片进行激活信用卡，然后会提示余额不足，提示你把USDT兑换","permalink":"https://test.jobcher.com/chatgpt-plus%E5%BC%80%E9%80%9A%E6%95%99%E7%A8%8B%E6%94%BB%E7%95%A5.html","summary":"ChatGPT Plus开通教程攻略 鉴于免费的ChatGPT账号经常无响应或者响应慢，一些已经顺利注册到ChatGPT的推特用户私信我，问我怎么开通ChatGPT Plus，于是我收集了各大佬们的各种开通ChatGPT Plus的方法，挑一个比较简单的测试了一下，目前顺利开通了ChatGPT Plus，20美金一个月，想要体验的同学可以跟着试试，目前国内大部分的master或者visa信用卡都无法通过验证的，我也是使用网友推荐的Depay信用卡成功开通ChatGPT Plus的。\n而且这卡还可以绑定美区的Apple ID作为付款方式，虽然美区Apple ID可以使用支付宝或者购买礼品卡进行充值，况且我已经绑定了Paypal，这卡还可以绑定国内微信支付宝进行消费，挺不错的。ChatGPT Plus开通攻略\n1、硬性条件 如果你具有两个条件，那么可以试试这个方法，能够顺利开通到ChatGPT Plus。\nChatGPT账号 纯净可访问ChatGPT的网络（全局美国IP网络） 如果你没有可以在这里跟着注册一个：ChatGPT注册详细步骤攻略 亲测成功\n2、注册领取虚拟信用卡 首先，你得注册一个可以绑定ChatGPT付款的信用卡：邀请注册地址\n使用手机或者邮箱都可以，注册完下载app\niOS需要外区账号\n安卓用户直接下载apk安装即可\n下载安装完app，使用账号登录，点击申请卡，然后根据自己的情况进行选择卡片类型\n免费开卡需要进行KYC验证 免KYC信息认证的需要支付10USDT 我选择的是免费开卡-标准卡，根据提示提交信息进行认证即可（大佬可以直接充钱免认证，看个人）\n3、钱包充值 目前激活该卡片需要充值USDT，而且仅支持USDT-TRC20方式进行充值\n我不是高级玩家，可以通过OKX、Bitop等等交易市场进行USDT-TRC20充值即可\n或者身边有朋友有的，直接转到你钱包也可，A姐使用的是OKX，\n不过发现我是新账号，需要7天才可以提币（不知道是不是针对我的，我也是小白）\n于是没有等，喊朋友直接转到我钱包了，身边没有朋友使用的，可以使用OKX试试\n开通ChatGPT需要20美元，其中转账或者兑换会有点汇率或者手续费\n充值25USDT够了，我充值了30USDT，开通完剩余8USDT多一点\n4、激活信用卡 等待到账号，点击充值，然后把收到的USDT充值到卡片进行激活信用卡，然后会提示余额不足，提示你把USDT兑换","title":"ChatGPT Plus开通教程攻略"},{"content":"打工人周报：记录每周值得分享的内容,周四发布,`第五期`欢迎关注。 资讯动态 1. 星链拟推出“全球漫游”互联网服务 月收费超 1300 元 SpaceX 旗下星链（Starlink）卫星互联网服务部分用户收到的最新消息显示，该公司正在测试名为“全球漫游”的互联网服务，其可以让人们“在世界上的任何地方接入网络”。然而，使用这项服务的费用并不便宜，除了花费 599 美元购买基本的星链套件之外，用户每月还需支付 200 美元（约合 1373 元人民币）费用。\n2. 爱奇艺黄金 VIP 恢复 720P 和 1080P 投屏 不再限制登录设备种类 2 月 20 日，爱奇艺做出两项会员服务调整：为 2023 年 2 月 20 日仍处于订阅状态的爱奇艺黄金 VIP 会员，恢复 720P 和 1080P 清晰度的投屏服务，以及爱奇艺黄金、白金、星钻 VIP 会员可在 5 台设备上登录，不再限制登录设备种类。当播放设备数量达上限后，爱奇艺会提示用户选择希望使用的播放设备。如遇 IP 地址异常等安全风险导致账号锁定，用户可通过修改密码解除锁定。\n3. 消息称京东拟 3 月初上线百亿补贴频道 2 月 20 日消息，据媒体报道，京东计划在 3 月初上线百亿补贴频道，正式向拼多多开战。报道称，百亿补贴频道将在 3 月 1 日~3 月 3 日前台切量 100%正式上线；3 月 3 日晚 8 点正式开场。今年，京东大商超事业群将重点发力 pop，自年初实施“0 元开店”策略以来，已经邀请了一批商家入驻，并承诺给予入驻商家一定的流量倾斜。至于这次京东的补贴方案，无论是自营还是 pop，都将与拼多多的商品价格进行比较，如果价格高于拼多多，就会进行补贴，同时也会与拼多多拉平抽取费用。报道还称，拼多多方面已采取初步应对措施，比如，拼多多百亿补贴频道已将部分京东员工 IP 屏蔽。（深厂）\n4. 苹果上新 348 元省电保护膜，网友：觉得贵的不是目标客户 近日，苹果中国大陆官网显示，平台上架了 2 款手机屏幕保护膜。该保护膜适用于 iPhone14 Pro 以及 14 Pro Max，名为 OtterBox Amplify Glass Glare Guard 防眩光屏幕保护膜，售价 348 元。据苹果官网介绍，这是专为 iPhone 设计的防眩光屏幕保护膜，为手机提供抗跌落、抗划伤、抗刮擦保护，同时具有先进的防眩光特性，让屏幕内容在各种光线条件下都清晰","permalink":"https://test.jobcher.com/%E6%89%93%E5%B7%A5%E4%BA%BA%E5%91%A8%E6%8A%A5%E7%AC%AC%E4%BA%94%E6%9C%9F.html","summary":"打工人周报：记录每周值得分享的内容,周四发布,`第五期`欢迎关注。 资讯动态 1. 星链拟推出“全球漫游”互联网服务 月收费超 1300 元 SpaceX 旗下星链（Starlink）卫星互联网服务部分用户收到的最新消息显示，该公司正在测试名为“全球漫游”的互联网服务，其可以让人们“在世界上的任何地方接入网络”。然而，使用这项服务的费用并不便宜，除了花费 599 美元购买基本的星链套件之外，用户每月还需支付 200 美元（约合 1373 元人民币）费用。\n2. 爱奇艺黄金 VIP 恢复 720P 和 1080P 投屏 不再限制登录设备种类 2 月 20 日，爱奇艺做出两项会员服务调整：为 2023 年 2 月 20 日仍处于订阅状态的爱奇艺黄金 VIP 会员，恢复 720P 和 1080P 清晰度的投屏服务，以及爱奇艺黄金、白金、星钻 VIP 会员可在 5 台设备上登录，不再限制登录设备种类。当播放设备数量达上限后，爱奇艺会提示用户选择希望使用的播放设备。如遇 IP 地址异常等安全风险导致账号锁定，用户可通过修改密码解除锁定。\n3. 消息称京东拟 3 月初上线百亿补贴频道 2 月 20 日消息，据媒体报道，京东计划在 3 月初上线百亿补贴频道，正式向拼多多开战。报道称，百亿补贴频道将在 3 月 1 日~3 月 3 日前台切量 100%正式上线；3 月 3 日晚 8 点正式开场。今年，京东大商超事业群将重点发力 pop，自年初实施“0 元开店”策略以来，已经邀请了一批商家入驻，并承诺给予入驻商家一定的流量倾斜。至于这次京东的补贴方案，无论是自营还是 pop，都将与拼多多的商品价格进行比较，如果价格高于拼多多，就会进行补贴，同时也会与拼多多拉平抽取费用。报道还称，拼多多方面已采取初步应对措施，比如，拼多多百亿补贴频道已将部分京东员工 IP 屏蔽。（深厂）","title":"打工人周报（第五期）"},{"content":"打工人周报：记录每周值得分享的内容,周四发布,`第四期`欢迎关注。 上周因为个人原因延了一期，之后会补上。 资讯动态 1. 宝马 i4 车主收到通知：车停在陡坡上无法升级 近日，宝马 i4 车主 Clare Eliza 近日收到通知：“路面太陡无法启动升级程序。请将车辆停到平坦区域再进行更新”。也就是说宝马 i4 车辆停在陡坡上就无法执行更新。宝马发言人表示：“宝马 i4 配备了俯仰、偏航、横向和纵向加速和减速等各种各样的传感器，汽车能够自行检测是否停在平坦路面上。这是一项安全预防措施，防止在糟糕的情况下导致车辆无法正常升级，避免滑坡等情况影响系统的升级”。（IT 之家）\n2. 科学家发现阻止新冠病毒感染的受体 悉尼大学的科学家在肺部发现一种蛋白质，可阻止 SARS-CoV-2 感染，在人体内形成天然保护屏障。被称为 LRRC15（leucine-rich repeat-containing protein 15） 的蛋白质能与 SARS-CoV-2 结合但不传播感染。英国牛津以及美国布朗和耶鲁大学的团队都各自独立在 LRRC15 蛋白质中发现了受体。\nSARS-CoV-2 病毒主要通过与 ACE2 受体结合感染人体细胞，而肺细胞具有高水平的 ACE2 受体，因此病毒主要通过感染肺部而造成严重问题。LRRC15 和 ACE2 一样都是 SARS-CoV-2 的受体，但不同之处是它不支持感染，通过粘住病毒使其无法移动，防止其它脆弱的细胞被感染。它会形成一道屏障，隔离病毒和最脆弱的肺细胞。（奇客 Solidot）\n3. 印度首款太阳能电动汽车 Vayve Eva 亮相，每天不花钱能跑 12 公里 2 月 12 日消息，总部位于印度浦那的电动汽车初创公司 Vayve Mobility 宣布计划于 2024 年推出印度首款太阳能电动汽车 Eva，并于 2024 年年中开始交付。\n从图中可以看到，Vayve Eva 是一款超小型的城市通勤车，可容纳两名成人和一名儿童。Eva 在车顶配备了一堆额定功率为 150W 的太阳能电池板，每天可以增加 10~12 公里的续航里程。Vayve Eva 还装有 14kWh 的电池组，总续航达到了 250 公里，并且可以使用家用壁式插座充电器在 4 小时内充满电。（IT 之家）\n4. 多台设备同时登录腾讯视频致账号被封 升级 SVIP 可立即解锁 近日，河南的魏女士的腾讯视频账号在三部手机","permalink":"https://test.jobcher.com/%E6%89%93%E5%B7%A5%E4%BA%BA%E5%91%A8%E6%8A%A5%E7%AC%AC%E5%9B%9B%E6%9C%9F.html","summary":"打工人周报：记录每周值得分享的内容,周四发布,`第四期`欢迎关注。 上周因为个人原因延了一期，之后会补上。 资讯动态 1. 宝马 i4 车主收到通知：车停在陡坡上无法升级 近日，宝马 i4 车主 Clare Eliza 近日收到通知：“路面太陡无法启动升级程序。请将车辆停到平坦区域再进行更新”。也就是说宝马 i4 车辆停在陡坡上就无法执行更新。宝马发言人表示：“宝马 i4 配备了俯仰、偏航、横向和纵向加速和减速等各种各样的传感器，汽车能够自行检测是否停在平坦路面上。这是一项安全预防措施，防止在糟糕的情况下导致车辆无法正常升级，避免滑坡等情况影响系统的升级”。（IT 之家）\n2. 科学家发现阻止新冠病毒感染的受体 悉尼大学的科学家在肺部发现一种蛋白质，可阻止 SARS-CoV-2 感染，在人体内形成天然保护屏障。被称为 LRRC15（leucine-rich repeat-containing protein 15） 的蛋白质能与 SARS-CoV-2 结合但不传播感染。英国牛津以及美国布朗和耶鲁大学的团队都各自独立在 LRRC15 蛋白质中发现了受体。\nSARS-CoV-2 病毒主要通过与 ACE2 受体结合感染人体细胞，而肺细胞具有高水平的 ACE2 受体，因此病毒主要通过感染肺部而造成严重问题。LRRC15 和 ACE2 一样都是 SARS-CoV-2 的受体，但不同之处是它不支持感染，通过粘住病毒使其无法移动，防止其它脆弱的细胞被感染。它会形成一道屏障，隔离病毒和最脆弱的肺细胞。（奇客 Solidot）\n3. 印度首款太阳能电动汽车 Vayve Eva 亮相，每天不花钱能跑 12 公里 2 月 12 日消息，总部位于印度浦那的电动汽车初创公司 Vayve Mobility 宣布计划于 2024 年推出印度首款太阳能电动汽车 Eva，并于 2024 年年中开始交付。\n从图中可以看到，Vayve Eva 是一款超小型的城市通勤车，可容纳两名成人和一名儿童。Eva 在车顶配备了一堆额定功率为 150W 的太阳能电池板，每天可以增加 10~12 公里的续航里程。Vayve Eva 还装有 14kWh 的电池组，总续航达到了 250 公里，并且可以使用家用壁式插座充电器在 4 小时内充满电。（IT 之家）","title":"打工人周报（第四期）"},{"content":"打工人周报：记录每周值得分享的内容,周四发布,`第三期`欢迎关注。 资讯动态 1. 优酷“首月 1 元”会员引争议：取消续费却被扣 24 元 1 月 30 日消息，近日优酷的“1 元会员”又引发争议。据上观新闻报道，优酷视频于 2022 年年末上线“首月 1 元”会员优惠充值活动，但多名用户反映，其在完成支付后才发现，支付宝相应页面中弹出的实则为“优酷月月省”活动界面，支付 1 元后默认签约 1 年，除首月外，每月将自动扣费 12 元。由于并无长期会员需求，不少用户选择了提前中止参与该活动，不料却立刻收到了扣费 24 元的提示：“未完成任务，扣回已享优惠。”\n2. ChatGPT 全球爆火后：百度宣布 3 月将推出类似 AI 服务 1 月 30 日，据报道，一位知情人士透露，百度公司正计划在今年 3 月推出与 OpenAI 的 ChatGPT 类似的人工智能聊天机器人服务，最初版本将嵌入其搜索服务中。这项工具将允许用户获得对话式的搜索结果，但名称尚未确定。百度的一位代表对该消息不予置评。\n3. 网易开放暴雪游戏退款申请通道 申请排队人数超 90 万 2 月 1 日，网易暴雪游戏客服团队面向暴雪游戏国服玩家，发布了《网之易关于暴雪游戏产品运营到期开放退款的说明》。网易暴雪游戏客服团队表示，从 2023 年 2 月 1 日 11 时起，针对玩家在“暴雪游戏产品”中已充值但未消耗的虚拟货币或未失效的游戏服务（下称“可退款商品”）开放退款申请通道。\n此外，提交退款申请的截止日期为 2023 年 6 月 30 日，未在截止日期前提交退款申请的玩家将被视为主动放弃相关权益。截至 2 月 2 日 0 时 12 分，在暴雪游戏服务中心的退款渠道中，申请退款的排队人数已超 90 万。\n4. OpenAI 发布“反侦查”工具，可检测文本是否由 AI 生成 2 月 1 日，AI 聊天机器人 ChatGPT 的开发商 OpenAI 发布了监测机器生成文本的免费 Web 工具(需要登陆或注册)，帮助教师和其他需要的群体判断一段文本是机器还是人类撰写的。OpenAI 表示，该工具并不完美，可能会出现假阳性和假阴性，不能单靠它去判断一篇文档的作者身份。该工具会根据五分制对分析的文本给出结果：非常不可能是 AI 生成的、不可能，不清楚，有可能和很可能。该工具对于一千字以上文本和英文书写的文本表现最优。（奇客）\n5.","permalink":"https://test.jobcher.com/%E6%89%93%E5%B7%A5%E4%BA%BA%E5%91%A8%E6%8A%A5%E7%AC%AC%E4%B8%89%E6%9C%9F.html","summary":"打工人周报：记录每周值得分享的内容,周四发布,`第三期`欢迎关注。 资讯动态 1. 优酷“首月 1 元”会员引争议：取消续费却被扣 24 元 1 月 30 日消息，近日优酷的“1 元会员”又引发争议。据上观新闻报道，优酷视频于 2022 年年末上线“首月 1 元”会员优惠充值活动，但多名用户反映，其在完成支付后才发现，支付宝相应页面中弹出的实则为“优酷月月省”活动界面，支付 1 元后默认签约 1 年，除首月外，每月将自动扣费 12 元。由于并无长期会员需求，不少用户选择了提前中止参与该活动，不料却立刻收到了扣费 24 元的提示：“未完成任务，扣回已享优惠。”\n2. ChatGPT 全球爆火后：百度宣布 3 月将推出类似 AI 服务 1 月 30 日，据报道，一位知情人士透露，百度公司正计划在今年 3 月推出与 OpenAI 的 ChatGPT 类似的人工智能聊天机器人服务，最初版本将嵌入其搜索服务中。这项工具将允许用户获得对话式的搜索结果，但名称尚未确定。百度的一位代表对该消息不予置评。\n3. 网易开放暴雪游戏退款申请通道 申请排队人数超 90 万 2 月 1 日，网易暴雪游戏客服团队面向暴雪游戏国服玩家，发布了《网之易关于暴雪游戏产品运营到期开放退款的说明》。网易暴雪游戏客服团队表示，从 2023 年 2 月 1 日 11 时起，针对玩家在“暴雪游戏产品”中已充值但未消耗的虚拟货币或未失效的游戏服务（下称“可退款商品”）开放退款申请通道。\n此外，提交退款申请的截止日期为 2023 年 6 月 30 日，未在截止日期前提交退款申请的玩家将被视为主动放弃相关权益。截至 2 月 2 日 0 时 12 分，在暴雪游戏服务中心的退款渠道中，申请退款的排队人数已超 90 万。","title":"打工人周报（第三期）"},{"content":"打工人周报：记录每周值得分享的内容,周四发布,`第二期`欢迎关注。 [通知]因春节假期改为周一发布 资讯动态 1. 曝 iPad Pro 未来会砍掉实体按键：梦回 iPhone 7 时代 1 月 12 日消息，据 9to5Mac 报道，苹果今年下半年要发布的 iPhone 15 Pro 将会砍掉实体按键，未来 iPad Pro、Apple Watch 等也将会跟进，它们都将采用类似 iPhone 7、iPhone 8 时代的固态 Home 按键设计。据悉，iPad Pro 将会集成 Taptic Engine 固态按键控制器 IC，它被用来模拟按压物理按键的震动。知名分析师郭明錤表示，苹果之所以想砍掉实体按键，最主要原因是想提高设备耐用性，物理电源和音量按键很容易出故障，砍掉按键一方面提升耐用性，另一方面增强设备防水性。\n2. AMD 承认闹乌龙，官方表示尚未确认锐龙 7000 X3D 上市时间 根据 AMD 官网放出的参数页信息，AMD R9 7950X3D、R9 7900X3D、R7 7800X3D 将于 2 月 14 日上市，但有网友怀疑只是占位符，现在 AMD 官方也已经确认这一数字并非真实日期，不过官方并未给出任何进一步的细节。上周，AMD 在 CES 2023 上正式发布了采用 3D 缓存的锐龙 7000X3D 台式机处理器，最高 16 核 32 线程，L2+L3 缓存达到 144MB，共有三个型号。AMD 在 PPT 中声称，在流行的电子竞技游戏中，R7 7800X3D 的游戏性能提升可达 25%。\n3. iOS 惹祸？苹果正在修复 iPhone 14 Pro 屏幕闪烁水平线问题 近日，苹果承认，当设备打开时，iPhone 14 ProMax 用户可能会在显示屏上看到闪烁的水平线。并表示这个问题并非硬件缺陷引起。iOS 16.3 目前正在与公共测试版计划的开发人员和成员进行测试，但该更新预计至少要再过几周才能启动。更迫在眉睫的是，继上个月发布 iOS 16.2 之后，苹果可能会发布 iOS 16.2.1，以解决用户遇到的这个问题和其他错误。（IT 之家）\n4. 兔年茅台生肖酒上市不到一周价格腰斩 近日，兔年茅台酒上市一周就大降价，价格从 6000 降到 3000 多一点，被茅台经销商吐槽为“流氓兔”。每年生肖酒刚上市，都会因供应量不足价格暴涨，而今年茅台官方兔茅放量，造成供大于求，因此价格一直下降。","permalink":"https://test.jobcher.com/%E6%89%93%E5%B7%A5%E4%BA%BA%E5%91%A8%E6%8A%A5%E7%AC%AC%E4%BA%8C%E6%9C%9F.html","summary":"打工人周报：记录每周值得分享的内容,周四发布,`第二期`欢迎关注。 [通知]因春节假期改为周一发布 资讯动态 1. 曝 iPad Pro 未来会砍掉实体按键：梦回 iPhone 7 时代 1 月 12 日消息，据 9to5Mac 报道，苹果今年下半年要发布的 iPhone 15 Pro 将会砍掉实体按键，未来 iPad Pro、Apple Watch 等也将会跟进，它们都将采用类似 iPhone 7、iPhone 8 时代的固态 Home 按键设计。据悉，iPad Pro 将会集成 Taptic Engine 固态按键控制器 IC，它被用来模拟按压物理按键的震动。知名分析师郭明錤表示，苹果之所以想砍掉实体按键，最主要原因是想提高设备耐用性，物理电源和音量按键很容易出故障，砍掉按键一方面提升耐用性，另一方面增强设备防水性。\n2. AMD 承认闹乌龙，官方表示尚未确认锐龙 7000 X3D 上市时间 根据 AMD 官网放出的参数页信息，AMD R9 7950X3D、R9 7900X3D、R7 7800X3D 将于 2 月 14 日上市，但有网友怀疑只是占位符，现在 AMD 官方也已经确认这一数字并非真实日期，不过官方并未给出任何进一步的细节。上周，AMD 在 CES 2023 上正式发布了采用 3D 缓存的锐龙 7000X3D 台式机处理器，最高 16 核 32 线程，L2+L3 缓存达到 144MB，共有三个型号。AMD 在 PPT 中声称，在流行的电子竞技游戏中，R7 7800X3D 的游戏性能提升可达 25%。","title":"打工人周报（第二期）"},{"content":"打工人周报：记录每周值得分享的内容,周四发布,`第一期`欢迎关注。 资讯动态 1. 苹果宣布送 iPhone 或 iPad 新用户 6 个月 iCloud+ 苹果公司宣布，近期购买并激活新 iPhone 或 iPad 的新订阅用户，可免费获取 6 个月 iCloud+服务。简而言之，就是今年 1 月之后购买激活 iPhone 或 iPad 的用户。\n停用 iCloud+ 服务三个月以上的原订阅用户也可享受这一优惠”，老用户停用一段时间也可以享受优惠。\n2. 苹果推出 Apple Business Connect 工具 据苹果官网消息, Apple 今日推出了 Apple Business Connect。这款免费工具让各种规模的企业都能认领相应地址的地点卡，并自主设计关键信息在 Apple 地图、信息、钱包、Siri 等各种 App 中向超过十亿 Apple 用户展示的方式。\nApple Business Connect 是一款全新的免费工具，让企业可以在地点卡中自定义显示精美图像、关键信息和特别促销活动\n3. TikTok 推出限制给成人观众观看的功能 TikTok 宣布扩大其观众控制功能，使创作者能够将他们的视频限制给成人观众观看。在这次扩展之前，仅限成人的观众控制功能仅适用于 TikTok Live。现在，该公司也将该功能引入其短视频。\n4. iPhone 16 Pro 或取消灵动岛 近日，据 9to5Mac 报道，有两份报告显示，苹果在明年推出的 iPhone 16 系列（或仅限 iPhone 16 Pro 机型）将配备屏下 Face ID 传感器。这意味着苹果完全可以取消灵动岛（或刘海），仅保留 1 个前摄圆形打孔。\n互联网环境 1. 黑鲨被爆拖欠员工离职补偿金：CEO 微博变大型讨赔偿金现场 1 月 11 日消息，游戏手机厂商黑鲨科技被爆拖欠离职员工补偿金，黑鲨手机向部分被裁员工发布短信，告知暂无法按约定金额全额支付离职补偿金。该通知引发员工反弹，不少员工开启维权，在黑鲨手机办公地以及黑鲨手机 CEO 罗语周的微博账号下留言讨债，要求补偿金赔偿到位。\n据了解，自腾讯收购黑鲨计划搁浅后，黑鲨内部风波不断。经过几轮裁员后，黑鲨团队已从 2022 年 8 月的 1000 余人，减少至目前的 100 多人，仅保留互联网、职能等少数部门。而黑鲨科技的官博从去年 10 月开始再无更新，截至目前，黑鲨方面尚无回应。","permalink":"https://test.jobcher.com/%E6%89%93%E5%B7%A5%E4%BA%BA%E5%91%A8%E6%8A%A5%E7%AC%AC%E4%B8%80%E6%9C%9F.html","summary":"打工人周报：记录每周值得分享的内容,周四发布,`第一期`欢迎关注。 资讯动态 1. 苹果宣布送 iPhone 或 iPad 新用户 6 个月 iCloud+ 苹果公司宣布，近期购买并激活新 iPhone 或 iPad 的新订阅用户，可免费获取 6 个月 iCloud+服务。简而言之，就是今年 1 月之后购买激活 iPhone 或 iPad 的用户。\n停用 iCloud+ 服务三个月以上的原订阅用户也可享受这一优惠”，老用户停用一段时间也可以享受优惠。\n2. 苹果推出 Apple Business Connect 工具 据苹果官网消息, Apple 今日推出了 Apple Business Connect。这款免费工具让各种规模的企业都能认领相应地址的地点卡，并自主设计关键信息在 Apple 地图、信息、钱包、Siri 等各种 App 中向超过十亿 Apple 用户展示的方式。\nApple Business Connect 是一款全新的免费工具，让企业可以在地点卡中自定义显示精美图像、关键信息和特别促销活动\n3. TikTok 推出限制给成人观众观看的功能 TikTok 宣布扩大其观众控制功能，使创作者能够将他们的视频限制给成人观众观看。在这次扩展之前，仅限成人的观众控制功能仅适用于 TikTok Live。现在，该公司也将该功能引入其短视频。\n4. iPhone 16 Pro 或取消灵动岛 近日，据 9to5Mac 报道，有两份报告显示，苹果在明年推出的 iPhone 16 系列（或仅限 iPhone 16 Pro 机型）将配备屏下 Face ID 传感器。这意味着苹果完全可以取消灵动岛（或刘海），仅保留 1 个前摄圆形打孔。","title":"打工人周报（第一期）"},{"content":" 转眼间来到了 2022 年的尾声，2022 年不仅仅对于世界来说，还是对于我个人来说都是意义非凡的一年。\n逆境和成长 2022 年初在中国大陆仍然实行着最为严格的清零政策并愈演愈烈，城市居民被限制人身自由，就连农村地区也被大量要求居家隔离，严重损害了中国经济和社会活力。中国失业人口再创新高，大量的毕业生找不到工作。在美国，最为严重的通货膨胀席卷全国，高昂的加息政策，损害了底层人民和工薪阶层。在中东，塔利班武装重新占领阿富汗，重新实行政教合一的暴力统治。在俄罗斯，爆发了乌克兰战争，将俄罗斯真正从苏联的阴影中脱离出来。在世界各地发生了太多的变化，2022 年注定是要被载入史册的一年。\n对于我个人来说，2022 年也是成长非常大的一年，我经历了自工作来最大的变化，我从一家工作了多年的企业毕业，再次进入了社会的试炼场中求职，接触了更多的人，碰到了更多的事，也有了更多的感悟。曾经的我会讲工作看的比一切都重要，通过勤奋和努力可以改变一切，但是，社会的规则并不是这样的。决定你的个人价值并不是这些外在的东西，决定你个人价值的是你自己对自己的看法。你认为自己有价值，你就是你能够做到有价值。你觉得自己不重要，别人自然觉得你不重要。\n在 🆕 的 2023 年，希望世界和平，人人幸福，愿生活在苦难中的人们，能够早日远离苦难，让幸福来敲门……\n欢迎关注我的博客[www.jobcher.com](https://www.jobcher.com/) ","permalink":"https://test.jobcher.com/%E9%80%86%E5%A2%83%E5%92%8C%E6%88%90%E9%95%BF-2022%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93.html","summary":" 转眼间来到了 2022 年的尾声，2022 年不仅仅对于世界来说，还是对于我个人来说都是意义非凡的一年。\n逆境和成长 2022 年初在中国大陆仍然实行着最为严格的清零政策并愈演愈烈，城市居民被限制人身自由，就连农村地区也被大量要求居家隔离，严重损害了中国经济和社会活力。中国失业人口再创新高，大量的毕业生找不到工作。在美国，最为严重的通货膨胀席卷全国，高昂的加息政策，损害了底层人民和工薪阶层。在中东，塔利班武装重新占领阿富汗，重新实行政教合一的暴力统治。在俄罗斯，爆发了乌克兰战争，将俄罗斯真正从苏联的阴影中脱离出来。在世界各地发生了太多的变化，2022 年注定是要被载入史册的一年。\n对于我个人来说，2022 年也是成长非常大的一年，我经历了自工作来最大的变化，我从一家工作了多年的企业毕业，再次进入了社会的试炼场中求职，接触了更多的人，碰到了更多的事，也有了更多的感悟。曾经的我会讲工作看的比一切都重要，通过勤奋和努力可以改变一切，但是，社会的规则并不是这样的。决定你的个人价值并不是这些外在的东西，决定你个人价值的是你自己对自己的看法。你认为自己有价值，你就是你能够做到有价值。你觉得自己不重要，别人自然觉得你不重要。\n在 🆕 的 2023 年，希望世界和平，人人幸福，愿生活在苦难中的人们，能够早日远离苦难，让幸福来敲门……\n欢迎关注我的博客[www.jobcher.com](https://www.jobcher.com/) ","title":"逆境和成长-2022年终总结"},{"content":"背景 很多时候,避免不了同时使用 python2 和 python3 的环境,也避免不了不同的工作所需要不同版本的库文件,比如在想用 TensorFlow 较早版本的同时;还想运行 Pytorch 最新版；还想顺便学习 Nao 机器人编程,学习 Django 后台,这个时候,一款非常好用的包管理工具就显得十分重要了,这就是我写这篇博客的原因,这篇博客将会讲解：\n如何安装 conda; 如何更换 conda 的下载源; 如何使用 canda; 安装 conda 在安装时这两个选项需要点上：\n更换 conda 的下载源 Conda官方的下载源太慢了,而且经常会出现 HTTPERROR 之类的错误,如果想要用 Conda 愉快的创建不同工作环境,愉快的下载安装各种库,那么换下载源是必不可少的\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ conda config --set show_channel_urls yes # 设置搜索时显示通道地址 具体操作同时按 Win+R 键打开运行窗口,输入 cmd,回车：\n将上面的命令全部复制,到命令行里单击右键就会自动执行复制的命令,添加清华源\n使用 conda 查看环境\nconda info -e conda info --envs 创建环境\nconda create -n name python=3.6 # name参数指定虚拟环境的名字,python参数指定要安装python的版本,但注意至少需要指定python版本或者要安装的包,在后一种情况下,自动安装最新python版本 # 例如 conda create -n jobcher pillow numpy python=2.7.14 # 创建名字为naoqi,Python版本为2.7.14的虚拟环境,同时还会安装上pillow numpy这两个库 ","permalink":"https://test.jobcher.com/%E4%BC%98%E9%9B%85%E7%9A%84%E4%BD%BF%E7%94%A8conda%E7%AE%A1%E7%90%86python%E7%8E%AF%E5%A2%83.html","summary":"背景 很多时候,避免不了同时使用 python2 和 python3 的环境,也避免不了不同的工作所需要不同版本的库文件,比如在想用 TensorFlow 较早版本的同时;还想运行 Pytorch 最新版；还想顺便学习 Nao 机器人编程,学习 Django 后台,这个时候,一款非常好用的包管理工具就显得十分重要了,这就是我写这篇博客的原因,这篇博客将会讲解：\n如何安装 conda; 如何更换 conda 的下载源; 如何使用 canda; 安装 conda 在安装时这两个选项需要点上：\n更换 conda 的下载源 Conda官方的下载源太慢了,而且经常会出现 HTTPERROR 之类的错误,如果想要用 Conda 愉快的创建不同工作环境,愉快的下载安装各种库,那么换下载源是必不可少的\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ conda config --set show_channel_urls yes # 设置搜索时显示通道地址 具体操作同时按 Win+R 键打开运行窗口,输入 cmd,回车：\n将上面的命令全部复制,到命令行里单击右键就会自动执行复制的命令,添加清华源\n使用 conda 查看环境\nconda info -e conda info --envs 创建环境\nconda create -n name python=3.","title":"优雅的使用Conda管理python环境"},{"content":"背景 在开发 Web 项目当中，浏览器必不可少，而浏览器的启动参数可以帮我们实现很多功能。\n常用参数 序号 参数 说明 1 \u0026amp;ndash;allow- ted-plugins 不停用过期的插件。 2 \u0026amp;ndash;allow-running-insecure-content 默认情况下，https 页面不允许从 http 链接引用 javascript/css/plug-ins。添加这一参数会放行这些内容。 3 \u0026amp;ndash;allow-scripting-gallery 允许拓展脚本在官方应用中心生效。默认情况下，出于安全因素考虑这些脚本都会被阻止。 4 \u0026amp;ndash;disable-desktop-notifications 禁用桌面通知，在 Windows 中桌面通知默认是启用的。 5 \u0026amp;ndash;disable-file-system 停用 FileSystem API。 6 \u0026amp;ndash;disable-preconnect 停用 TCP/IP 预连接。 7 \u0026amp;ndash;disable-remote-fonts 关闭远程字体支持。SVG 中字体不受此参数影响。 8 \u0026amp;ndash;disable-web-security 不遵守同源策略。 9 \u0026amp;ndash;disk-cache-dir 将缓存设置在给定的路径。 10 \u0026amp;ndash;disk-cache-size 设置缓存大小上限，以字节为单位。 11 \u0026amp;ndash;dns-prefetch-disable 停用 DNS 预读。 12 \u0026amp;ndash;enable-print-preview 启用打印预览。 13 \u0026amp;ndash;extensions-update-frequency 设定拓展自动更新频率，以秒为单位。 14 \u0026amp;ndash;incognito 让浏览器直接以隐身模式启动。 15 \u0026amp;ndash;keep-alive-for-test 最后一个标签关闭后仍保持浏览器进程。（某种意义上可以提高热启动速度，不过你最好得有充足的内存） 16 \u0026amp;ndash;kiosk 启用 kiosk 模式。（一种类似于全屏的浏览模式） 17 \u0026amp;ndash;lang 使用指定的语言。 18 \u0026amp;ndash;no-displaying-insecure-content 默认情况下，https 页面允许从 http 链接引用图片/字体/框架。添加这一参数会阻止这些内容。","permalink":"https://test.jobcher.com/chrome%E6%B5%8F%E8%A7%88%E5%99%A8%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E5%A4%A7%E5%85%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0.html","summary":"背景 在开发 Web 项目当中，浏览器必不可少，而浏览器的启动参数可以帮我们实现很多功能。\n常用参数 序号 参数 说明 1 \u0026ndash;allow- ted-plugins 不停用过期的插件。 2 \u0026ndash;allow-running-insecure-content 默认情况下，https 页面不允许从 http 链接引用 javascript/css/plug-ins。添加这一参数会放行这些内容。 3 \u0026ndash;allow-scripting-gallery 允许拓展脚本在官方应用中心生效。默认情况下，出于安全因素考虑这些脚本都会被阻止。 4 \u0026ndash;disable-desktop-notifications 禁用桌面通知，在 Windows 中桌面通知默认是启用的。 5 \u0026ndash;disable-file-system 停用 FileSystem API。 6 \u0026ndash;disable-preconnect 停用 TCP/IP 预连接。 7 \u0026ndash;disable-remote-fonts 关闭远程字体支持。SVG 中字体不受此参数影响。 8 \u0026ndash;disable-web-security 不遵守同源策略。 9 \u0026ndash;disk-cache-dir 将缓存设置在给定的路径。 10 \u0026ndash;disk-cache-size 设置缓存大小上限，以字节为单位。 11 \u0026ndash;dns-prefetch-disable 停用 DNS 预读。 12 \u0026ndash;enable-print-preview 启用打印预览。 13 \u0026ndash;extensions-update-frequency 设定拓展自动更新频率，以秒为单位。 14 \u0026ndash;incognito 让浏览器直接以隐身模式启动。 15 \u0026ndash;keep-alive-for-test 最后一个标签关闭后仍保持浏览器进程。（某种意义上可以提高热启动速度，不过你最好得有充足的内存） 16 \u0026ndash;kiosk 启用 kiosk 模式。（一种类似于全屏的浏览模式） 17 \u0026ndash;lang 使用指定的语言。 18 \u0026ndash;no-displaying-insecure-content 默认情况下，https 页面允许从 http 链接引用图片/字体/框架。添加这一参数会阻止这些内容。","title":"Chrome浏览器启动参数大全（命令行参数）"},{"content":"背景 Jenkins 编译 Android apk，上传 apk 包，生成下载二维码，并推送钉钉\n安装 Android 环境 安装 JDK # 这里使用的是openjdk 1.8.0版本，有需要的话需要到java官网上进行下载对应的JDK版本。 $ yum install java -y # 其他版本JDK的安装方式 $ mv jdk1.8.0_161 /usr/local/ $ ln -s /usr/local/jdk1.8.0_161 /usr/local/jdk $ vim /etc/profile #配置JDK的环境变量 export JAVA_HOME=/usr/local/jdk export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar $ source /etc/profile #重新加载系统环境变量 $ java -version #查看java版本 Android SDK 安装 # 下载sdk工具包 $ wget https://dl.google.com/android/repository/sdk-tools-linux-3859397.zip # 创建sdk工具文件夹和解压工具包 $ mkdir -p /opt/android/sdk $ unzip sdk-tools-linux-3859397.zip -d /opt/android/sdk # 使用sdkmanager工具配置构建工具和平台版本 $ cd /opt/android/sdk/tools/bin/ $ ./sdkmanager \u0026amp;#34;build-tools;29.0.6\u0026amp;#34; \u0026amp;#34;platforms;android-29\u0026amp;#34; \u0026amp;#34;platform-tools\u0026amp;#34; $ ./sdkmanager --list #可以查看有哪些版本，自行选择对应的版本 # 增加系统环境变量 $ vim /etc/profile export ANDROID_HOME=/opt/android/sdk","permalink":"https://test.jobcher.com/jenkins-%E7%BC%96%E8%AF%91android-apk-%E6%B5%81%E6%B0%B4%E7%BA%BF.html","summary":"背景 Jenkins 编译 Android apk，上传 apk 包，生成下载二维码，并推送钉钉\n安装 Android 环境 安装 JDK # 这里使用的是openjdk 1.8.0版本，有需要的话需要到java官网上进行下载对应的JDK版本。 $ yum install java -y # 其他版本JDK的安装方式 $ mv jdk1.8.0_161 /usr/local/ $ ln -s /usr/local/jdk1.8.0_161 /usr/local/jdk $ vim /etc/profile #配置JDK的环境变量 export JAVA_HOME=/usr/local/jdk export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar $ source /etc/profile #重新加载系统环境变量 $ java -version #查看java版本 Android SDK 安装 # 下载sdk工具包 $ wget https://dl.google.com/android/repository/sdk-tools-linux-3859397.zip # 创建sdk工具文件夹和解压工具包 $ mkdir -p /opt/android/sdk $ unzip sdk-tools-linux-3859397.zip -d /opt/android/sdk # 使用sdkmanager工具配置构建工具和平台版本 $ cd /opt/android/sdk/tools/bin/ $ .","title":"Jenkins 编译Android apk 流水线"},{"content":"背景 使用 kubeadm 安装 kubernetes 集群非常方便，但是也有一个比较烦人的问题就是默认的证书有效期只有一年时间，所以需要考虑证书升级的问题\n检查证书 由 kubeadm 生成的客户端证书默认只有一年有效期，我们可以通过 check-expiration 命令来检查证书是否过期：\nkubeadm alpha certs check-expiration 该命令显示 /etc/kubernetes/pki 文件夹中的客户端证书以及 kubeadm 使用的 KUBECONFIG 文件中嵌入的客户端证书的到期时间/剩余时间。\n手动更新 kubeadm alpha certs renew\n这个命令用 CA（或者 front-proxy-CA ）证书和存储在 /etc/kubernetes/pki 中的密钥执行更新。\n高可用的集群，这个命令需要在所有控制面板节点上执行\n具体执行 接下来我们来更新我们的集群证书，下面的操作都是在 master 节点上进行\n备份节点 $ mkdir /etc/kubernetes.bak $ cp -r /etc/kubernetes/pki/ /etc/kubernetes.bak $ cp /etc/kubernetes/*.conf /etc/kubernetes.bak 备份 etcd 数据目录 $ cp -r /var/lib/etcd /var/lib/etcd.bak 执行更新证书的命令 kubeadm alpha certs renew all --config=kubeadm.yaml 检查更新 kubeadm alpha certs check-expiration 更新下 kubeconfig 文件 kubeadm init phase kubeconfig all --config kubeadm.yaml 覆盖掉原本的 admin 文件 $ mv $HOME/.kube/config $HOME/.kube/config.old $ cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ chown $(id -u):$(id -g) $HOME/.kube/config 重启 kube-apiserver、kube-controller、kube-scheduler、etcd ,","permalink":"https://test.jobcher.com/kubernetes-%E6%9B%B4%E6%96%B0%E8%AF%81%E4%B9%A6.html","summary":"背景 使用 kubeadm 安装 kubernetes 集群非常方便，但是也有一个比较烦人的问题就是默认的证书有效期只有一年时间，所以需要考虑证书升级的问题\n检查证书 由 kubeadm 生成的客户端证书默认只有一年有效期，我们可以通过 check-expiration 命令来检查证书是否过期：\nkubeadm alpha certs check-expiration 该命令显示 /etc/kubernetes/pki 文件夹中的客户端证书以及 kubeadm 使用的 KUBECONFIG 文件中嵌入的客户端证书的到期时间/剩余时间。\n手动更新 kubeadm alpha certs renew\n这个命令用 CA（或者 front-proxy-CA ）证书和存储在 /etc/kubernetes/pki 中的密钥执行更新。\n高可用的集群，这个命令需要在所有控制面板节点上执行\n具体执行 接下来我们来更新我们的集群证书，下面的操作都是在 master 节点上进行\n备份节点 $ mkdir /etc/kubernetes.bak $ cp -r /etc/kubernetes/pki/ /etc/kubernetes.bak $ cp /etc/kubernetes/*.conf /etc/kubernetes.bak 备份 etcd 数据目录 $ cp -r /var/lib/etcd /var/lib/etcd.bak 执行更新证书的命令 kubeadm alpha certs renew all --config=kubeadm.yaml 检查更新 kubeadm alpha certs check-expiration 更新下 kubeconfig 文件 kubeadm init phase kubeconfig all --config kubeadm.","title":"Kubernetes — 更新证书"},{"content":"背景 关于 Oracle 数据库一直是许多初学者比较头疼的地方，一方面受限于线上文档比较少，令一方面在企业中不得不接触和使用 Oracle 数据库，这篇文章是教大家如何通过配置 oracle client 来远程访问 Oracle 数据库。本文会通过 python3 和 cx_Oracle 来实现对 Oracle 的访问和增删改查\n下载 oracle 客户端 官方地址下载\n安装 下载并安装你的 oracle client，因为我连接的 11g oracle，所以下载 11.2 版本\n# 下载 wget https://download.oracle.com/otn/linux/instantclient/11204/oracle-instantclient11.2-basic-11.2.0.4.0-1.x86_64.rpm # 安装 rpm -ivh oracle-instantclient11.2-basic-11.2.0.4.0-1.x86_64.rpm 配置环境变量 # 直接运行 export ORACLE_HOME=/usr/lib/oracle/11.2/client64 export ORABIN=/usr/lib/oracle/11.2/client64/bin # 编辑环境变量配置文件 vim /etc/profile # 底部增加内容 export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL export ORACLE_HOME=/usr/lib/oracle/11.2/client64 export TNS_ADMIN=/usr/lib/oracle/11.2/client64 export LD_LIBRARY_PATH=/usr/lib/oracle/11.2/client64/lib export ORABIN=/usr/lib/oracle/11.2/client64/bin PATH=$PATH:$ORABIN export PATH export PATH=$ORACLE_HOME:$PATH export PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin # 刷新环境变量 source /etc/profile 下载 cx_Oracle pip3 install cx_Oracle","permalink":"https://test.jobcher.com/oracle-instant-client-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%AE%9E%E7%8E%B0%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5oracle.html","summary":"背景 关于 Oracle 数据库一直是许多初学者比较头疼的地方，一方面受限于线上文档比较少，令一方面在企业中不得不接触和使用 Oracle 数据库，这篇文章是教大家如何通过配置 oracle client 来远程访问 Oracle 数据库。本文会通过 python3 和 cx_Oracle 来实现对 Oracle 的访问和增删改查\n下载 oracle 客户端 官方地址下载\n安装 下载并安装你的 oracle client，因为我连接的 11g oracle，所以下载 11.2 版本\n# 下载 wget https://download.oracle.com/otn/linux/instantclient/11204/oracle-instantclient11.2-basic-11.2.0.4.0-1.x86_64.rpm # 安装 rpm -ivh oracle-instantclient11.2-basic-11.2.0.4.0-1.x86_64.rpm 配置环境变量 # 直接运行 export ORACLE_HOME=/usr/lib/oracle/11.2/client64 export ORABIN=/usr/lib/oracle/11.2/client64/bin # 编辑环境变量配置文件 vim /etc/profile # 底部增加内容 export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL export ORACLE_HOME=/usr/lib/oracle/11.2/client64 export TNS_ADMIN=/usr/lib/oracle/11.2/client64 export LD_LIBRARY_PATH=/usr/lib/oracle/11.2/client64/lib export ORABIN=/usr/lib/oracle/11.2/client64/bin PATH=$PATH:$ORABIN export PATH export PATH=$ORACLE_HOME:$PATH export PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin # 刷新环境变量 source /etc/profile 下载 cx_Oracle pip3 install cx_Oracle","title":"Oracle Instant Client 安装配置实现远程连接oracle"},{"content":"28 合 1 多功能脚本 脚本说明: 多合一脚本，DD 系统，BBR，xray,TG 搭建等等·常用的各种脚本基本都有！ 系统支持: CentOS6+ / Debian6+ / Ubuntu14+ 支持安装 BBR，搭建 KCPtun，ssr 多用户版 安装 V2ary，Tg 专用代理（Go 版），安装 Goflyway 小鸡性能测试，回程线路测试，云监控 傻瓜式一键 DD 包 一键开启默认 bbr Netflix 解锁检测 xray 安装 宝塔面板，闲蛋面板，x-ui 面板，WARP 一键配置 脚本特点: 目前网上的各个一键脚本基本都是只有 安装/启动/重启 等基础功能，对于小白来说还是不够简单方便。常用的各种脚本基本都有！\n下载安装: bash \u0026amp;lt;(curl -s -L https://git.io/JPj82) gfw_push 一键安装 脚本说明: 监测服务器 IP 是否被墙并推送至 Telegram 一键脚本 系统支持: CentOS6+ / Debian6+ / Ubuntu14+ 下载安装: bash \u0026amp;lt;(curl -s -L git.io/JPjzm) 服务器测速 脚本说明: 服务器一键测速脚本 系统支持: CentOS7 / Debian7+ / Ubuntu14+ 下载安装: bash \u0026amp;lt;(curl -s -L git.io/JPjzE) ","permalink":"https://test.jobcher.com/shell%E5%8A%9F%E8%83%BD%E8%84%9A%E6%9C%AC%E9%9B%86%E5%90%88.html","summary":"28 合 1 多功能脚本 脚本说明: 多合一脚本，DD 系统，BBR，xray,TG 搭建等等·常用的各种脚本基本都有！ 系统支持: CentOS6+ / Debian6+ / Ubuntu14+ 支持安装 BBR，搭建 KCPtun，ssr 多用户版 安装 V2ary，Tg 专用代理（Go 版），安装 Goflyway 小鸡性能测试，回程线路测试，云监控 傻瓜式一键 DD 包 一键开启默认 bbr Netflix 解锁检测 xray 安装 宝塔面板，闲蛋面板，x-ui 面板，WARP 一键配置 脚本特点: 目前网上的各个一键脚本基本都是只有 安装/启动/重启 等基础功能，对于小白来说还是不够简单方便。常用的各种脚本基本都有！\n下载安装: bash \u0026lt;(curl -s -L https://git.io/JPj82) gfw_push 一键安装 脚本说明: 监测服务器 IP 是否被墙并推送至 Telegram 一键脚本 系统支持: CentOS6+ / Debian6+ / Ubuntu14+ 下载安装: bash \u0026lt;(curl -s -L git.io/JPjzm) 服务器测速 脚本说明: 服务器一键测速脚本 系统支持: CentOS7 / Debian7+ / Ubuntu14+ 下载安装: bash \u0026lt;(curl -s -L git.","title":"shell功能脚本集合"},{"content":"zlibary 无法下载 因为 zlib 最近被封，导致现在通过正常方法下载不了电子书，但是不要慌，我们可以通过暗网进行下载~\n安装 brave 浏览器 官网下载\n下载你需要的版本，这个下载浏览器很简单，我就不多说了\n配置 tor 配置 编辑 tor 配置 使用 tor 浏览 zlibary tor 暗网版\n","permalink":"https://test.jobcher.com/zlibary-%E6%97%A0%E6%B3%95%E4%B8%8B%E8%BD%BD-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html","summary":"zlibary 无法下载 因为 zlib 最近被封，导致现在通过正常方法下载不了电子书，但是不要慌，我们可以通过暗网进行下载~\n安装 brave 浏览器 官网下载\n下载你需要的版本，这个下载浏览器很简单，我就不多说了\n配置 tor 配置 编辑 tor 配置 使用 tor 浏览 zlibary tor 暗网版","title":"zlibary 无法下载 解决方案"},{"content":"工作原理 检测到配置文件变化 通过停止所有输入停止当前pipline 用新的配置创建一个新的管道 检查配置文件语法是否正确 检查所有的输入和输出是否可以初始化 检查成功使用新的 pipeline 替换当前的pipeline 检查失败,使用旧的继续工作. 在重载过程中,jvm 没有重启. Logstash 自动重新加载配置 为了可以自动检测配置文件的变动和自动重新加载配置文件,需要在启动的时候使用以下命令:\n./bin/lagstash -f configfile.conf --config.reload.automatic 启动 Logstash 的时候使用--config.reload.automatic或-r选项来开启自动重载配置。\n修改检测间隔时间 默认检测配置文件的间隔时间是3秒,可以通过以下命令改变\n--config.reload.interval \u0026amp;lt;second\u0026amp;gt; 如果 Logstash 已经运行并且没有开启自动重载，你可以强制 Logstash 重新载入配置文件并且重启管道通过发送一个 SIGHUP 信号。比如：\nkill -1 \u0026amp;lt;pid\u0026amp;gt; 其中是正在运行的 Logstash 的进程号。\n注意！！！ stdin输入插件不支持自动重启.\nsyslog作为输入源,当重载配置文件时,会崩溃.\n解决方法\n","permalink":"https://test.jobcher.com/logstash-%E8%87%AA%E5%8A%A8%E9%87%8D%E8%BD%BD%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.html","summary":"工作原理 检测到配置文件变化 通过停止所有输入停止当前pipline 用新的配置创建一个新的管道 检查配置文件语法是否正确 检查所有的输入和输出是否可以初始化 检查成功使用新的 pipeline 替换当前的pipeline 检查失败,使用旧的继续工作. 在重载过程中,jvm 没有重启. Logstash 自动重新加载配置 为了可以自动检测配置文件的变动和自动重新加载配置文件,需要在启动的时候使用以下命令:\n./bin/lagstash -f configfile.conf --config.reload.automatic 启动 Logstash 的时候使用--config.reload.automatic或-r选项来开启自动重载配置。\n修改检测间隔时间 默认检测配置文件的间隔时间是3秒,可以通过以下命令改变\n--config.reload.interval \u0026lt;second\u0026gt; 如果 Logstash 已经运行并且没有开启自动重载，你可以强制 Logstash 重新载入配置文件并且重启管道通过发送一个 SIGHUP 信号。比如：\nkill -1 \u0026lt;pid\u0026gt; 其中是正在运行的 Logstash 的进程号。\n注意！！！ stdin输入插件不支持自动重启.\nsyslog作为输入源,当重载配置文件时,会崩溃.\n解决方法","title":"Logstash 自动重载配置文件"},{"content":"关于 macOS 13 软件失效 Warning: You are using macOS 13.\nWe do not provide support for this pre-release version.\nYou will encounter build failures with some formulae.\nPlease create pull requests instead of asking for help on Homebrew\u0026amp;rsquo;s GitHub, Twitter or any other official channels. You are responsible for resolving any issues you experience while you are running this pre-release version.\n简单来说就是 macOS13 版本 暂时不提供技术支持\n解决方法 升级完 macos13 之后发现了比较麻烦的问题，很多软件出现了不兼容，这真的很无奈，对于我们这些做 IT 的人来说，这是致命的。我以 git 软件举例，有以下几个方法。\n1. 使用时间机器恢复备份 使用前提：你之前备份了系统，并且系统正常 这个方法更加一劳永逸，因为我们并不确定还有什么软件不支持 macos13\n2. 重新安装 xcode-select xcode-select --install ","permalink":"https://test.jobcher.com/macos-13-%E5%8D%87%E7%BA%A7-%E8%BD%AF%E4%BB%B6%E5%A4%B1%E6%95%88.html","summary":"关于 macOS 13 软件失效 Warning: You are using macOS 13.\nWe do not provide support for this pre-release version.\nYou will encounter build failures with some formulae.\nPlease create pull requests instead of asking for help on Homebrew\u0026rsquo;s GitHub, Twitter or any other official channels. You are responsible for resolving any issues you experience while you are running this pre-release version.\n简单来说就是 macOS13 版本 暂时不提供技术支持\n解决方法 升级完 macos13 之后发现了比较麻烦的问题，很多软件出现了不兼容，这真的很无奈，对于我们这些做 IT 的人来说，这是致命的。我以 git 软件举例，有以下几个方法。","title":"macOS 13 升级 软件失效"},{"content":"Nexus3 docker-compose 安装 创建外部存储\nmkdir -p /data/nexus chmod +777 -R /data/nexus 运行 docker-compose\nversion: \u0026amp;#39;3\u0026amp;#39; services: nexus3: image: sonatype/nexus3:3.42.0 container_name: nexus3 ports: - 8081:8081 - 5000:5000 volumes: - /data/nexus:/nexus-data environment: - INSTALL4J_ADD_VM_PARAMS=-Xms1024m -Xmx1024m -XX:MaxDirectMemorySize=1024m -Djava.util.prefs.userRoot=/some-other-dir restart: always # 赋予外部root权限 privileged: true docker-compose up -d 运行 docker-compose\n","permalink":"https://test.jobcher.com/nexus3-%E4%BD%BF%E7%94%A8%E5%92%8C%E9%83%A8%E7%BD%B2.html","summary":"Nexus3 docker-compose 安装 创建外部存储\nmkdir -p /data/nexus chmod +777 -R /data/nexus 运行 docker-compose\nversion: \u0026#39;3\u0026#39; services: nexus3: image: sonatype/nexus3:3.42.0 container_name: nexus3 ports: - 8081:8081 - 5000:5000 volumes: - /data/nexus:/nexus-data environment: - INSTALL4J_ADD_VM_PARAMS=-Xms1024m -Xmx1024m -XX:MaxDirectMemorySize=1024m -Djava.util.prefs.userRoot=/some-other-dir restart: always # 赋予外部root权限 privileged: true docker-compose up -d 运行 docker-compose","title":"Nexus3 使用和部署"},{"content":"githubAction set-output 弃用错误 The set-output command is deprecated and will be disabled soon. Please upgrade to using Environment Files. For more information see: https://github.blog/changelog/2022-10-11-github-actions-deprecating-save-state-and-set-output-commands/\n原因 如果您有一个使用 设置输出的GitHub Actionsecho ::set-output key=value工作流程，您已经开始看到无用的弃用警告。这是修复它的方法。查看官方链接基本上得不到什么帮助！\n修复方法 更新其它人的 action 方法 将 @actions/core 提升到 1.10.0 修改自己的 aciton 方法 run: echo \u0026amp;#34;::set-output name=KEY::VALUE\u0026amp;#34; ## 改为 run: echo \u0026amp;#34;KEY=VALUE\u0026amp;#34; \u0026amp;gt;\u0026amp;gt;$GITHUB_OUTPUT 建议：使用自己的方法\n总结 平台经营者非常肆意妄为的修改自己的代码内容弃用功能，无限的权力滋生傲慢……我相信大部分开发这并没有注意到这个告警，知道流水线服务报错之后才会注意到，希望微软可以对能更加包容不同的开发者，尊重开发者社区。\n","permalink":"https://test.jobcher.com/githubaction-set-output%E5%BC%83%E7%94%A8%E9%94%99%E8%AF%AF.html","summary":"githubAction set-output 弃用错误 The set-output command is deprecated and will be disabled soon. Please upgrade to using Environment Files. For more information see: https://github.blog/changelog/2022-10-11-github-actions-deprecating-save-state-and-set-output-commands/\n原因 如果您有一个使用 设置输出的GitHub Actionsecho ::set-output key=value工作流程，您已经开始看到无用的弃用警告。这是修复它的方法。查看官方链接基本上得不到什么帮助！\n修复方法 更新其它人的 action 方法 将 @actions/core 提升到 1.10.0 修改自己的 aciton 方法 run: echo \u0026#34;::set-output name=KEY::VALUE\u0026#34; ## 改为 run: echo \u0026#34;KEY=VALUE\u0026#34; \u0026gt;\u0026gt;$GITHUB_OUTPUT 建议：使用自己的方法\n总结 平台经营者非常肆意妄为的修改自己的代码内容弃用功能，无限的权力滋生傲慢……我相信大部分开发这并没有注意到这个告警，知道流水线服务报错之后才会注意到，希望微软可以对能更加包容不同的开发者，尊重开发者社区。","title":"githubAction set-output弃用错误"},{"content":"背景 有很多朋友问我什么是 web3.0，web3.0 似乎离我们非常远。有人会说 web3.0 是未来下一代的技术很有前景！但是举出一个具体的例子，似乎又非常困难。使用 web3.0 是一件非常高科技的事情。本文就是通过各 IPFS 给各位初学者和对 web3.0 感兴趣的人使用介绍，看完本篇文章，你就能进入 web3.0 的世界了~\nIPFS 星际文件系统(InterPlanetary File System). IPFS 是一个分布式的 web, 点到点超媒体协议. 可以让我们的互联网速度更快, 更加安全, 并且更加开放. IPFS协议的目标是取代传统的互联网协议HTTP\n下载安装 本文不会对技术做更深入探讨，只在应用层面上介绍\n下载 官网\n下载 windows\n下载 MAC\n安装 运行 .exe 文件开始安装，选择是要为您自己还是为计算机上的所有用户安装应用程序。点击下一步：\n选择应用程序的安装位置。默认位置通常很好。点击下一步：\n等待安装完成，然后单击完成：\n您现在可以在状态栏中找到 IPFS 图标：\n使用 打开软件 可以正常使用了！是不是很简单接下来浏览器直接查看 web3.0 站点 站点 我的 web3.0 blog： ipfs.jobcher.com\n对标 youdTube 的视频网站: d.tube\nOrbit，QQ 在 IPFS 上的替代者: orbit.chat\nAkasha，对标 facebook，微信等社交工具：akasha.world\n","permalink":"https://test.jobcher.com/%E6%89%93%E5%BC%80web-3.0%E7%9A%84%E5%A4%A7%E9%97%A8ipfs%E4%BD%BF%E7%94%A8.html","summary":"背景 有很多朋友问我什么是 web3.0，web3.0 似乎离我们非常远。有人会说 web3.0 是未来下一代的技术很有前景！但是举出一个具体的例子，似乎又非常困难。使用 web3.0 是一件非常高科技的事情。本文就是通过各 IPFS 给各位初学者和对 web3.0 感兴趣的人使用介绍，看完本篇文章，你就能进入 web3.0 的世界了~\nIPFS 星际文件系统(InterPlanetary File System). IPFS 是一个分布式的 web, 点到点超媒体协议. 可以让我们的互联网速度更快, 更加安全, 并且更加开放. IPFS协议的目标是取代传统的互联网协议HTTP\n下载安装 本文不会对技术做更深入探讨，只在应用层面上介绍\n下载 官网\n下载 windows\n下载 MAC\n安装 运行 .exe 文件开始安装，选择是要为您自己还是为计算机上的所有用户安装应用程序。点击下一步：\n选择应用程序的安装位置。默认位置通常很好。点击下一步：\n等待安装完成，然后单击完成：\n您现在可以在状态栏中找到 IPFS 图标：\n使用 打开软件 可以正常使用了！是不是很简单接下来浏览器直接查看 web3.0 站点 站点 我的 web3.0 blog： ipfs.jobcher.com\n对标 youdTube 的视频网站: d.tube\nOrbit，QQ 在 IPFS 上的替代者: orbit.chat\nAkasha，对标 facebook，微信等社交工具：akasha.world","title":"打开web 3.0的大门——IPFS使用"},{"content":"Rook 云存储介绍和部署 Rook 将分布式存储软件转变为自我管理，自我缩放和自我修复的存储服务。它通过自动化部署，引导、配置、供应、扩展、升级、迁移、灾难恢复、监控和资源管理来实现。 Rook 使用基础的云原生容器管理、调度和编排平台提供的功能来履行其职责。\nRook 利用扩展点深入融入云原生环境，为调度、生命周期管理、资源管理、安全性、监控和用户体验提供无缝体验。\n部署 使用 helm 部署 helm init -i jimmysong/kubernetes-helm-tiller:v2.8.1 helm repo add rook-alpha https://charts.rook.io/alpha helm install rook-alpha/rook --name rook --namespace rook-system 直接使用 yaml 文件部署 kubectl apply -f rook-operator.yaml 不论使用那种方式部署的 rook operator，都会在 rook-agent 中看到 rook-agent 用户无法列出集群中某些资源的错误，可以通过为 rook-agent 的分配 cluster-admin 权限临时解决，详见 Issue 1472。\n使用如下 yaml 文件创建一个 ClusterRoleBinding 并应用到集群中。\nkind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: rookagent-clusterrolebinding subjects: - kind: ServiceAccount name: rook-agent namespace: rook-system roleRef: kind: ClusterRole name: cluster-admin apiGroup: \u0026amp;#34;\u0026amp;#34; 部署 rook cluster 创建完 rook operator 后，我们再部署 rook cluster。\napiVersion: v1 kind: Namespace metadata: name: rook --- apiVersion: rook.io/v1alpha1 kind: Cluster metadata:","permalink":"https://test.jobcher.com/kubernetes-rook%E4%BA%91%E5%AD%98%E5%82%A8%E4%BB%8B%E7%BB%8D%E5%92%8C%E9%83%A8%E7%BD%B2.html","summary":"Rook 云存储介绍和部署 Rook 将分布式存储软件转变为自我管理，自我缩放和自我修复的存储服务。它通过自动化部署，引导、配置、供应、扩展、升级、迁移、灾难恢复、监控和资源管理来实现。 Rook 使用基础的云原生容器管理、调度和编排平台提供的功能来履行其职责。\nRook 利用扩展点深入融入云原生环境，为调度、生命周期管理、资源管理、安全性、监控和用户体验提供无缝体验。\n部署 使用 helm 部署 helm init -i jimmysong/kubernetes-helm-tiller:v2.8.1 helm repo add rook-alpha https://charts.rook.io/alpha helm install rook-alpha/rook --name rook --namespace rook-system 直接使用 yaml 文件部署 kubectl apply -f rook-operator.yaml 不论使用那种方式部署的 rook operator，都会在 rook-agent 中看到 rook-agent 用户无法列出集群中某些资源的错误，可以通过为 rook-agent 的分配 cluster-admin 权限临时解决，详见 Issue 1472。\n使用如下 yaml 文件创建一个 ClusterRoleBinding 并应用到集群中。\nkind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: rookagent-clusterrolebinding subjects: - kind: ServiceAccount name: rook-agent namespace: rook-system roleRef: kind: ClusterRole name: cluster-admin apiGroup: \u0026#34;\u0026#34; 部署 rook cluster 创建完 rook operator 后，我们再部署 rook cluster。","title":"Kubernetes — Rook云存储介绍和部署"},{"content":"基于 K8S 搭建 Ceph 分布式存储 前提 正常运行的多节点 K8S 集群，可以是两个节点也可以是更多。 每一个节点需要一个没有被分区的硬盘，最好大小一致不然会浪费。 没错其实就是一个要求，必须有集群才能进行容器管理，必须有硬盘才能做存储这些都是基础。 添加硬盘 主机 IP 磁盘 master01 10.12.12.51 SATA 20G master02 10.12.12.52 SATA 20G master03 10.12.12.53 SATA 20G worker01 10.12.12.54 SATA 20G worker02 10.12.12.55 SATA 20G 在 5 个节点都加 20g 存储\n重启 k8s 节点 kubectl cordon \u0026amp;lt;节点\u0026amp;gt; kubectl drain \u0026amp;lt;节点\u0026amp;gt; --ignore-daemonsets --delete-emptydir-data # 虚拟机重启后 kubectl uncordon \u0026amp;lt;节点\u0026amp;gt; 查看新增存储 fdisk -l 看到新增 20g 存储,不要格式化分区硬盘！！！\nDisk /dev/sdb: 20 GiB, 21474836480 bytes, 41943040 sectors Disk model: QEMU HARDDISK Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes ROOK 自动创建 Rook 是一个开源的cloud-native storage编排, 提供平台和框架；为各种存储解决方案提供平台、框架和支持，以便与云原生环境本地集成。 Rook 将存储软件转变为自我管理、自我扩展和自我修复的存储服务，它通过自动化部署、引导、配置、置备、扩展、升级、迁移、灾难恢复、监控和资源管理来实现此目的。 Rook 使用底层云本机容器管理、调度和编排平台提供的工具来实现它自身的功能。 Rook 目前支持Ceph、NFS、Minio Object Store和CockroachDB。 Rook 使用Kubernetes原语使Ceph存储系统能够在Kubernetes上运行。","permalink":"https://test.jobcher.com/kubernetes-%E5%9F%BA%E4%BA%8Ek8s%E6%90%AD%E5%BB%BAceph%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8.html","summary":"基于 K8S 搭建 Ceph 分布式存储 前提 正常运行的多节点 K8S 集群，可以是两个节点也可以是更多。 每一个节点需要一个没有被分区的硬盘，最好大小一致不然会浪费。 没错其实就是一个要求，必须有集群才能进行容器管理，必须有硬盘才能做存储这些都是基础。 添加硬盘 主机 IP 磁盘 master01 10.12.12.51 SATA 20G master02 10.12.12.52 SATA 20G master03 10.12.12.53 SATA 20G worker01 10.12.12.54 SATA 20G worker02 10.12.12.55 SATA 20G 在 5 个节点都加 20g 存储\n重启 k8s 节点 kubectl cordon \u0026lt;节点\u0026gt; kubectl drain \u0026lt;节点\u0026gt; --ignore-daemonsets --delete-emptydir-data # 虚拟机重启后 kubectl uncordon \u0026lt;节点\u0026gt; 查看新增存储 fdisk -l 看到新增 20g 存储,不要格式化分区硬盘！！！\nDisk /dev/sdb: 20 GiB, 21474836480 bytes, 41943040 sectors Disk model: QEMU HARDDISK Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes ROOK 自动创建 Rook 是一个开源的cloud-native storage编排, 提供平台和框架；为各种存储解决方案提供平台、框架和支持，以便与云原生环境本地集成。 Rook 将存储软件转变为自我管理、自我扩展和自我修复的存储服务，它通过自动化部署、引导、配置、置备、扩展、升级、迁移、灾难恢复、监控和资源管理来实现此目的。 Rook 使用底层云本机容器管理、调度和编排平台提供的工具来实现它自身的功能。 Rook 目前支持Ceph、NFS、Minio Object Store和CockroachDB。 Rook 使用Kubernetes原语使Ceph存储系统能够在Kubernetes上运行。","title":"Kubernetes — 基于K8S搭建Ceph分布式存储"},{"content":"Kubernetes — 探针和生命周期 用于判断容器内应用程序是否已经启动。\n存活（Liveness）探针 用于探测容器是否运行，如果探测失败，kubelet 会根据配置的重启策略进行相应的处理，若没有配置探针该返回值默认为 success 就绪（Readiness）探针 用于探测容器内的程序是否健康，如果返回值为 success，那么代表这个容器已经完全启动，并且程序已经是可以接受流量的状态 启动（Startup）探针 用于探测容器是否启动，如果配置了 startup 就会先禁止其他探测，直到它成功，成功后将不在运行探测 Pod 检测方式 ExecAction：在容器执行一个命令，返回值为 0，则认为容器健康 TCPSocketAction：通过 TCP 连接检查容器是否联通，通的话，则认为容器正常 HTTPGetAction：通过应用程序暴露的 API 地址来检查程序是否正常的，如果状态码为 200-400 之间，则认为容器健康 gRPCAction：通过 gRPC 的检查机制，判断容器是不是正常 StartupProbe 启动探针 有时候，会有一些现有的应用在启动时需要较长的初始化时间。 要这种情况下，若要不影响对死锁作出快速响应的探测，设置存活探测参数是要技巧的。 技巧就是使用相同的命令来设置启动探测，针对 HTTP 或 TCP 检测，可以通过将 failureThreshold * periodSeconds 参数设置为足够长的时间来应对糟糕情况下的启动时间。\nports: - name: liveness-port containerPort: 8080 hostPort: 8080 livenessProbe: httpGet: path: /healthz port: liveness-port failureThreshold: 1 periodSeconds: 10 startupProbe: httpGet: path: /healthz port: liveness-port failureThreshold: 30 periodSeconds: 10 幸亏有启动探测，应用程序将会有最多 5 分钟（30 * 10 = 300s）的时间来完成其启动过程。 一旦启动探测成功一次，存活探测任务就会接管对容器的探测，对容器死锁作出快速响应。 如果启动探测一直没有成功，容器会在 300 秒后被杀","permalink":"https://test.jobcher.com/kubernetes-%E6%8E%A2%E9%92%88%E5%92%8C%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.html","summary":"Kubernetes — 探针和生命周期 用于判断容器内应用程序是否已经启动。\n存活（Liveness）探针 用于探测容器是否运行，如果探测失败，kubelet 会根据配置的重启策略进行相应的处理，若没有配置探针该返回值默认为 success 就绪（Readiness）探针 用于探测容器内的程序是否健康，如果返回值为 success，那么代表这个容器已经完全启动，并且程序已经是可以接受流量的状态 启动（Startup）探针 用于探测容器是否启动，如果配置了 startup 就会先禁止其他探测，直到它成功，成功后将不在运行探测 Pod 检测方式 ExecAction：在容器执行一个命令，返回值为 0，则认为容器健康 TCPSocketAction：通过 TCP 连接检查容器是否联通，通的话，则认为容器正常 HTTPGetAction：通过应用程序暴露的 API 地址来检查程序是否正常的，如果状态码为 200-400 之间，则认为容器健康 gRPCAction：通过 gRPC 的检查机制，判断容器是不是正常 StartupProbe 启动探针 有时候，会有一些现有的应用在启动时需要较长的初始化时间。 要这种情况下，若要不影响对死锁作出快速响应的探测，设置存活探测参数是要技巧的。 技巧就是使用相同的命令来设置启动探测，针对 HTTP 或 TCP 检测，可以通过将 failureThreshold * periodSeconds 参数设置为足够长的时间来应对糟糕情况下的启动时间。\nports: - name: liveness-port containerPort: 8080 hostPort: 8080 livenessProbe: httpGet: path: /healthz port: liveness-port failureThreshold: 1 periodSeconds: 10 startupProbe: httpGet: path: /healthz port: liveness-port failureThreshold: 30 periodSeconds: 10 幸亏有启动探测，应用程序将会有最多 5 分钟（30 * 10 = 300s）的时间来完成其启动过程。 一旦启动探测成功一次，存活探测任务就会接管对容器的探测，对容器死锁作出快速响应。 如果启动探测一直没有成功，容器会在 300 秒后被杀","title":"Kubernetes — 探针和生命周期"},{"content":"windows-exporter 监控安装 windows_exporter 下载安装 启动 下载 msi 版本，输入一下命令启动\nmsiexec /i C:\\Users\\Administrator\\Downloads\\windows_exporter.msi ENABLED_COLLECTORS=\u0026amp;#34;ad,iis,logon,memory,process,tcp,scheduled_task\u0026amp;#34; TEXTFILE_DIR=\u0026amp;#34;C:\\custom_metrics\\\u0026amp;#34; 卸载\nmsiexec /uninstall C:\\Users\\Administrator\\Downloads\\windows_exporter.msi 添加 prometheus 监控 prometheus.yaml\n# 新增 windows-exporter - job_name: \u0026amp;#34;windows-exporter\u0026amp;#34; file_sd_configs: - files: - \u0026amp;#34;./file_sd/windows-exporter.yaml\u0026amp;#34; ./file_sd/windows-exporter.yaml\n# 新增 windows-exporter - targets: [\u0026amp;#34;192.168.0.6:9182\u0026amp;#34;] labels: instance: windows-task 添加 alertmanager 告警 # 告警信息 groups: - name: sanjiang windows 任务计划程序告警 rules: - alert: windows实例任务告警 expr: windows_scheduled_task_state{state=\u0026amp;#34;disabled\u0026amp;#34;,task=~\u0026amp;#34;/ETL_kettle_tasks/.*\u0026amp;#34;}==1 for: 30s labels: severity: critical target: \u0026amp;#34;{{$labels.job}}\u0026amp;#34; annotations: summary: \u0026amp;#34;sanjiang: {{$labels.job}} windows 任务异常\u0026amp;#34; description: \u0026amp;#34;{{$labels.task}} of job {{$labels.job}} 该任务断联已超过1分","permalink":"https://test.jobcher.com/windows-exporter-%E7%9B%91%E6%8E%A7.html","summary":"windows-exporter 监控安装 windows_exporter 下载安装 启动 下载 msi 版本，输入一下命令启动\nmsiexec /i C:\\Users\\Administrator\\Downloads\\windows_exporter.msi ENABLED_COLLECTORS=\u0026#34;ad,iis,logon,memory,process,tcp,scheduled_task\u0026#34; TEXTFILE_DIR=\u0026#34;C:\\custom_metrics\\\u0026#34; 卸载\nmsiexec /uninstall C:\\Users\\Administrator\\Downloads\\windows_exporter.msi 添加 prometheus 监控 prometheus.yaml\n# 新增 windows-exporter - job_name: \u0026#34;windows-exporter\u0026#34; file_sd_configs: - files: - \u0026#34;./file_sd/windows-exporter.yaml\u0026#34; ./file_sd/windows-exporter.yaml\n# 新增 windows-exporter - targets: [\u0026#34;192.168.0.6:9182\u0026#34;] labels: instance: windows-task 添加 alertmanager 告警 # 告警信息 groups: - name: sanjiang windows 任务计划程序告警 rules: - alert: windows实例任务告警 expr: windows_scheduled_task_state{state=\u0026#34;disabled\u0026#34;,task=~\u0026#34;/ETL_kettle_tasks/.*\u0026#34;}==1 for: 30s labels: severity: critical target: \u0026#34;{{$labels.job}}\u0026#34; annotations: summary: \u0026#34;sanjiang: {{$labels.job}} windows 任务异常\u0026#34; description: \u0026#34;{{$labels.","title":"windows-exporter 监控"},{"content":"Kubernetes — 开放标准（OCI、CRI、CNI、CSI、SMI、CPI）概述 什么是 Kubernetes 开放标准？— K8s 开放标准简介\n开放标准有助于和补充像 Kubernetes 这样的系统，Kubernetes 是用于编排容器的事实上的标准平台。开放标准定义了实施 Kubernetes 的最佳实践，并在支持此实施方面发挥着至关重要的作用。开放标准由开源 Kubernetes 社区而非某个特定供应商制定，以确保更高的效率、避免供应商锁定以及更轻松地将其他软件集成到技术堆栈中。\nOCI 容器开放接口规范，由多家公司共同组成于 2015 年 6 月成立的项目（Docker, Google, CoreOS 等公司），并由 Linux 基金会运行管理，旨在围绕容器格式和运行时制定一个开放的工业化标准，目前主要有两个标准文档：容器运行时标准 （runtime spec）和 容器镜像标准（image spec）\nOCI 是一个开放的治理结构，其明确目的是围绕容器格式和运行时创建开放的行业标准。 它提供了必须由容器运行时引擎实现的规范。两个重要的规格是： runC：种子容器运行时引擎。大多数现代容器运行时环境都使用 runC 并围绕这个种子引擎开发附加功能。 这种低级运行时用于启动容器的各种工具，包括 Docker 本身。 OCI 规范：关于如何运行、构建和分发容器的映像、运行时和分发规范。 虽然 Docker 经常与容器技术同步使用，但社区一直致力于 OCI 的开放行业标准。 Image-Spec image-spec 定义了如何构建和打包容器镜像。 本规范的目标是创建可互操作的工具，用于构建、传输和准备要运行的容器映像。 Runtime-Spec runtime-spec 指定容器的配置、执行环境和生命周期。 这概述了如何运行在磁盘上解压的“文件系统包(filesystem bundle)”。概括地说，OCI 实现会下载一个 OCI 映像，然后将该映像解压缩到一个 OCI 运行时文件系统包中。 Distribution-Spec Distribution-Spec 提供了一个标准，用于一般内容的分发，特别是容器图像的分发。它是 OCI 项目的最新补充。 实现分发规范的容器注册表为容器映像提供可靠、高度可扩展、安全的存储服务。 客户要么使用云提供商实施、供应商实施，要么使用分发的开源实施。\nCRI","permalink":"https://test.jobcher.com/kubernetes-%E5%BC%80%E6%94%BE%E6%A0%87%E5%87%86ocicricnicsismicpi%E6%A6%82%E8%BF%B0.html","summary":"Kubernetes — 开放标准（OCI、CRI、CNI、CSI、SMI、CPI）概述 什么是 Kubernetes 开放标准？— K8s 开放标准简介\n开放标准有助于和补充像 Kubernetes 这样的系统，Kubernetes 是用于编排容器的事实上的标准平台。开放标准定义了实施 Kubernetes 的最佳实践，并在支持此实施方面发挥着至关重要的作用。开放标准由开源 Kubernetes 社区而非某个特定供应商制定，以确保更高的效率、避免供应商锁定以及更轻松地将其他软件集成到技术堆栈中。\nOCI 容器开放接口规范，由多家公司共同组成于 2015 年 6 月成立的项目（Docker, Google, CoreOS 等公司），并由 Linux 基金会运行管理，旨在围绕容器格式和运行时制定一个开放的工业化标准，目前主要有两个标准文档：容器运行时标准 （runtime spec）和 容器镜像标准（image spec）\nOCI 是一个开放的治理结构，其明确目的是围绕容器格式和运行时创建开放的行业标准。 它提供了必须由容器运行时引擎实现的规范。两个重要的规格是： runC：种子容器运行时引擎。大多数现代容器运行时环境都使用 runC 并围绕这个种子引擎开发附加功能。 这种低级运行时用于启动容器的各种工具，包括 Docker 本身。 OCI 规范：关于如何运行、构建和分发容器的映像、运行时和分发规范。 虽然 Docker 经常与容器技术同步使用，但社区一直致力于 OCI 的开放行业标准。 Image-Spec image-spec 定义了如何构建和打包容器镜像。 本规范的目标是创建可互操作的工具，用于构建、传输和准备要运行的容器映像。 Runtime-Spec runtime-spec 指定容器的配置、执行环境和生命周期。 这概述了如何运行在磁盘上解压的“文件系统包(filesystem bundle)”。概括地说，OCI 实现会下载一个 OCI 映像，然后将该映像解压缩到一个 OCI 运行时文件系统包中。 Distribution-Spec Distribution-Spec 提供了一个标准，用于一般内容的分发，特别是容器图像的分发。它是 OCI 项目的最新补充。 实现分发规范的容器注册表为容器映像提供可靠、高度可扩展、安全的存储服务。 客户要么使用云提供商实施、供应商实施，要么使用分发的开源实施。\nCRI","title":"Kubernetes — 开放标准（OCI、CRI、CNI、CSI、SMI、CPI）概述"},{"content":"k8s 部署插件 Kubernetes 是高度可配置且可扩展的。因此，大多数情况下， 你不需要派生自己的 Kubernetes 副本或者向项目代码提交补丁，本文会介绍几种常用的 k8s 插件，如果大家喜欢的话，希望大家点赞支持。\n1. Flannel 网络插件 Flannel是由 go 语言开发，是一种基于 Overlay 网络的跨主机容器网络解决方案，也就是将TCP数据包封装在另一种网络包里面进行路由转发和通信，Flannel 是 CoreOS 开发，专门用于 docker 多主机互联的一个工具，简单来说，它的功能是让集群中的不同节点主机创建的容器都具有全局唯一的虚拟IP地址\n主要功能：\n为每个 node 分配 subnet，容器将自动从该子网中获取 IP 地址 当有 node 加入到网络中时，为每个 node 增加路由配置 下载并安装 wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml 如果 yml 中的\u0026amp;quot;Network\u0026amp;quot;: 10.244.0.0/16和kubeadm init xxx --pod-network-cidr不一样，就需要修改成一样的。不然可能会使得Node间Cluster IP不通。\n2. Ingress Controller Ingress 是对集群中服务的外部访问进行管理的 API 对象，典型的访问方式是 HTTP。\nIngress 可以提供负载均衡、SSL 终结和基于名称的虚拟托管\n下面是一个将所有流量都发送到同一 Service 的简单 Ingress 示例：\nIngress 可为 Service 提供外部可访问的 URL、负载均衡流量、终止 SSL/TLS，以及基于名称的虚拟托管。 Ingress 控制器 通常负责通过负载均衡器来实现 Ingress，尽管它也可以配置边缘路由器或其他前端来帮助处理流量。\nIngress 不会公开任意端口或协议。 将 HTTP 和 HTTPS 以外的服务公开到 Internet 时，通常使用 Service.Type=NodePort 或 Service.Type=LoadBalancer 类型的 Service","permalink":"https://test.jobcher.com/kubernetes-%E9%83%A8%E7%BD%B2%E6%8F%92%E4%BB%B6-flannelweb-uicorednsingress-controller.html","summary":"k8s 部署插件 Kubernetes 是高度可配置且可扩展的。因此，大多数情况下， 你不需要派生自己的 Kubernetes 副本或者向项目代码提交补丁，本文会介绍几种常用的 k8s 插件，如果大家喜欢的话，希望大家点赞支持。\n1. Flannel 网络插件 Flannel是由 go 语言开发，是一种基于 Overlay 网络的跨主机容器网络解决方案，也就是将TCP数据包封装在另一种网络包里面进行路由转发和通信，Flannel 是 CoreOS 开发，专门用于 docker 多主机互联的一个工具，简单来说，它的功能是让集群中的不同节点主机创建的容器都具有全局唯一的虚拟IP地址\n主要功能：\n为每个 node 分配 subnet，容器将自动从该子网中获取 IP 地址 当有 node 加入到网络中时，为每个 node 增加路由配置 下载并安装 wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml 如果 yml 中的\u0026quot;Network\u0026quot;: 10.244.0.0/16和kubeadm init xxx --pod-network-cidr不一样，就需要修改成一样的。不然可能会使得Node间Cluster IP不通。\n2. Ingress Controller Ingress 是对集群中服务的外部访问进行管理的 API 对象，典型的访问方式是 HTTP。\nIngress 可以提供负载均衡、SSL 终结和基于名称的虚拟托管\n下面是一个将所有流量都发送到同一 Service 的简单 Ingress 示例：\nIngress 可为 Service 提供外部可访问的 URL、负载均衡流量、终止 SSL/TLS，以及基于名称的虚拟托管。 Ingress 控制器 通常负责通过负载均衡器来实现 Ingress，尽管它也可以配置边缘路由器或其他前端来帮助处理流量。","title":"kubernetes 部署插件 (Flannel、Web UI、CoreDNS、Ingress Controller)"},{"content":"Cloudflare Zero Trust 内网穿透 最快的 Zero Trust 应用访问和互联网浏览平台\n增加可见性，消除复杂性，降低远程和办公室用户的风险。杜绝数据丢失、恶意软件和网络钓鱼，保护用户、应用程序和设备安全。\n使用 Tunnel 隧道来实现内网传统，实现内网访问各类应用\n安装部署 https://dash.teams.cloudflare.com/\nDocker 部署 在 docker 环境运行 \u0026amp;lt;token\u0026amp;gt; 是你个人令牌\ndocker run -d --name cloudflared cloudflare/cloudflared:latest tunnel --no-autoupdate run --token \u0026amp;lt;token\u0026amp;gt; Linux 部署 X86-64 位 curl -L --output cloudflared.rpm https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-x86_64.rpm \u0026amp;amp;\u0026amp;amp; \\ sudo yum localinstall -y cloudflared.rpm \u0026amp;amp;\u0026amp;amp; \\ sudo cloudflared service install \u0026amp;lt;token\u0026amp;gt; X86-32 位 curl -L --output cloudflared.rpm https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-386.rpm \u0026amp;amp;\u0026amp;amp; sudo yum localinstall -y cloudflared.rpm \u0026amp;amp;\u0026amp;amp; sudo cloudflared service install \u0026amp;lt;token\u0026amp;gt; arm64 curl -L --output cloudflared.rpm https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-aarch64.rpm \u0026amp;amp;\u0026amp;amp; sudo yum localinstall -y","permalink":"https://test.jobcher.com/cloudflare-zero-trust-%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F.html","summary":"Cloudflare Zero Trust 内网穿透 最快的 Zero Trust 应用访问和互联网浏览平台\n增加可见性，消除复杂性，降低远程和办公室用户的风险。杜绝数据丢失、恶意软件和网络钓鱼，保护用户、应用程序和设备安全。\n使用 Tunnel 隧道来实现内网传统，实现内网访问各类应用\n安装部署 https://dash.teams.cloudflare.com/\nDocker 部署 在 docker 环境运行 \u0026lt;token\u0026gt; 是你个人令牌\ndocker run -d --name cloudflared cloudflare/cloudflared:latest tunnel --no-autoupdate run --token \u0026lt;token\u0026gt; Linux 部署 X86-64 位 curl -L --output cloudflared.rpm https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-x86_64.rpm \u0026amp;\u0026amp; \\ sudo yum localinstall -y cloudflared.rpm \u0026amp;\u0026amp; \\ sudo cloudflared service install \u0026lt;token\u0026gt; X86-32 位 curl -L --output cloudflared.rpm https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-386.rpm \u0026amp;\u0026amp; sudo yum localinstall -y cloudflared.rpm \u0026amp;\u0026amp; sudo cloudflared service install \u0026lt;token\u0026gt; arm64 curl -L --output cloudflared.","title":"Cloudflare Zero Trust 内网穿透"},{"content":"苏州旅行 苏州，古称吴，现简称苏，是中华人民共和国江苏省东南部的一个地级市，位于长江三角洲和太湖平原的中心地带，著名的鱼米之乡、状元之乡、院士之乡、经济重镇、历史文化名城，自古与杭州共享有“上有天堂、下有苏杭”美誉。\n苏州景点 day1 金鸡湖 苏州金鸡湖，是国家5A级景区，但却是免费开放的。湖东与湖西高楼林立，展现了苏州现代的一面。夜晚，灯光璀璨，如群星般夺目；霓虹闪烁，如银河般绚烂~ 金鸡湖十景 苏州中心 东方之门 音乐喷泉 金鸡湖大桥 文化艺术中心 月光码头 诚品书店 国金中心 望湖角 李公堤 day2 苏州博物馆 地址：姑苏区东北街204号 交通：乘坐游1、游2、游5、55、178、202、309、313、518、529路等到苏州博物馆 门票：免费(可在官网提前预约) 开放时间：每星期二至星期日- 9:00~17:00（16:00停止入馆） ◆建议用时：2-3小时 拙政园 拙政园和苏州博物馆紧临，两者之间步行不会超过3分钟，而平江路是在拙政园的南门沿着门前的东北街往东走，大约在150米处右转过桥就是了，因此可以把这三处安排在同一天，建议游览顺序是拙政园—苏州博物馆—平江路。 淡季（1、2、3、6、11、12月）：70元 旺季（4、5、7、8、9、10月）：90元 day3 虎丘 地址：姑苏区山塘街虎丘山门内8号 交通：南门入口：146、游1、游2路虎丘首末站；北门入口：32、快线3号虎丘北门站 门票：淡季：60.00元 旺季：80.00元 开放时间： 7:30-17:30/17：00 建议用时：2-3小时 苏州美食 饭店 苏帮菜——浓油赤酱里的姑苏风情 鲃肺汤是取生长于太湖一带的鲃鱼，将其肉与肝加入火腿、香菇、笋片等辅料，在鸡汤中共同熬煮，汤鲜味美，是一道不可多得的汤品。 酱方是采用上乘猪五花为原料，经 24 小时腌制后，加入卤汁炖煮 3 小时而成。肉的色泽鲜亮诱人，入口外皮 Q 弹、肉质紧实。 响油鳝糊是以将新鲜鳝鱼切成段，加酱油等佐料爆炒。因鳝糊上桌时油滋滋作响，而得名“响油鳝糊”。菜色深红，口味鲜甜，油而不腻。 樱桃肉因肉形状及色泽极似樱桃而得名，是将优质的五花肉切成小块，以文火炖煮七八小时而成。肥而不腻，满口精华。 松鼠鳜鱼是将鳜鱼在油锅内炸至金黄，再淋上由番茄酱等熬制的酱汁而成。因炸开的鱼肉形似松鼠而得名，入口酥脆酸甜。 碧螺虾仁是将新鲜虾仁配以碧螺春为佐料烹制而成，色泽清淡雅致，虾肉饱满 Q ","permalink":"https://test.jobcher.com/%E8%8B%8F%E5%B7%9E%E6%97%85%E8%A1%8C.html","summary":"苏州旅行 苏州，古称吴，现简称苏，是中华人民共和国江苏省东南部的一个地级市，位于长江三角洲和太湖平原的中心地带，著名的鱼米之乡、状元之乡、院士之乡、经济重镇、历史文化名城，自古与杭州共享有“上有天堂、下有苏杭”美誉。\n苏州景点 day1 金鸡湖 苏州金鸡湖，是国家5A级景区，但却是免费开放的。湖东与湖西高楼林立，展现了苏州现代的一面。夜晚，灯光璀璨，如群星般夺目；霓虹闪烁，如银河般绚烂~ 金鸡湖十景 苏州中心 东方之门 音乐喷泉 金鸡湖大桥 文化艺术中心 月光码头 诚品书店 国金中心 望湖角 李公堤 day2 苏州博物馆 地址：姑苏区东北街204号 交通：乘坐游1、游2、游5、55、178、202、309、313、518、529路等到苏州博物馆 门票：免费(可在官网提前预约) 开放时间：每星期二至星期日- 9:00~17:00（16:00停止入馆） ◆建议用时：2-3小时 拙政园 拙政园和苏州博物馆紧临，两者之间步行不会超过3分钟，而平江路是在拙政园的南门沿着门前的东北街往东走，大约在150米处右转过桥就是了，因此可以把这三处安排在同一天，建议游览顺序是拙政园—苏州博物馆—平江路。 淡季（1、2、3、6、11、12月）：70元 旺季（4、5、7、8、9、10月）：90元 day3 虎丘 地址：姑苏区山塘街虎丘山门内8号 交通：南门入口：146、游1、游2路虎丘首末站；北门入口：32、快线3号虎丘北门站 门票：淡季：60.00元 旺季：80.00元 开放时间： 7:30-17:30/17：00 建议用时：2-3小时 苏州美食 饭店 苏帮菜——浓油赤酱里的姑苏风情 鲃肺汤是取生长于太湖一带的鲃鱼，将其肉与肝加入火腿、香菇、笋片等辅料，在鸡汤中共同熬煮，汤鲜味美，是一道不可多得的汤品。 酱方是采用上乘猪五花为原料，经 24 小时腌制后，加入卤汁炖煮 3 小时而成。肉的色泽鲜亮诱人，入口外皮 Q 弹、肉质紧实。 响油鳝糊是以将新鲜鳝鱼切成段，加酱油等佐料爆炒。因鳝糊上桌时油滋滋作响，而得名“响油鳝糊”。菜色深红，口味鲜甜，油而不腻。 樱桃肉因肉形状及色泽极似樱桃而得名，是将优质的五花肉切成小块，以文火炖煮七八小时而成。肥而不腻，满口精华。 松鼠鳜鱼是将鳜鱼在油锅内炸至金黄，再淋上由番茄酱等熬制的酱汁而成。因炸开的鱼肉形似松鼠而得名，入口酥脆酸甜。 碧螺虾仁是将新鲜虾仁配以碧螺春为佐料烹制而成，色泽清淡雅致，虾肉饱满 Q ","title":"苏州旅行"},{"content":"【主料】 精排骨（500 克） 【辅料】 食用面碱（约 2 克） 柠檬（半个） 生姜（1 小块） 小葱（2 根） 八角（1 颗） 桂皮（1 小块） 香叶（半片） 冰糖（约 50 克） 可乐（1000 克） 【调味料】 食用盐（适量） 料酒（适量） 生抽酱油（20 克） ","permalink":"https://test.jobcher.com/%E6%87%92%E4%BA%BA%E7%83%A7%E6%8E%92%E9%AA%A8.html","summary":"【主料】 精排骨（500 克） 【辅料】 食用面碱（约 2 克） 柠檬（半个） 生姜（1 小块） 小葱（2 根） 八角（1 颗） 桂皮（1 小块） 香叶（半片） 冰糖（约 50 克） 可乐（1000 克） 【调味料】 食用盐（适量） 料酒（适量） 生抽酱油（20 克） ","title":"懒人烧排骨"},{"content":"k8s CNI 问题 连接认证失效 删除 calico 换成 flannel 后，容器没有正常启动\nnetwork: error getting ClusterInformation: connection is unauthorized: Unauthorized]\n解决问题 删除掉 /etc/cni/net.d/ 目录下的 calico 配置文件即可。\n要删除所有节点的配置文件\nsudo rm -rf /etc/cni/net.d/*calico* 不要重复网络插件 ","permalink":"https://test.jobcher.com/k8s-cni-%E9%97%AE%E9%A2%98-%E8%BF%9E%E6%8E%A5%E8%AE%A4%E8%AF%81%E5%A4%B1%E6%95%88.html","summary":"k8s CNI 问题 连接认证失效 删除 calico 换成 flannel 后，容器没有正常启动\nnetwork: error getting ClusterInformation: connection is unauthorized: Unauthorized]\n解决问题 删除掉 /etc/cni/net.d/ 目录下的 calico 配置文件即可。\n要删除所有节点的配置文件\nsudo rm -rf /etc/cni/net.d/*calico* 不要重复网络插件 ","title":"k8s CNI 问题 连接认证失效"},{"content":"k8s.gcr.io 国内无法连接解决方法 Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\n这个一看知道什么原因了，应该 GFW！那好吧，只能给 docker 加个代理了。\n解决问题 添加 mirror 站点\nregistry.cn-hangzhou.aliyuncs.com/google_containers ","permalink":"https://test.jobcher.com/k8s.gcr.io%E5%9B%BD%E5%86%85%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.html","summary":"k8s.gcr.io 国内无法连接解决方法 Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\n这个一看知道什么原因了，应该 GFW！那好吧，只能给 docker 加个代理了。\n解决问题 添加 mirror 站点\nregistry.cn-hangzhou.aliyuncs.com/google_containers ","title":"k8s.gcr.io国内无法连接解决方法"},{"content":"Golang 初识（安装、使用） Go 导学 go 语言由 google 公司推出。\n运行速度快，简单易学 适合区块链开发 拥有丰富指令 可以直接包含 C 语言 语言层面支持并发 Go 方向 网络编程 服务器编程 区块链开发 环境安装 安装环境 安装包下载\nhttps://golang.google.cn/dl/\nwindows 部署 wget https://golang.google.cn/dl/go1.19.1.windows-amd64.msi # 直接安装 GOPATH 设置 在环境变量 PATH 上直接配置安装地址\n编写第一个程序 package main import \u0026amp;#34;fmt\u0026amp;#34; func main() { fmt.Println(\u0026amp;#34;Hello World!\u0026amp;#34;) } ","permalink":"https://test.jobcher.com/golang-%E5%88%9D%E8%AF%86%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8.html","summary":"Golang 初识（安装、使用） Go 导学 go 语言由 google 公司推出。\n运行速度快，简单易学 适合区块链开发 拥有丰富指令 可以直接包含 C 语言 语言层面支持并发 Go 方向 网络编程 服务器编程 区块链开发 环境安装 安装环境 安装包下载\nhttps://golang.google.cn/dl/\nwindows 部署 wget https://golang.google.cn/dl/go1.19.1.windows-amd64.msi # 直接安装 GOPATH 设置 在环境变量 PATH 上直接配置安装地址\n编写第一个程序 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello World!\u0026#34;) } ","title":"Golang 初识（安装、使用）"},{"content":"Headscale Tailscale 的控制服务器是不开源的，而且对免费用户有诸多限制，这是人家的摇钱树，可以理解。好在目前有一款开源的实现叫 Headscale，这也是唯一的一款，希望能发展壮大。\nHeadscale 由欧洲航天局的 Juan Font 使用 Go 语言开发，在 BSD 许可下发布，实现了 Tailscale 控制服务器的所有主要功能，可以部署在企业内部，没有任何设备数量的限制，且所有的网络流量都由自己控制。\nHeadscale 部署 我决定使用docker-compose进行部署\n创建存储 #!/bin/bash mkdir -p /opt/headscale mkdir -p ./config touch ./config/db.sqlite curl https://raw.githubusercontent.com/juanfont/headscale/main/config-example.yaml -o ./config/config.yaml 运行 docker-compose 文件 创建 docker-compose.yaml\nversion: \u0026amp;#34;3\u0026amp;#34; services: headscale: image: headscale/headscale:latest volumes: - ./config:/etc/headscale/ - ./data:/var/lib/headscale ports: - 8080:8080 - 9090:9090 - 50443:50443 command: headscale serve restart: unless-stopped 运行\ndocker-compose up -d\nHeadscale 使用 Linux 使用 wget https://pkgs.tailscale.com/stable/tailscale_1.22.2_amd64.tgz 解压\ntar zxvf tailscale_1.22.2_amd64.tgz 将二进制文件复制到官方软件包默认的路径下：\ncp tailscale_1.22.2_amd64/tailscaled /usr/sbin/tailscaled cp tailscale_1.22.2_amd64/tailscale /usr/bin/tailscale 将 systemD","permalink":"https://test.jobcher.com/headscale-%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8.html","summary":"Headscale Tailscale 的控制服务器是不开源的，而且对免费用户有诸多限制，这是人家的摇钱树，可以理解。好在目前有一款开源的实现叫 Headscale，这也是唯一的一款，希望能发展壮大。\nHeadscale 由欧洲航天局的 Juan Font 使用 Go 语言开发，在 BSD 许可下发布，实现了 Tailscale 控制服务器的所有主要功能，可以部署在企业内部，没有任何设备数量的限制，且所有的网络流量都由自己控制。\nHeadscale 部署 我决定使用docker-compose进行部署\n创建存储 #!/bin/bash mkdir -p /opt/headscale mkdir -p ./config touch ./config/db.sqlite curl https://raw.githubusercontent.com/juanfont/headscale/main/config-example.yaml -o ./config/config.yaml 运行 docker-compose 文件 创建 docker-compose.yaml\nversion: \u0026#34;3\u0026#34; services: headscale: image: headscale/headscale:latest volumes: - ./config:/etc/headscale/ - ./data:/var/lib/headscale ports: - 8080:8080 - 9090:9090 - 50443:50443 command: headscale serve restart: unless-stopped 运行\ndocker-compose up -d\nHeadscale 使用 Linux 使用 wget https://pkgs.tailscale.com/stable/tailscale_1.22.2_amd64.tgz 解压","title":"headscale 部署使用"},{"content":"清理 Docker 容器日志 如果 docker 容器正在运行，那么使用rm -rf方式删除日志后，通过df -h会发现磁盘空间并没有释放。原因是在 Linux 或者 Unix 系统中，通过rm -rf或者文件管理器删除文件，将会从文件系统的目录结构上解除链接（unlink）。如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用。正确姿势是cat /dev/null \u0026amp;gt; *-json.log，当然你也可以通过rm -rf删除后重启 docker。\n日志清理脚本 clean_docker_log.sh #!/bin/sh echo \u0026amp;#34;======== start clean docker containers logs ========\u0026amp;#34; logs=$(find /var/lib/docker/containers/ -name *-json.log) for log in $logs do echo \u0026amp;#34;clean logs : $log\u0026amp;#34; cat /dev/null \u0026amp;gt; $log done echo \u0026amp;#34;======== end clean docker containers logs ========\u0026amp;#34; chmod +x clean_docker_log.sh \u0026amp;amp;\u0026amp;amp; ./clean_docker_log.sh\n设置 Docker 容器日志大小 设置一个容器服务的日志大小上限\n上述方法，日志文件迟早又会涨回来。要从根本上解决问题，需要限制容器服务的日志大小上限。这个通过配置容器docker-compose的max-size选项来实现\nnginx: image: nginx:1.12.1 restart: always logging: driver: “json-file” options: max-size: “5g” 全局设置 新建/etc/docker/daemon.json，若有就不用新建了。添加log-dirver和log-opts参数\n# vim /etc/docker/daemon.json { \u0026amp;#34;log-driver\u0026amp;#34;:\u0026amp;#34;json-file\u0026amp;#34;, \u0026amp;#34;log-opts\u0026amp;#34;: {\u0026amp;#34;max-size\u0026amp;#34;:\u0026amp;#34;500m\u0026amp;#34;,","permalink":"https://test.jobcher.com/%E6%B8%85%E7%90%86docker%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97.html","summary":"清理 Docker 容器日志 如果 docker 容器正在运行，那么使用rm -rf方式删除日志后，通过df -h会发现磁盘空间并没有释放。原因是在 Linux 或者 Unix 系统中，通过rm -rf或者文件管理器删除文件，将会从文件系统的目录结构上解除链接（unlink）。如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用。正确姿势是cat /dev/null \u0026gt; *-json.log，当然你也可以通过rm -rf删除后重启 docker。\n日志清理脚本 clean_docker_log.sh #!/bin/sh echo \u0026#34;======== start clean docker containers logs ========\u0026#34; logs=$(find /var/lib/docker/containers/ -name *-json.log) for log in $logs do echo \u0026#34;clean logs : $log\u0026#34; cat /dev/null \u0026gt; $log done echo \u0026#34;======== end clean docker containers logs ========\u0026#34; chmod +x clean_docker_log.sh \u0026amp;\u0026amp; ./clean_docker_log.sh\n设置 Docker 容器日志大小 设置一个容器服务的日志大小上限\n上述方法，日志文件迟早又会涨回来。要从根本上解决问题，需要限制容器服务的日志大小上限。这个通过配置容器docker-compose的max-size选项来实现\nnginx: image: nginx:1.12.1 restart: always logging: driver: “json-file” options: max-size: “5g” 全局设置 新建/etc/docker/daemon.","title":"清理Docker容器日志"},{"content":"注意此教程需要通过电脑端完成\n操作步骤 1、微信打开羊了个羊小程序，玩第一关 2、进入当前登录的微信数据文件夹 微信左下角 -\u0026amp;gt; 设置 -\u0026amp;gt; 文件管理 -\u0026amp;gt; 打开文件夹\n打开后进入当前登录的微信数据文件夹\n3、进入当前登录微信数据文件夹后，依次进入 \\Applet\\wx141bfb9b73c970a9\\usr\\gamecaches\\resources\n注意 wx141bfb9b73c970a9 文件名可能不同，但以 a9 结尾\n4、修改游戏配置文件 在此文件夹下，有很多 json 文件，找到默认排序的第三个，大小 2k 的文件\n我的电脑是 16632884479734.json 文件，用记事本打开，清空里面内容，将 new.txt 文件中的代码复制进此 json 文件，","permalink":"https://test.jobcher.com/%E7%BE%8A%E4%BA%86%E4%B8%AA%E7%BE%8A%E5%B0%8F%E7%A8%8B%E5%BA%8F-%E7%A0%B4%E8%A7%A3%E9%80%9A%E5%85%B3.html","summary":"注意此教程需要通过电脑端完成\n操作步骤 1、微信打开羊了个羊小程序，玩第一关 2、进入当前登录的微信数据文件夹 微信左下角 -\u0026gt; 设置 -\u0026gt; 文件管理 -\u0026gt; 打开文件夹\n打开后进入当前登录的微信数据文件夹\n3、进入当前登录微信数据文件夹后，依次进入 \\Applet\\wx141bfb9b73c970a9\\usr\\gamecaches\\resources\n注意 wx141bfb9b73c970a9 文件名可能不同，但以 a9 结尾\n4、修改游戏配置文件 在此文件夹下，有很多 json 文件，找到默认排序的第三个，大小 2k 的文件\n我的电脑是 16632884479734.json 文件，用记事本打开，清空里面内容，将 new.txt 文件中的代码复制进此 json 文件，","title":"羊了个羊小程序 破解通关"},{"content":"K8S 问题排查：cgroup 内存泄露问题 unable to ensure pod container exists: failed to create container for [kubepods besteffort pod5f26dae8-0421-4eab-a3f7-aa51c6848e2b] : mkdir /sys/fs/cgroup/memory/kubepods/besteffort/pod5f26dae8-0421-4eab-a3f7-aa51c6848e2b: cannot allocate memory 查看 linux 内核 cat /proc/version uname -a 可以发现 linux 版本是 3.0 版本\n原因 cgroup 的 kmem account 特性在 Linux 3.x 内核上有内存泄露问题，然后k8s用了这个特性，导致后面创建不出新的pod来了\n解决方法 # 修改/etc/default/grub 为 GRUB_CMDLINE_LINUX=\u0026amp;#34;crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet cgroup.memory=nokmem\u0026amp;#34; #加上了 cgroup.memory=nokmem # 生成配置 /usr/sbin/grub2-mkconfig -o /boot/grub2/grub.cfg # 重启机器 reboot 验证 cat /sys/fs/cgroup/memory/kubepods/burstable/pod*/*/memory.kmem.slabinfo 输出信息\ncat: /sys/fs/cgroup/memory/kubepods/burstable/pod0fe273ca-42e0-4223-9fe8-16d8dd1774e9/0fdd5d9c16929fd600dbdf313b5c3ebabad912dc0cb076ed6e7799e028b31481/memory.kmem.slabinfo: 输入/输出错误 cat:","permalink":"https://test.jobcher.com/k8s-%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5cgroup-%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98.html","summary":"K8S 问题排查：cgroup 内存泄露问题 unable to ensure pod container exists: failed to create container for [kubepods besteffort pod5f26dae8-0421-4eab-a3f7-aa51c6848e2b] : mkdir /sys/fs/cgroup/memory/kubepods/besteffort/pod5f26dae8-0421-4eab-a3f7-aa51c6848e2b: cannot allocate memory 查看 linux 内核 cat /proc/version uname -a 可以发现 linux 版本是 3.0 版本\n原因 cgroup 的 kmem account 特性在 Linux 3.x 内核上有内存泄露问题，然后k8s用了这个特性，导致后面创建不出新的pod来了\n解决方法 # 修改/etc/default/grub 为 GRUB_CMDLINE_LINUX=\u0026#34;crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet cgroup.memory=nokmem\u0026#34; #加上了 cgroup.memory=nokmem # 生成配置 /usr/sbin/grub2-mkconfig -o /boot/grub2/grub.cfg # 重启机器 reboot 验证 cat /sys/fs/cgroup/memory/kubepods/burstable/pod*/*/memory.kmem.slabinfo 输出信息\ncat: /sys/fs/cgroup/memory/kubepods/burstable/pod0fe273ca-42e0-4223-9fe8-16d8dd1774e9/0fdd5d9c16929fd600dbdf313b5c3ebabad912dc0cb076ed6e7799e028b31481/memory.kmem.slabinfo: 输入/输出错误 cat:","title":"K8S 问题排查：cgroup 内存泄露问题"},{"content":"RocketMQ k8s 部署 4 主 4 从集群 使用 NFS 配置 StatefulSet 的动态持久化存储 安装 NFS 服务端 sudo apt update sudo apt install nfs-kernel-server nfs-common 安装 NFS 客户端 所有的节点都得执行\nsudo apt install nfs-common -y\n创建目录 mkdir -p /data/storage/k8s/rocketmq 使用 NFS 作为StatefulSet持久化存储的操作记录，分别需要创建nfs-provisioner的rbac、storageclass、nfs-client-provisioner和statefulset的pod\n创建 nfs 的 rbac --- apiVersion: v1 kind: ServiceAccount metadata: name: nfs-provisioner namespace: sanjiang --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-provisioner-runner namespace: sanjiang rules: - apiGroups: [\u0026amp;#34;\u0026amp;#34;] resources: [\u0026amp;#34;persistentvolumes\u0026amp;#34;] verbs: [\u0026amp;#34;get\u0026amp;#34;, \u0026amp;#34;list\u0026amp;#34;, \u0026amp;#34;watch\u0026amp;#34;, \u0026amp;#34;create\u0026amp;#34;, \u0026amp;#34;delete\u0026amp;#34;] - apiGroups: [\u0026amp;#34;\u0026amp;#34;] resources: [\u0026amp;#34;persistentvolumeclaims\u0026amp;#34;] verbs: [\u0026amp;#34;get\u0026amp;#34;, \u0026amp;#34;list\u0026amp;#34;, \u0026amp;#34;watch\u0026amp;#34;, \u0026amp;#34;update\u0026amp;#34;] - apiGroups: [\u0026amp;#34;storage.k8s.io\u0026amp;#34;] resources: [\u0026amp;#34;storageclasses\u0026amp;#34;] verbs: [\u0026amp;#34;get\u0026amp;#34;, \u0026amp;#34;list\u0026amp;#34;, \u0026amp;#34;watch\u0026amp;#34;] - apiGroups:","permalink":"https://test.jobcher.com/rocketmq-k8s%E9%83%A8%E7%BD%B2-4%E4%B8%BB4%E4%BB%8E%E9%9B%86%E7%BE%A4.html","summary":"RocketMQ k8s 部署 4 主 4 从集群 使用 NFS 配置 StatefulSet 的动态持久化存储 安装 NFS 服务端 sudo apt update sudo apt install nfs-kernel-server nfs-common 安装 NFS 客户端 所有的节点都得执行\nsudo apt install nfs-common -y\n创建目录 mkdir -p /data/storage/k8s/rocketmq 使用 NFS 作为StatefulSet持久化存储的操作记录，分别需要创建nfs-provisioner的rbac、storageclass、nfs-client-provisioner和statefulset的pod\n创建 nfs 的 rbac --- apiVersion: v1 kind: ServiceAccount metadata: name: nfs-provisioner namespace: sanjiang --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-provisioner-runner namespace: sanjiang rules: - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;persistentvolumes\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;create\u0026#34;, \u0026#34;delete\u0026#34;] - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;persistentvolumeclaims\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;update\u0026#34;] - apiGroups: [\u0026#34;storage.","title":"RocketMQ k8s部署 4主4从集群"},{"content":"contained 安装及使用 containerd 是一个行业标准的容器运行时，强调简单性、健壮性和可移植性。它可作为 Linux 和 Windows 的守护进程使用，可以管理其主机系统的完整容器生命周期：图像传输和存储、容器执行和监督、低级存储和网络附件等。\ncontainerd is a member of CNCF with graduated status.\n早在 2016 年 3 月，Docker 1.11的Docker Engine里就包含了containerd，而现在则是把containerd从Docker Engine里彻底剥离出来，作为一个独立的开源项目独立发展，目标是提供一个更加开放、稳定的容器运行基础设施。和原先包含在 Docker Engine 里containerd相比，独立的containerd将具有更多的功能，可以涵盖整个容器运行时管理的所有需求。 containerd并不是直接面向最终用户的，而是主要用于集成到更上层的系统里，比如Swarm, Kubernetes, Mesos等容器编排系统。 containerd以Daemon的形式运行在系统上，通过暴露底层的gRPC API，上层系统可以通过这些API管理机器上的容器。 每个containerd只负责一台机器，Pull 镜像，对容器的操作（启动、停止等），网络，存储都是由 containerd 完成。具体运行容器由runC负责，实际上只要是符合OCI规范的容器都可以支持。 对于容器编排服务来说，运行时只需要使用containerd+runC，更加轻量，容易管理。 5.独立之后containerd的特性演进可以和Docker Engine分开，专注容器运行时管理，可以更稳定。 安装 centos\nyum install -y containerd.io ubuntu\napt install -y containerd.io 设置开机自启\nsystemctl enable containerd systemctl start containerd systemctl status containerd 验证\nctr version ctr 命令 命令 作用 plugins, plugin 提供有关容器插件的信息 version 打印客户端和服务器版本 containers, c, container 管理容器 content 管理","permalink":"https://test.jobcher.com/contained-%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8.html","summary":"contained 安装及使用 containerd 是一个行业标准的容器运行时，强调简单性、健壮性和可移植性。它可作为 Linux 和 Windows 的守护进程使用，可以管理其主机系统的完整容器生命周期：图像传输和存储、容器执行和监督、低级存储和网络附件等。\ncontainerd is a member of CNCF with graduated status.\n早在 2016 年 3 月，Docker 1.11的Docker Engine里就包含了containerd，而现在则是把containerd从Docker Engine里彻底剥离出来，作为一个独立的开源项目独立发展，目标是提供一个更加开放、稳定的容器运行基础设施。和原先包含在 Docker Engine 里containerd相比，独立的containerd将具有更多的功能，可以涵盖整个容器运行时管理的所有需求。 containerd并不是直接面向最终用户的，而是主要用于集成到更上层的系统里，比如Swarm, Kubernetes, Mesos等容器编排系统。 containerd以Daemon的形式运行在系统上，通过暴露底层的gRPC API，上层系统可以通过这些API管理机器上的容器。 每个containerd只负责一台机器，Pull 镜像，对容器的操作（启动、停止等），网络，存储都是由 containerd 完成。具体运行容器由runC负责，实际上只要是符合OCI规范的容器都可以支持。 对于容器编排服务来说，运行时只需要使用containerd+runC，更加轻量，容易管理。 5.独立之后containerd的特性演进可以和Docker Engine分开，专注容器运行时管理，可以更稳定。 安装 centos\nyum install -y containerd.io ubuntu\napt install -y containerd.io 设置开机自启\nsystemctl enable containerd systemctl start containerd systemctl status containerd 验证\nctr version ctr 命令 命令 作用 plugins, plugin 提供有关容器插件的信息 version 打印客户端和服务器版本 containers, c, container 管理容器 content 管理","title":"contained 安装及使用"},{"content":"Planet 下载及安装 官网下载 Planet 是一款用于发布和关注 Web 内容的免费开源软件，它不需要集中式服务器或服务。它使用 IPFS 来实现点对点的内容分发。此外，您可以将您的内容链接到以太坊名称 (.eth)，以便其他人可以通过 Planet 以 .eth 名称关注您。由于 IPFS 和 ENS 都是去中心化的，因此您可以以去中心化的方式构建您的网站或关注其他网站。\n如何使用 标准是 EIP-1577，这个 Content Hash 字段可以接受一些可能的值。例如，IPFS——另一种去中心化的内容分发技术。而vitalik.eth 网站已经在 IPFS 上运行。\n通过 Planet 关注来自 vitalik.eth 的更新\n使用 Planet 创建网站后，右键单击侧栏中的项目，然后选择Copy IPNS，然后您将在粘贴板中看到如下所示的内容：\nk51qzi5uqu5dgv8kzl1anc0m74n6t9ffdjnypdh846ct5wgpljc7rulynxa74a 公开 ENS 然后您可以像这样将该 IPNS 放入您的 ENS ContentHash 中：\n确保在该字符串之前添加了 ipns://。\n完成！ 然后您的网站将链接到您的 ENS。恭喜！现在你有一个在 ENS + IPFS 上运行的去中心化网站！\n","permalink":"https://test.jobcher.com/planet-%E4%B8%8B%E8%BD%BD%E5%8F%8A%E5%AE%89%E8%A3%85.html","summary":"Planet 下载及安装 官网下载 Planet 是一款用于发布和关注 Web 内容的免费开源软件，它不需要集中式服务器或服务。它使用 IPFS 来实现点对点的内容分发。此外，您可以将您的内容链接到以太坊名称 (.eth)，以便其他人可以通过 Planet 以 .eth 名称关注您。由于 IPFS 和 ENS 都是去中心化的，因此您可以以去中心化的方式构建您的网站或关注其他网站。\n如何使用 标准是 EIP-1577，这个 Content Hash 字段可以接受一些可能的值。例如，IPFS——另一种去中心化的内容分发技术。而vitalik.eth 网站已经在 IPFS 上运行。\n通过 Planet 关注来自 vitalik.eth 的更新\n使用 Planet 创建网站后，右键单击侧栏中的项目，然后选择Copy IPNS，然后您将在粘贴板中看到如下所示的内容：\nk51qzi5uqu5dgv8kzl1anc0m74n6t9ffdjnypdh846ct5wgpljc7rulynxa74a 公开 ENS 然后您可以像这样将该 IPNS 放入您的 ENS ContentHash 中：\n确保在该字符串之前添加了 ipns://。\n完成！ 然后您的网站将链接到您的 ENS。恭喜！现在你有一个在 ENS + IPFS 上运行的去中心化网站！","title":"Planet 下载及安装"},{"content":"索引 在关系数据库中，如果有上万甚至上亿条记录，在查找记录的时候，想要获得非常快的速度，就需要使用索引。\n索引是关系数据库中对某一列或多个列的值进行预排序的数据结构。通过使用索引，可以让数据库系统不必扫描整个表，而是直接定位到符合条件的记录，这样就大大加快了查询速度。\nstudents表:\nid class_id name gender score 1 1 小明 M 90 2 1 小红 F 95 3 1 小军 M 88 如果要经常根据score列进行查询，就可以对score列创建索引： ALTER TABLE students ADD INDEX idx_score (score); 使用ADD INDEX idx_score (score)就创建了一个名称为idx_score，使用列score的索引。索引名称是任意的，索引如果有多列，可以在括号里依次写上，例如： ALTER TABLE students ADD INDEX idx_name_score (name, score); 索引的效率取决于索引列的值是否散列，即该列的值如果越互不相同，那么索引效率越高。反过来，如果记录的列存在大量相同的值，例如gender列，大约一半的记录值是M，另一半是F，因此，对该列创建索引就没有意义。\n唯一索引 在设计关系数据表的时候，看上去唯一的列，例如身份证号、邮箱地址等，因为他们具有业务含义，因此不宜作为主键。\n但是，这些列根据业务要求，又具有唯一性约束：即不能出现两条记录存储了同一个身份证号。这个时候，就可以给该列添加一个唯一索引。例如，我们假设students表的name不能重复：\nALTER TABLE students ADD UNIQUE INDEX uni_name (name); 通过UNIQUE关键字我们就添加了一个唯一索引。\n也可以只对某一列添加一个唯一约束而不创建唯一索引：\nALTER TABLE students ADD CONSTRAINT uni_name UNIQUE (name); 这种情况下，name列没有索引，但仍然具有唯一性保证。\n无论是否创建索引，对于用户和应用程序来说，使用关系数据库不会有任何区别。这里的意思是说，当我们在数据库中查询时，如果有相应的索引可用，数据库系统就会自动使用索引来提高查询效率，如果没有索引，查询也能正常执行，只是速度会变慢。因此，索引可以在使用数据库的过程中逐","permalink":"https://test.jobcher.com/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%B4%A2%E5%BC%95%E6%93%8D%E4%BD%9C.html","summary":"索引 在关系数据库中，如果有上万甚至上亿条记录，在查找记录的时候，想要获得非常快的速度，就需要使用索引。\n索引是关系数据库中对某一列或多个列的值进行预排序的数据结构。通过使用索引，可以让数据库系统不必扫描整个表，而是直接定位到符合条件的记录，这样就大大加快了查询速度。\nstudents表:\nid class_id name gender score 1 1 小明 M 90 2 1 小红 F 95 3 1 小军 M 88 如果要经常根据score列进行查询，就可以对score列创建索引： ALTER TABLE students ADD INDEX idx_score (score); 使用ADD INDEX idx_score (score)就创建了一个名称为idx_score，使用列score的索引。索引名称是任意的，索引如果有多列，可以在括号里依次写上，例如： ALTER TABLE students ADD INDEX idx_name_score (name, score); 索引的效率取决于索引列的值是否散列，即该列的值如果越互不相同，那么索引效率越高。反过来，如果记录的列存在大量相同的值，例如gender列，大约一半的记录值是M，另一半是F，因此，对该列创建索引就没有意义。\n唯一索引 在设计关系数据表的时候，看上去唯一的列，例如身份证号、邮箱地址等，因为他们具有业务含义，因此不宜作为主键。\n但是，这些列根据业务要求，又具有唯一性约束：即不能出现两条记录存储了同一个身份证号。这个时候，就可以给该列添加一个唯一索引。例如，我们假设students表的name不能重复：\nALTER TABLE students ADD UNIQUE INDEX uni_name (name); 通过UNIQUE关键字我们就添加了一个唯一索引。\n也可以只对某一列添加一个唯一约束而不创建唯一索引：\nALTER TABLE students ADD CONSTRAINT uni_name UNIQUE (name); 这种情况下，name列没有索引，但仍然具有唯一性保证。\n无论是否创建索引，对于用户和应用程序来说，使用关系数据库不会有任何区别。这里的意思是说，当我们在数据库中查询时，如果有相应的索引可用，数据库系统就会自动使用索引来提高查询效率，如果没有索引，查询也能正常执行，只是速度会变慢。因此，索引可以在使用数据库的过程中逐","title":"关系数据库 索引操作"},{"content":"RocketMQ docker-compose 部署 4 主 4 从集群 V 4.8.0\n采用4主4从，同步模式。HA 实现上采用Master/Slave+Failover组件方式 每台主机运行三个容器，分别为NameServer、BrokerMaster、SlaveMaster，每个 Master 和 Slave 分别存放在不同的机器上\n架构 IP 角色 服务 193.0.40.172 NameServer - 193.0.40.172 BrokerMaster broker-a 193.0.40.172 SlaveMaster broker-d-s 193.0.40.172 BrokerMaster broker-b 193.0.40.172 SlaveMaster broker-a-s 193.0.40.172 BrokerMaster broker-c 193.0.40.172 SlaveMaster broker-b-s 193.0.40.172 BrokerMaster broker-d 193.0.40.172 SlaveMaster broker-c-s 部署 安装 docker-compose #!/bin/bash # 下载安装 v2.4.1 docker-compose curl -L https://get.daocloud.io/docker/compose/releases/download/v2.4.1/docker-compose-`uname -s`-`uname -m` \u0026amp;gt; /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose docker-compose --version 执行 docker-compose --version 查看是否安装成功\n生成配置文件 #!/bin/bash #docker-compose 生成配置文件 mkdir -p /rocketmq/data/namesv1 mkdir -p /rocketmq/logs/namesv1 mkdir -p /rocketmq/data/namesv2 mkdir -p","permalink":"https://test.jobcher.com/rocketmq-docker-compose%E9%83%A8%E7%BD%B2-4%E4%B8%BB4%E4%BB%8E%E9%9B%86%E7%BE%A4.html","summary":"RocketMQ docker-compose 部署 4 主 4 从集群 V 4.8.0\n采用4主4从，同步模式。HA 实现上采用Master/Slave+Failover组件方式 每台主机运行三个容器，分别为NameServer、BrokerMaster、SlaveMaster，每个 Master 和 Slave 分别存放在不同的机器上\n架构 IP 角色 服务 193.0.40.172 NameServer - 193.0.40.172 BrokerMaster broker-a 193.0.40.172 SlaveMaster broker-d-s 193.0.40.172 BrokerMaster broker-b 193.0.40.172 SlaveMaster broker-a-s 193.0.40.172 BrokerMaster broker-c 193.0.40.172 SlaveMaster broker-b-s 193.0.40.172 BrokerMaster broker-d 193.0.40.172 SlaveMaster broker-c-s 部署 安装 docker-compose #!/bin/bash # 下载安装 v2.4.1 docker-compose curl -L https://get.daocloud.io/docker/compose/releases/download/v2.4.1/docker-compose-`uname -s`-`uname -m` \u0026gt; /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose docker-compose --version 执行 docker-compose --version 查看是否安装成功","title":"RocketMQ docker-compose部署 4主4从集群"},{"content":"Argo cd 安装和部署 Argo CD 是一个为 Kubernetes 而生的，遵循声明式 GitOps 理念的持续部署（CD）工具。Argo CD 可在 Git 存储库更改时自动同步和部署应用程序 安装 k8s 快速安装\nk3s kubectl create namespace argocd k3s kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml 安装 Argo CD CLI Argo CD CLI 是用于管理 Argo CD 的命令行工具,Mac 系统可以直接使用 brew install 进行安装\nbrew install argocd 发布 Argo CD 服务 默认情况下， Argo CD 服务不对外暴露服务，可以通过 LoadBalancer 或者 NodePort 类型的 Service、Ingress、Kubectl 端口转发等方式将 Argo CD 服务发布到 Kubernetes 集群外部。\n通过 NodePort 服务的方式暴露 Argo CD 到集群外部\nkubectl patch svc argocd-server -n argocd -p \u0026amp;#39;{\u0026amp;#34;spec\u0026amp;#34;: {\u0026amp;#34;type\u0026amp;#34;: \u0026amp;#34;NodePort\u0026amp;#34;}}\u0026amp;#39; 查看端口 kubectl get svc -n argocd\n使用 获取 Argo CD 密码 默认情况下 admin\n帐号的初始密码是自动生成的，会以明文的形式存储在 Argo CD 安装的命名空间中argocd-initial-admin-secret 的 Secret 对象下的 password\nkubectl -n argocd get secret \\ argocd-initial-admin-secret \\ -o jsonpath=\u0026amp;#34;{.data.password}\u0026amp;#34; | base64 -d 命令行可以使用以下方式登录 argocd login \u0026amp;lt;节点 IP\u0026amp;gt;:\u0026amp;lt;端口\u0026amp;gt;\n","permalink":"https://test.jobcher.com/argo-cd-%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2.html","summary":"Argo cd 安装和部署 Argo CD 是一个为 Kubernetes 而生的，遵循声明式 GitOps 理念的持续部署（CD）工具。Argo CD 可在 Git 存储库更改时自动同步和部署应用程序 安装 k8s 快速安装\nk3s kubectl create namespace argocd k3s kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml 安装 Argo CD CLI Argo CD CLI 是用于管理 Argo CD 的命令行工具,Mac 系统可以直接使用 brew install 进行安装\nbrew install argocd 发布 Argo CD 服务 默认情况下， Argo CD 服务不对外暴露服务，可以通过 LoadBalancer 或者 NodePort 类型的 Service、Ingress、Kubectl 端口转发等方式将 Argo CD 服务发布到 Kubernetes 集群外部。\n通过 NodePort 服务的方式暴露 Argo CD 到集群外部","title":"Argo cd 安装和部署"},{"content":"skywalking 基于 OpenTracing 规范，专门为微服务架构以及云原生服务。\nAPM 监控 一个基于微服务架构的电商系统\nAPM (Application Performance Management) 即应用性能管理，属于 IT 运维管理（ITOM)范畴.\n分为一下三个方面：\nLogging\n服务在处理某个请求时打印的错误日志，可以将这些日志信息记录到Elasticsearch或是其他存储中。通过 Kibana 或是其他工具来分析这些日志了解服务的行为和状态，大多数情况下。日志记录的数据很分散，并且相互独立。例如错误日志，请求处理过程中关键步骤的日志等等。 Metrics\nMetric是可以聚合的，例如为电商系统中每个 HTTP 接口添加一个计数器，计算每个接口的 QPS，可以通过简单的加和计算得到系统的总负载情况。 Tracing\n在微服务架构系统中一请求会经过很多服务处理，调用链路会非常长，要确定中间哪个服务出现异常是非常麻烦的事情，通过分布式链路追踪，运维人员就可以构建一个请求的视图。视图上战术了一个请求从进入系统开始到返回响应的整个流程。 系统交互图\n系统加载图 \u0026amp;gt; 目前流行的APM监控 Zipkin 对 web.xml 进行修改，代码侵入 twitter 开源 Cat 支持 Java、C/C++、Node.Js、Python、go 代码侵入，埋点 美团开源 Pinpoint 基于字节码注入技术，代码无侵入 韩国公司开发，社区交流滞后 只支持 hbase 颗粒度更细 Skywalking\n观测性分析平台 基于字节码注入技术，代码无侵入 服务、服务实例、端点指标分析 服务拓扑图分析 服务、服务实例和端点（Endpont）SLA 分析 支持 es，h2,mysql,TiDb,sharding-sphere skywalking 整体框架 上部分 Agent ：负责从应用中，收集链路信息，发送给 SkyWalking OAP 服务器。目前支持 SkyWalking、Zikpin、Jaeger 等提供的 Tracing 数据信息。而我们目前采用的是，SkyWalking Agent 收集 SkyWalking Tracing 数据，传递给服务器。 下部分 SkyWalking OAP ：负责接收 Agent 发送的 Tracing 数据信息，然后进行分析(Analysis Core) ，存储","permalink":"https://test.jobcher.com/skywalking-apm-%E7%9B%91%E6%8E%A7.html","summary":"skywalking 基于 OpenTracing 规范，专门为微服务架构以及云原生服务。\nAPM 监控 一个基于微服务架构的电商系统\nAPM (Application Performance Management) 即应用性能管理，属于 IT 运维管理（ITOM)范畴.\n分为一下三个方面：\nLogging\n服务在处理某个请求时打印的错误日志，可以将这些日志信息记录到Elasticsearch或是其他存储中。通过 Kibana 或是其他工具来分析这些日志了解服务的行为和状态，大多数情况下。日志记录的数据很分散，并且相互独立。例如错误日志，请求处理过程中关键步骤的日志等等。 Metrics\nMetric是可以聚合的，例如为电商系统中每个 HTTP 接口添加一个计数器，计算每个接口的 QPS，可以通过简单的加和计算得到系统的总负载情况。 Tracing\n在微服务架构系统中一请求会经过很多服务处理，调用链路会非常长，要确定中间哪个服务出现异常是非常麻烦的事情，通过分布式链路追踪，运维人员就可以构建一个请求的视图。视图上战术了一个请求从进入系统开始到返回响应的整个流程。 系统交互图\n系统加载图 \u0026gt; 目前流行的APM监控 Zipkin 对 web.xml 进行修改，代码侵入 twitter 开源 Cat 支持 Java、C/C++、Node.Js、Python、go 代码侵入，埋点 美团开源 Pinpoint 基于字节码注入技术，代码无侵入 韩国公司开发，社区交流滞后 只支持 hbase 颗粒度更细 Skywalking\n观测性分析平台 基于字节码注入技术，代码无侵入 服务、服务实例、端点指标分析 服务拓扑图分析 服务、服务实例和端点（Endpont）SLA 分析 支持 es，h2,mysql,TiDb,sharding-sphere skywalking 整体框架 上部分 Agent ：负责从应用中，收集链路信息，发送给 SkyWalking OAP 服务器。目前支持 SkyWalking、Zikpin、Jaeger 等提供的 Tracing 数据信息。而我们目前采用的是，SkyWalking Agent 收集 SkyWalking Tracing 数据，传递给服务器。 下部分 SkyWalking OAP ：负责接收 Agent 发送的 Tracing 数据信息，然后进行分析(Analysis Core) ，存储","title":"skywalking APM 监控"},{"content":"介绍 systemd 是 linux 中用来启动守护进程，Linux 最早一直采用 init 进程\n(systemd 架构图)\nsystemd 命令 systemd 不是一个具体的命令，而是一组命令，用于系统管理的各个方面\n1.systemctl systemctl是 Systemd 的主命令，用于管理系统。\n# 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # CPU停止工作 $ sudo systemctl halt # 暂停系统 $ sudo systemctl suspend # 让系统进入冬眠状态 $ sudo systemctl hibernate # 让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue 2.systemd-analyze systemd-analyze命令用于查看启动耗时\n# 查看启动耗时 systemd-analyze # 查看每个服务的启动耗时 $ systemd-analyze blame # 显示瀑布状的启动过程流 $ systemd-analyze critical-chain # 显示指定服务的启动流 $ systemd-analyze critical-chain atd.service 3.hostnamectl hostnamectl命令用于查看当前主机的信息。\n# 显示当前主机的信息 $ hostnamectl # 设置主机名。 $ sudo hostnamectl set-hostname jobcher 4.localectl localectl命令用于查看本地化设置\n# 查看本地化设置 $ localectl # 设置本地化参数。 $ sudo localectl set-locale LANG=en_GB.utf8 $ sudo localectl set-keymap en_GB 5.timedatectl timedatectl命令用于查看当前时区设置\n# 查看当前时区设置 $ timedatectl # 显示所有可用的时区 $ timedatectl list-timezones # 设置当前时区 $ sudo timedatectl","permalink":"https://test.jobcher.com/systemd-%E5%AE%88%E6%8A%A4%E5%91%BD%E4%BB%A4.html","summary":"介绍 systemd 是 linux 中用来启动守护进程，Linux 最早一直采用 init 进程\n(systemd 架构图)\nsystemd 命令 systemd 不是一个具体的命令，而是一组命令，用于系统管理的各个方面\n1.systemctl systemctl是 Systemd 的主命令，用于管理系统。\n# 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # CPU停止工作 $ sudo systemctl halt # 暂停系统 $ sudo systemctl suspend # 让系统进入冬眠状态 $ sudo systemctl hibernate # 让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue 2.systemd-analyze systemd-analyze命令用于查看启动耗时\n# 查看启动耗时 systemd-analyze # 查看每个服务的启动耗时 $ systemd-analyze blame # 显示瀑布状的启动过程流 $ systemd-analyze critical-chain # 显示指定服务的启动流 $ systemd-analyze critical-chain atd.","title":"systemd 守护命令"},{"content":"docker 无法启动 打开服务器输入docker ps,输出错误\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n怀疑是不是docker.services 部署没成功，systemctl start docker 启动 docker，结果服务器还是报错\nJob for docker.service failed because the control process exited with error code.\nSee \u0026amp;ldquo;systemctl status docker.service\u0026amp;rdquo; and \u0026amp;ldquo;journalctl -xe\u0026amp;rdquo; for details.\nsystemctl status docker.service 输出日志：\n● docker.service - Docker Application Container Engine Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Thu 2022-08-04 11:43:05 CST; 2min 57s ago TriggeredBy: ● docker.socket Docs: https://docs.docker.com Process: 30432 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock (code=exited, status=1/FAILURE) Main PID: 30432 (code=exited, status=1/FAILURE) Aug 04 11:43:05 master01 systemd[1]: docker.service: Scheduled restart job, restart counter is at 3. Aug 04 11:43:05 master01 systemd[1]: Stopped","permalink":"https://test.jobcher.com/docker-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86.html","summary":"docker 无法启动 打开服务器输入docker ps,输出错误\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n怀疑是不是docker.services 部署没成功，systemctl start docker 启动 docker，结果服务器还是报错\nJob for docker.service failed because the control process exited with error code.\nSee \u0026ldquo;systemctl status docker.service\u0026rdquo; and \u0026ldquo;journalctl -xe\u0026rdquo; for details.\nsystemctl status docker.service 输出日志：\n● docker.service - Docker Application Container Engine Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Thu 2022-08-04 11:43:05 CST; 2min 57s ago TriggeredBy: ● docker.","title":"docker 问题处理"},{"content":"kubernetes 存储 k8s 支持多种途径的多种类型的存储。例如 iSCSI,SMB,NFS，以及对象存储。都是不同类型的部署在云上或者自建数据中心的外部存储系统。k8s 上的所有存储都被称作卷\nCSI 容器存储接口 CSI 是 k8s 存储体系中一部分，是一个开源项目，定义了一套基于标准的接口，从而使容器能够以一种统一的方式被不同的容器编排的工具使用。可以将插件称为provisioner\n持久化 持久化卷 （pv） 持久化卷申请 （pvc） 存储类 （sv） PV 代表 k8s 的存储，pvc 代表的是许可证，赋予 pod 访问 pv 的权限。cs 使分配过程是动态的。\n使用 iSCSI 操作存储 iscsi 卷能将 iSCSI (基于 IP 的 SCSI) 卷挂载到你的 Pod 中。 不像 emptyDir 那样会在删除 Pod 的同时也会被删除，iscsi 卷的内容在删除 Pod 时会被保留，卷只是被卸载。 这意味着 iscsi 卷可以被预先填充数据，并且这些数据可以在 Pod 之间共享。\niSCSI 的一个特点是它可以同时被多个用户以只读方式挂载。 这意味着你可以用数据集预先填充卷，然后根据需要在尽可能多的 Pod 上使用它。 不幸的是，iSCSI 卷只能由单个使用者以读写模式挂载。不允许同时写入。\n创建 iscsi-pv.yaml iscsi-pvc.yaml iscsi-pv.yaml\napiVersion: v1 kind: PersistentVolume metadata: name: iscsi-pv spec: capacity: storage: 500Gi accessModes: - ReadWriteOnce iscsi: targetPortal: 10.12.12.xxx:3260 # 修改 iqn: iqn.2000-01.com.synology:xxx.Target-1.21xxxxx344 # 修改 lun: 1 iscsi-pvc.yaml\napiVersion: v1 kind: PersistentVolume metadata: name: iscsi-pv spec: capacity: storage: 500Gi accessModes: - ReadWriteOnce iscsi: targetPortal: 10.12.12.xxx:3260 # ","permalink":"https://test.jobcher.com/kubernetes-%E5%AD%98%E5%82%A8.html","summary":"kubernetes 存储 k8s 支持多种途径的多种类型的存储。例如 iSCSI,SMB,NFS，以及对象存储。都是不同类型的部署在云上或者自建数据中心的外部存储系统。k8s 上的所有存储都被称作卷\nCSI 容器存储接口 CSI 是 k8s 存储体系中一部分，是一个开源项目，定义了一套基于标准的接口，从而使容器能够以一种统一的方式被不同的容器编排的工具使用。可以将插件称为provisioner\n持久化 持久化卷 （pv） 持久化卷申请 （pvc） 存储类 （sv） PV 代表 k8s 的存储，pvc 代表的是许可证，赋予 pod 访问 pv 的权限。cs 使分配过程是动态的。\n使用 iSCSI 操作存储 iscsi 卷能将 iSCSI (基于 IP 的 SCSI) 卷挂载到你的 Pod 中。 不像 emptyDir 那样会在删除 Pod 的同时也会被删除，iscsi 卷的内容在删除 Pod 时会被保留，卷只是被卸载。 这意味着 iscsi 卷可以被预先填充数据，并且这些数据可以在 Pod 之间共享。\niSCSI 的一个特点是它可以同时被多个用户以只读方式挂载。 这意味着你可以用数据集预先填充卷，然后根据需要在尽可能多的 Pod 上使用它。 不幸的是，iSCSI 卷只能由单个使用者以读写模式挂载。不允许同时写入。\n创建 iscsi-pv.yaml iscsi-pvc.yaml iscsi-pv.yaml\napiVersion: v1 kind: PersistentVolume metadata: name: iscsi-pv spec: capacity: storage: 500Gi accessModes: - ReadWriteOnce iscsi: targetPortal: 10.","title":"kubernetes 存储"},{"content":"linux 服务器 删除空间却未释放 在Linux或者Unix系统中，通过rm或者文件管理器删除文件将会从文件系统的目录结构上解除链接(unlink)，然而如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用，这样就会导致我们明明删除了文件，但是磁盘空间却未被释放\n获取占用列表状态 lsof | grep deleted 可以看到哪些文件还被使用，未被释放空间。\n释放磁盘空间 一种方法是 kill 掉相应的进程，或者停掉使用这个文件的应用，让 os 自动回收磁盘空间，当 linux 打开一个文件的时候,Linux 内核会为每一个进程在/proc/, /proc/nnnn/fd/目录（nnnn 为 pid）建立一个以其 pid 为名的目录用来保存进程的相关信息，而其子目录 fd 保存的是该进程打开的所有文件的 fd（fd：file descriptor）；\nkill进程是通过截断 proc 文件系统中的文件可以强制要求系统回收分配给正在使用的的文件，这是一项高级技术，仅当管理员确定不会对运行中的进程造成影响时使用。 kill -9 12345 # PID 重启服务 lsof 命令 lsof全名list opened files，也就是列举系统中已经被打开的文件。我们都知道，linux 环境中，任何事物都是文件，设备是文件，目录是文件，甚至sockets也是文件。\n","permalink":"https://test.jobcher.com/linux%E6%9C%8D%E5%8A%A1%E5%99%A8-%E5%88%A0%E9%99%A4%E7%A9%BA%E9%97%B4%E5%8D%B4%E6%9C%AA%E9%87%8A%E6%94%BE.html","summary":"linux 服务器 删除空间却未释放 在Linux或者Unix系统中，通过rm或者文件管理器删除文件将会从文件系统的目录结构上解除链接(unlink)，然而如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用，这样就会导致我们明明删除了文件，但是磁盘空间却未被释放\n获取占用列表状态 lsof | grep deleted 可以看到哪些文件还被使用，未被释放空间。\n释放磁盘空间 一种方法是 kill 掉相应的进程，或者停掉使用这个文件的应用，让 os 自动回收磁盘空间，当 linux 打开一个文件的时候,Linux 内核会为每一个进程在/proc/, /proc/nnnn/fd/目录（nnnn 为 pid）建立一个以其 pid 为名的目录用来保存进程的相关信息，而其子目录 fd 保存的是该进程打开的所有文件的 fd（fd：file descriptor）；\nkill进程是通过截断 proc 文件系统中的文件可以强制要求系统回收分配给正在使用的的文件，这是一项高级技术，仅当管理员确定不会对运行中的进程造成影响时使用。 kill -9 12345 # PID 重启服务 lsof 命令 lsof全名list opened files，也就是列举系统中已经被打开的文件。我们都知道，linux 环境中，任何事物都是文件，设备是文件，目录是文件，甚至sockets也是文件。","title":"linux服务器 删除空间却未释放"},{"content":"logstash 多管道部署 找到 logstash 目录位置，一般来说在 /etc/logstash 路径下,修改 logstash.yml\n#增加 日志记录 path.logs: /var/log/logstash 增加管道 增加 conf.d目录下 test.conf\ninput { beats { host =\u0026amp;gt; \u0026amp;#34;0.0.0.0\u0026amp;#34; port =\u0026amp;gt; 23000 # 修改端口IP } } filter { mutate{ add_field =\u0026amp;gt; { \u0026amp;#34;cluster\u0026amp;#34; =\u0026amp;gt; \u0026amp;#34;test\u0026amp;#34; # 修改标签 \u0026amp;#34;job\u0026amp;#34; =\u0026amp;gt; \u0026amp;#34;logstash\u0026amp;#34; } } } output { file { path =\u0026amp;gt; \u0026amp;#34;/data/路径名称\u0026amp;#34; # 路径名称 gzip =\u0026amp;gt; false #匹配以空格开头的行 } } 修改 pipelines.yml\n- pipeline.id: 名称 path.config: \u0026amp;#34;/etc/logstash/conf.d/配置文件.conf\u0026amp;#34; queue.type: persisted 启动 logstash 文件 /usr/share/logstash/bin/logstash \u0026amp;amp; ","permalink":"https://test.jobcher.com/logstash-%E5%A4%9A%E7%AE%A1%E9%81%93%E9%83%A8%E7%BD%B2.html","summary":"logstash 多管道部署 找到 logstash 目录位置，一般来说在 /etc/logstash 路径下,修改 logstash.yml\n#增加 日志记录 path.logs: /var/log/logstash 增加管道 增加 conf.d目录下 test.conf\ninput { beats { host =\u0026gt; \u0026#34;0.0.0.0\u0026#34; port =\u0026gt; 23000 # 修改端口IP } } filter { mutate{ add_field =\u0026gt; { \u0026#34;cluster\u0026#34; =\u0026gt; \u0026#34;test\u0026#34; # 修改标签 \u0026#34;job\u0026#34; =\u0026gt; \u0026#34;logstash\u0026#34; } } } output { file { path =\u0026gt; \u0026#34;/data/路径名称\u0026#34; # 路径名称 gzip =\u0026gt; false #匹配以空格开头的行 } } 修改 pipelines.yml\n- pipeline.id: 名称 path.config: \u0026#34;/etc/logstash/conf.d/配置文件.conf\u0026#34; queue.type: persisted 启动 logstash 文件 /usr/share/logstash/bin/logstash \u0026amp; ","title":"logstash 多管道部署"},{"content":"kubernetes 从1.23.x 升级到 1.24.x k8s 在1.24.x之后的版本放弃了和 docker 的兼容，使用 containerd 作为底层的容器，直接参照官方文档的资料进行更新就会报错。因为你没有安装 containerd，所以要安装 containerd 并配置才能正确的升级 k8s\n我用的是CentOS7.9的版本，因此以下操作都是在CentOS下操作。\nMaster 节点操作 1.升级 kubeadm yum install -y kubeadm-1.24.2-0 --disableexcludes=kubernetes kubeadm version kubeadm upgrade plan sudo kubeadm upgrade apply v1.24.2 2.安装 containerd yum install containerd.io -y containerd config default \u0026amp;gt; /etc/containerd/config.toml vim /var/lib/kubelet/kubeadm-flags.env 修改 kubeadm-flags.env 变量：\nKUBELET_KUBEADM_ARGS=\u0026amp;#34;--pod-infra-container-image=k8s.gcr.io/pause:3.6 --container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock\u0026amp;#34; 3.升级 kubelet yum install -y kubelet-1.24.2-0 kubectl-1.24.2-0 --disableexcludes=kubernetes systemctl daemon-reload \u0026amp;amp;\u0026amp;amp; systemctl restart containerd \u0026amp;amp;\u0026amp;amp; systemctl restart kubelet 查看状态：\nkubectl get nodes\nsystemctl status kubelet\nWorker 节点操作 1.升级 kubeadm yum install -y kubeadm-1.24.2-0 --disableexcludes=kubernetes","permalink":"https://test.jobcher.com/kubernetes-%E4%BB%8E1.23.x-%E5%8D%87%E7%BA%A7%E5%88%B0-1.24.x.html","summary":"kubernetes 从1.23.x 升级到 1.24.x k8s 在1.24.x之后的版本放弃了和 docker 的兼容，使用 containerd 作为底层的容器，直接参照官方文档的资料进行更新就会报错。因为你没有安装 containerd，所以要安装 containerd 并配置才能正确的升级 k8s\n我用的是CentOS7.9的版本，因此以下操作都是在CentOS下操作。\nMaster 节点操作 1.升级 kubeadm yum install -y kubeadm-1.24.2-0 --disableexcludes=kubernetes kubeadm version kubeadm upgrade plan sudo kubeadm upgrade apply v1.24.2 2.安装 containerd yum install containerd.io -y containerd config default \u0026gt; /etc/containerd/config.toml vim /var/lib/kubelet/kubeadm-flags.env 修改 kubeadm-flags.env 变量：\nKUBELET_KUBEADM_ARGS=\u0026#34;--pod-infra-container-image=k8s.gcr.io/pause:3.6 --container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock\u0026#34; 3.升级 kubelet yum install -y kubelet-1.24.2-0 kubectl-1.24.2-0 --disableexcludes=kubernetes systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart containerd \u0026amp;\u0026amp; systemctl restart kubelet 查看状态：","title":"kubernetes 从1.23.x 升级到 1.24.x"},{"content":"编写 kubernetes 资源描述文件 1. 部署一个应用 apiVersion: apps/v1 #与k8s集群版本有关，使用 kubectl api-versions 即可查看当前集群支持的版本 kind: Deployment #该配置的类型，我们使用的是 Deployment metadata: #译名为元数据，即 Deployment 的一些基本属性和信息 name: nginx-deployment #Deployment 的名称 labels: #标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组，目前不需要理解 app: nginx #为该Deployment设置key为app，value为nginx的标签 spec: #这是关于该Deployment的描述，可以理解为你期待该Deployment在k8s中如何使用 replicas: 1 #使用该Deployment创建一个应用程序实例 selector: #标签选择器，与上面的标签共同作用，目前不需要理解 matchLabels: #选择包含标签app:nginx的资源 app: nginx template: #这是选择或创建的Pod的模板 metadata: #Pod的元数据 labels: #Pod的标签，上面的selector即选择包含标签app:nginx的Pod app: nginx spec: #期望Pod实现的功能（即在pod中部署） containers: #生成container，与docker中的container是同一种 - name: nginx #container的名称 image: nginx:1.7.9 #使用镜像nginx:1.7.9创建container，该container默认80端口可访问 kubectl apply -f xxx.yaml\n2、暴露应用 apiVersion: v1 kind: Service metadata: name: nginx-service #Service 的名称 labels: #Service 自己的标签 app: nginx #为该 Service 设置 key 为 app，value 为 nginx 的标签 spec: #这是关于该 Service 的定义，描述了 Service 如何选择 Pod，如何被访问 selector: #","permalink":"https://test.jobcher.com/%E7%BC%96%E5%86%99-kubernetes-%E8%B5%84%E6%BA%90%E6%8F%8F%E8%BF%B0%E6%96%87%E4%BB%B6.html","summary":"编写 kubernetes 资源描述文件 1. 部署一个应用 apiVersion: apps/v1 #与k8s集群版本有关，使用 kubectl api-versions 即可查看当前集群支持的版本 kind: Deployment #该配置的类型，我们使用的是 Deployment metadata: #译名为元数据，即 Deployment 的一些基本属性和信息 name: nginx-deployment #Deployment 的名称 labels: #标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组，目前不需要理解 app: nginx #为该Deployment设置key为app，value为nginx的标签 spec: #这是关于该Deployment的描述，可以理解为你期待该Deployment在k8s中如何使用 replicas: 1 #使用该Deployment创建一个应用程序实例 selector: #标签选择器，与上面的标签共同作用，目前不需要理解 matchLabels: #选择包含标签app:nginx的资源 app: nginx template: #这是选择或创建的Pod的模板 metadata: #Pod的元数据 labels: #Pod的标签，上面的selector即选择包含标签app:nginx的Pod app: nginx spec: #期望Pod实现的功能（即在pod中部署） containers: #生成container，与docker中的container是同一种 - name: nginx #container的名称 image: nginx:1.7.9 #使用镜像nginx:1.7.9创建container，该container默认80端口可访问 kubectl apply -f xxx.yaml\n2、暴露应用 apiVersion: v1 kind: Service metadata: name: nginx-service #Service 的名称 labels: #Service 自己的标签 app: nginx #为该 Service 设置 key 为 app，value 为 nginx 的标签 spec: #这是关于该 Service 的定义，描述了 Service 如何选择 Pod，如何被访问 selector: #","title":"编写 kubernetes 资源描述文件"},{"content":"nginx ssh-key connection exception Not long ago, I wanted to restart the company\u0026amp;rsquo;s gitlab server.I couldn\u0026amp;rsquo;t coonect to ssh when it restarted.emm……I try copy the ssh rsa.pub,but it didn\u0026amp;rsquo;t work.\nerror log:\nidentity_sign: private key ~/.ssh/id_rsa contents do not match public what is happen？\nsolution reconfigure gitlab ssh key!\ncreate new ssh key ssh-keygen -t rsa -C \u0026amp;#39;git@gitlab.com\u0026amp;#39; -f ~/.ssh/gitlab-rsa update config file,enter ~./ssh,open config # add host Host gitlab.com HostName gitlab.com IdentityFile ~/.ssh/gitlab_id-rsa enter http://gitlab.com ,Profile Settings\u0026amp;ndash;\u0026amp;gt;SSH Keys\u0026amp;ndash;\u0026amp;gt;Add SSH Key You are done\n","permalink":"https://test.jobcher.com/nginx-ssh-key-connection-exception.html","summary":"nginx ssh-key connection exception Not long ago, I wanted to restart the company\u0026rsquo;s gitlab server.I couldn\u0026rsquo;t coonect to ssh when it restarted.emm……I try copy the ssh rsa.pub,but it didn\u0026rsquo;t work.\nerror log:\nidentity_sign: private key ~/.ssh/id_rsa contents do not match public what is happen？\nsolution reconfigure gitlab ssh key!\ncreate new ssh key ssh-keygen -t rsa -C \u0026#39;git@gitlab.com\u0026#39; -f ~/.ssh/gitlab-rsa update config file,enter ~./ssh,open config # add host Host gitlab.com HostName gitlab.","title":"nginx ssh-key connection exception"},{"content":"k8s manual expansion We find k8s-master node.Input the Command：\nexpand kubectl scale --replicas=3 deploy my-test-deploy shrink kubectl scale --replicas=1 deploy my-test-deploy trouble cleaning get resource list kubectl get deployment kubectl get pods kubectl get nodes # exists in the namespace kubectl api-resources --namespaced=true # not exists in the namespace kubectl api-resources --namespaced=false show info kubectl describe pod my-test-pod kubectl describe deployment my-test-pod exec container kubectl exec -ti my-test-pod /bin/bash ","permalink":"https://test.jobcher.com/kubernetes-manual-expansion.html","summary":"k8s manual expansion We find k8s-master node.Input the Command：\nexpand kubectl scale --replicas=3 deploy my-test-deploy shrink kubectl scale --replicas=1 deploy my-test-deploy trouble cleaning get resource list kubectl get deployment kubectl get pods kubectl get nodes # exists in the namespace kubectl api-resources --namespaced=true # not exists in the namespace kubectl api-resources --namespaced=false show info kubectl describe pod my-test-pod kubectl describe deployment my-test-pod exec container kubectl exec -ti my-test-pod /bin/bash ","title":"kubernetes manual expansion"},{"content":"nginx exporter 安装配置 二进制安装 wget https://github.com/nginxinc/nginx-prometheus-exporter/releases/download/v0.10.0/nginx-prometheus-exporter_0.10.0_linux_amd64.tar.gz tar -zxvf nginx-prometheus-exporter_0.10.0_linux_amd64.tar.gz -C ./nginx-exporter 在 nginx 上配置 ./configure \\ … \\ --with-http_stub_status_module make sudo make install 在 nginx.config 上配置\nserver { # 新增 location /nginx_status { stub_status on; access_log off; } } 重启 nginx 服务\nnginx -t nginx -s reload 启动 nginx exporter nginx-prometheus-exporter -nginx.scrape-uri http://\u0026amp;lt;nginx\u0026amp;gt;:8080/nginx_status 配置 prometheus 添加 prometheus.yml - job_name: \u0026amp;#34;nginx-exporter\u0026amp;#34; file_sd_configs: - files: - \u0026amp;#34;./file_sd/nginx-exporter.yaml\u0026amp;#34; 在 ./file_sd/新建 nginx-exporter.yaml\n- targets: [\u0026amp;#34;\u0026amp;lt;IP\u0026amp;gt;:9113\u0026amp;#34;] labels: instance: \u0026amp;lt;nginx名称\u0026amp;gt; ","permalink":"https://test.jobcher.com/nginx-exporter-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE.html","summary":"nginx exporter 安装配置 二进制安装 wget https://github.com/nginxinc/nginx-prometheus-exporter/releases/download/v0.10.0/nginx-prometheus-exporter_0.10.0_linux_amd64.tar.gz tar -zxvf nginx-prometheus-exporter_0.10.0_linux_amd64.tar.gz -C ./nginx-exporter 在 nginx 上配置 ./configure \\ … \\ --with-http_stub_status_module make sudo make install 在 nginx.config 上配置\nserver { # 新增 location /nginx_status { stub_status on; access_log off; } } 重启 nginx 服务\nnginx -t nginx -s reload 启动 nginx exporter nginx-prometheus-exporter -nginx.scrape-uri http://\u0026lt;nginx\u0026gt;:8080/nginx_status 配置 prometheus 添加 prometheus.yml - job_name: \u0026#34;nginx-exporter\u0026#34; file_sd_configs: - files: - \u0026#34;./file_sd/nginx-exporter.yaml\u0026#34; 在 ./file_sd/新建 nginx-exporter.yaml\n- targets: [\u0026#34;\u0026lt;IP\u0026gt;:9113\u0026#34;] labels: instance: \u0026lt;nginx名称\u0026gt; ","title":"nginx exporter 安装配置"},{"content":"go Struct 结构体 结构体是将零个或多个任意类型的变量，组合在一起的聚合数据类型，也可以看做是数据的集合。\n声明结构体 //demo_11.go package main import ( \u0026amp;#34;fmt\u0026amp;#34; ) type Person struct { Name string Age int } func main() { var p1 Person p1.Name = \u0026amp;#34;Tom\u0026amp;#34; p1.Age = 30 fmt.Println(\u0026amp;#34;p1 =\u0026amp;#34;, p1) var p2 = Person{Name:\u0026amp;#34;Burke\u0026amp;#34;, Age:31} fmt.Println(\u0026amp;#34;p2 =\u0026amp;#34;, p2) p3 := Person{Name:\u0026amp;#34;Aaron\u0026amp;#34;, Age:32} fmt.Println(\u0026amp;#34;p2 =\u0026amp;#34;, p3) //匿名结构体 p4 := struct { Name string Age int } {Name:\u0026amp;#34;匿名\u0026amp;#34;, Age:33} fmt.Println(\u0026amp;#34;p4 =\u0026amp;#34;, p4) } 生成 JSON //demo_12.go package main import ( \u0026amp;#34;encoding/json\u0026amp;#34; \u0026amp;#34;fmt\u0026amp;#34; ) type Result struct { Code int `json:\u0026amp;#34;code\u0026amp;#34;` Message string `json:\u0026amp;#34;msg\u0026amp;#34;` } func main() { var res Result res.Code = 200 res.Message = \u0026amp;#34;success\u0026amp;#34; //序列化 jsons, errs := json.Marshal(res) if errs != nil { fmt.Println(\u0026amp;#34;json marshal error:\u0026amp;#34;, errs) } fmt.Println(\u0026amp;#34;json data :\u0026amp;#34;, string(jsons)) //反序列化 var res2 Result errs = json.Unmarshal(jsons, \u0026amp;amp;res2) if errs != nil { fmt.Println(\u0026amp;#34;json","permalink":"https://test.jobcher.com/go-struct-%E7%BB%93%E6%9E%84%E4%BD%93.html","summary":"go Struct 结构体 结构体是将零个或多个任意类型的变量，组合在一起的聚合数据类型，也可以看做是数据的集合。\n声明结构体 //demo_11.go package main import ( \u0026#34;fmt\u0026#34; ) type Person struct { Name string Age int } func main() { var p1 Person p1.Name = \u0026#34;Tom\u0026#34; p1.Age = 30 fmt.Println(\u0026#34;p1 =\u0026#34;, p1) var p2 = Person{Name:\u0026#34;Burke\u0026#34;, Age:31} fmt.Println(\u0026#34;p2 =\u0026#34;, p2) p3 := Person{Name:\u0026#34;Aaron\u0026#34;, Age:32} fmt.Println(\u0026#34;p2 =\u0026#34;, p3) //匿名结构体 p4 := struct { Name string Age int } {Name:\u0026#34;匿名\u0026#34;, Age:33} fmt.Println(\u0026#34;p4 =\u0026#34;, p4) } 生成 JSON //demo_12.go package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type Result struct { Code int `json:\u0026#34;code\u0026#34;` Message string `json:\u0026#34;msg\u0026#34;` } func main() { var res Result res.","title":"go Struct 结构体"},{"content":"go Slice 切片语法 切片是一种动态数组，比数组操作灵活，长度不是固定的，可以进行追加和删除。\nlen() 和 cap() 返回结果可相同和不同。\n声明切片 //demo_7.go package main import ( \u0026amp;#34;fmt\u0026amp;#34; ) func main() { var sli_1 [] int //nil 切片 fmt.Printf(\u0026amp;#34;len=%d cap=%d slice=%v\\n\u0026amp;#34;,len(sli_1),cap(sli_1),sli_1) var sli_2 = [] int {} //空切片 fmt.Printf(\u0026amp;#34;len=%d cap=%d slice=%v\\n\u0026amp;#34;,len(sli_1),cap(sli_2),sli_2) var sli_3 = [] int {1, 2, 3, 4, 5} fmt.Printf(\u0026amp;#34;len=%d cap=%d slice=%v\\n\u0026amp;#34;,len(sli_3),cap(sli_3),sli_3) sli_4 := [] int {1, 2, 3, 4, 5} fmt.Printf(\u0026amp;#34;len=%d cap=%d slice=%v\\n\u0026amp;#34;,len(sli_4),cap(sli_4),sli_4) var sli_5 [] int = make([] int, 5, 8) fmt.Printf(\u0026amp;#34;len=%d cap=%d slice=%v\\n\u0026amp;#34;,len(sli_5),cap(sli_5),sli_5) sli_6 := make([] int, 5, 9) fmt.Printf(\u0026amp;#34;len=%d cap=%d slice=%v\\n\u0026amp;#34;,len(sli_6),cap(sli_6),sli_6) } 截取切片 //demo_8.go package main import ( \u0026amp;#34;fmt\u0026amp;#34; ) func main() { sli := [] int {1, 2, 3, 4, 5, 6} fmt.Printf(\u0026amp;#34;len=%d cap=%d slice=%v\\n\u0026amp;#34;,len(sli),cap(sli),sli) fmt.Println(\u0026amp;#34;sli[1] ==\u0026amp;#34;, sli[1]) fmt.Println(\u0026amp;#34;sli[:]","permalink":"https://test.jobcher.com/go-slice%E5%88%87%E7%89%87%E8%AF%AD%E6%B3%95.html","summary":"go Slice 切片语法 切片是一种动态数组，比数组操作灵活，长度不是固定的，可以进行追加和删除。\nlen() 和 cap() 返回结果可相同和不同。\n声明切片 //demo_7.go package main import ( \u0026#34;fmt\u0026#34; ) func main() { var sli_1 [] int //nil 切片 fmt.Printf(\u0026#34;len=%d cap=%d slice=%v\\n\u0026#34;,len(sli_1),cap(sli_1),sli_1) var sli_2 = [] int {} //空切片 fmt.Printf(\u0026#34;len=%d cap=%d slice=%v\\n\u0026#34;,len(sli_1),cap(sli_2),sli_2) var sli_3 = [] int {1, 2, 3, 4, 5} fmt.Printf(\u0026#34;len=%d cap=%d slice=%v\\n\u0026#34;,len(sli_3),cap(sli_3),sli_3) sli_4 := [] int {1, 2, 3, 4, 5} fmt.Printf(\u0026#34;len=%d cap=%d slice=%v\\n\u0026#34;,len(sli_4),cap(sli_4),sli_4) var sli_5 [] int = make([] int, 5, 8) fmt.","title":"go Slice切片语法"},{"content":"go 基础知识 目录结构 ├─ code -- 代码根目录 │ ├─ bin │ ├─ pkg │ ├─ src │ ├── hello │ ├── hello.go bin 存放编译后可执行的文件。 pkg 存放编译后的应用包。 src 存放应用源代码。 Hello World 代码\n//在 hello 目录下创建 hello.go package main import ( \u0026amp;#34;fmt\u0026amp;#34; ) func main() { fmt.Println(\u0026amp;#34;Hello World!\u0026amp;#34;) } 基础命令 go build hello #在src目录或hello目录下执行 go build hello，只在对应当前目录下生成文件。 go install hello #在src目录或hello目录下执行 go install hello，会把编译好的结果移动到 $GOPATH/bin。 go run hello #在src目录或hello目录下执行 go run hello，不生成任何文件只运行程序。 go fmt hello #在src目录或hello目录下执行 go run hello，格式化代码，将代码修改成标准格式。 数据类型 类型 表示 备注 字符串 string 只能用一对双引号（\u0026amp;quot;\u0026amp;quot;）或反引号（``）括起来定义，不能用单引号（\u0026amp;rsquo;\u0026amp;rsquo;）定义！ 布尔 bool 只有 true 和 false，默认为 false。 整型 int8 uint8 int16 uint16 int32 uint32 int64 uint64 int uint 具体长度取决于 CPU 位数。 浮点型 float32 float64 常量声明 常量，在程序编译阶段就确定下来的值，而程序在运行时无法改变该值。\n1. 单个常量声明 第一种：const 变量名称 数据类型 = 变量值\n如果不赋值，使用的是该数据类型的默认值。\n第二种：const 变量名称 = 变量值\n根据变量值，自行判断数据类型。\n2. 多个常量声明 第一种：const 变量名称,变量名称 \u0026amp;hellip; ,数据类型 = 变量值,变量值 \u0026amp;hellip;\n第二种：const 变量名称,变量名称 \u0026amp;hellip; = 变量值,变量值 \u0026amp;hellip;\n3. 代码 //demo_1.go package main","permalink":"https://test.jobcher.com/go-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html","summary":"go 基础知识 目录结构 ├─ code -- 代码根目录 │ ├─ bin │ ├─ pkg │ ├─ src │ ├── hello │ ├── hello.go bin 存放编译后可执行的文件。 pkg 存放编译后的应用包。 src 存放应用源代码。 Hello World 代码\n//在 hello 目录下创建 hello.go package main import ( \u0026#34;fmt\u0026#34; ) func main() { fmt.Println(\u0026#34;Hello World!\u0026#34;) } 基础命令 go build hello #在src目录或hello目录下执行 go build hello，只在对应当前目录下生成文件。 go install hello #在src目录或hello目录下执行 go install hello，会把编译好的结果移动到 $GOPATH/bin。 go run hello #在src目录或hello目录下执行 go run hello，不生成任何文件只运行程序。 go fmt hello #在src目录或hello目录下执行 go run hello，格式化代码，将代码修改成标准格式。 数据类型 类型 表示 备注 字符串 string 只能用一对双引号（\u0026quot;\u0026quot;）或反引号（``）括起来定义，不能用单引号（\u0026rsquo;\u0026rsquo;）定义！ 布尔 bool 只有 true 和 false，默认为 false。 整型 int8 uint8 int16 uint16 int32 uint32 int64 uint64 int uint 具体长度取决于 CPU 位数。 浮点型 float32 float64 常量声明 常量，在程序编译阶段就确定下来的值，而程序在运行时无法改变该值。","title":"go 基础知识"},{"content":"VSCode 插件推荐=\u0026amp;gt; Code Runner Run code snippet or code file for multiple languages: C, C++, Java, JavaScript, PHP, Python, Perl, Perl 6, Ruby, Go, Lua, Groovy, PowerShell, BAT/CMD, BASH/SH, F# Script, F# (.NET Core), C# Script, C# (.NET Core), VBScript, TypeScript, CoffeeScript, Scala, Swift, Julia, Crystal, OCaml Script, R, AppleScript, Elixir, Visual Basic .NET, Clojure, Haxe, Objective-C, Rust, Racket, Scheme, AutoHotkey, AutoIt, Kotlin, Dart, Free Pascal, Haskell, Nim, D, Lisp, Kit, V, SCSS, Sass, CUDA, Less, Fortran, Ring, and custom command\n可以用编译运行超过 40 种语言，非常的方便～\n在 vscode 插件里安装 运行你的代码 键盘快捷键 Ctrl+Alt+N 快捷键 F1 调出 命令面板, 然后输入 Run Code 在编辑区，右键选择 Run Code 在左侧的文件管理器，右键选择 Run Code 右上角的运行小三角按钮 ","permalink":"https://test.jobcher.com/vscode%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%90-code-runner.html","summary":"VSCode 插件推荐=\u0026gt; Code Runner Run code snippet or code file for multiple languages: C, C++, Java, JavaScript, PHP, Python, Perl, Perl 6, Ruby, Go, Lua, Groovy, PowerShell, BAT/CMD, BASH/SH, F# Script, F# (.NET Core), C# Script, C# (.NET Core), VBScript, TypeScript, CoffeeScript, Scala, Swift, Julia, Crystal, OCaml Script, R, AppleScript, Elixir, Visual Basic .NET, Clojure, Haxe, Objective-C, Rust, Racket, Scheme, AutoHotkey, AutoIt, Kotlin, Dart, Free Pascal, Haskell, Nim, D, Lisp, Kit, V, SCSS, Sass, CUDA, Less, Fortran, Ring, and custom command","title":"VSCode插件推荐=\u003e Code Runner"},{"content":"ant build.xml 编写 生成 build.xml Eclipse 自动生成 Ant 的Build.xml 配置文件,生成的方法很隐蔽\n选择你要生成Build.xml文件的项目,右键. Export-\u0026amp;gt; General -\u0026amp;gt; Ant Buildfiles .\n点 Next,选择项目，再点Finish.\n编写 build.xml \u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34; standalone=\u0026amp;#34;no\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;!-- 每个构建文件对应一个项目。\u0026amp;lt;project\u0026amp;gt;标签时构建文件的根标签。它可以有多个内在属性，就如代码中所示，其各个属性的含义分别如下。 (1) default表示默认的运行目标，这个属性是必须的。 (2) basedir表示项目的基准目录。 (3) name表示项目名。 (4) description表示项目的描述。 --\u0026amp;gt; \u0026amp;lt;project default=\u0026amp;#34;build\u0026amp;#34; name=\u0026amp;#34;Sort\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;!-- 设置属性或文件路径，读取属性使用${property}，value路径默认项目根目录 --\u0026amp;gt; \u0026amp;lt;property file=\u0026amp;#34;ant/builds.properties\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;src.dir\u0026amp;#34; value=\u0026amp;#34;src/statics\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;classes.dir\u0026amp;#34; value=\u0026amp;#34;ant/classes\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;lib.dir\u0026amp;#34; value=\u0026amp;#34;lib\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;dist.dir\u0026amp;#34; value=\u0026amp;#34;ant/dist\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;!-- 定义classpath --\u0026amp;gt; \u0026amp;lt;path id=\u0026amp;#34;master-classpath\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;fileset file=\u0026amp;#34;${lib.dir}/*.jar\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;pathelement","permalink":"https://test.jobcher.com/ant-build.xml-%E7%BC%96%E5%86%99.html","summary":"ant build.xml 编写 生成 build.xml Eclipse 自动生成 Ant 的Build.xml 配置文件,生成的方法很隐蔽\n选择你要生成Build.xml文件的项目,右键. Export-\u0026gt; General -\u0026gt; Ant Buildfiles .\n点 Next,选择项目，再点Finish.\n编写 build.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;no\u0026#34;?\u0026gt; \u0026lt;!-- 每个构建文件对应一个项目。\u0026lt;project\u0026gt;标签时构建文件的根标签。它可以有多个内在属性，就如代码中所示，其各个属性的含义分别如下。 (1) default表示默认的运行目标，这个属性是必须的。 (2) basedir表示项目的基准目录。 (3) name表示项目名。 (4) description表示项目的描述。 --\u0026gt; \u0026lt;project default=\u0026#34;build\u0026#34; name=\u0026#34;Sort\u0026#34;\u0026gt; \u0026lt;!-- 设置属性或文件路径，读取属性使用${property}，value路径默认项目根目录 --\u0026gt; \u0026lt;property file=\u0026#34;ant/builds.properties\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;src.dir\u0026#34; value=\u0026#34;src/statics\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;classes.dir\u0026#34; value=\u0026#34;ant/classes\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;lib.dir\u0026#34; value=\u0026#34;lib\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;dist.dir\u0026#34; value=\u0026#34;ant/dist\u0026#34; /\u0026gt; \u0026lt;!-- 定义classpath --\u0026gt; \u0026lt;path id=\u0026#34;master-classpath\u0026#34;\u0026gt; \u0026lt;fileset file=\u0026#34;${lib.dir}/*.jar\u0026#34; /\u0026gt; \u0026lt;pathelement","title":"ant build.xml 编写"},{"content":"k8s 调度过程 执行滚动升级 修改 deployment.yml 文件，追加 rollingUpdate\n# 部署应用 apiVersion: apps/v1 kind: Deployment metadata: name: jobcher-blog-deployment labels: app: jobcher-blog spec: replicas: 3 selector: matchLabels: app: jobcher-blog minReadySeconds: 10 #准备10s strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 #更新期间不少于3-1 maxSurge: 1 #更新期间不超过3+1 template: metadata: labels: app: jobcher-blog spec: containers: - name: jobcher-blog-pod image: hub.docker.com/blog/hugo:latest 执行命令\nkubectl rollout restart deployment jobcher-blog-deployment\n","permalink":"https://test.jobcher.com/kubernetes-%E8%B0%83%E5%BA%A6%E8%BF%87%E7%A8%8B.html","summary":"k8s 调度过程 执行滚动升级 修改 deployment.yml 文件，追加 rollingUpdate\n# 部署应用 apiVersion: apps/v1 kind: Deployment metadata: name: jobcher-blog-deployment labels: app: jobcher-blog spec: replicas: 3 selector: matchLabels: app: jobcher-blog minReadySeconds: 10 #准备10s strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 #更新期间不少于3-1 maxSurge: 1 #更新期间不超过3+1 template: metadata: labels: app: jobcher-blog spec: containers: - name: jobcher-blog-pod image: hub.docker.com/blog/hugo:latest 执行命令\nkubectl rollout restart deployment jobcher-blog-deployment","title":"kubernetes 调度过程"},{"content":"Golang go build 编译不同系统下的可执行文件 Mac 系统编译 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build test.go CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go Linux 系统编译 CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build test.go CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go windows 系统编译 SET CGO_ENABLED=0 SET GOOS=darwin3 SET GOARCH=amd64 go build test.go SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 go build test.go GOOS：目标可执行程序运行操作系统，支持 darwin，freebsd，linux，windows GOARCH：目标可执行程序操作系统构架，包括 386，amd64，arm ","permalink":"https://test.jobcher.com/golang-go-build-%E7%BC%96%E8%AF%91%E4%B8%8D%E5%90%8C%E7%89%88%E6%9C%AC.html","summary":"Golang go build 编译不同系统下的可执行文件 Mac 系统编译 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build test.go CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go Linux 系统编译 CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build test.go CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go windows 系统编译 SET CGO_ENABLED=0 SET GOOS=darwin3 SET GOARCH=amd64 go build test.go SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 go build test.go GOOS：目标可执行程序运行操作系统，支持 darwin，freebsd，linux，windows GOARCH：目标可执行程序操作系统构架，包括 386，amd64，arm ","title":"Golang go build 编译不同版本"},{"content":"记录一次上门打散工 壬寅年头磨难多\n人间规则奈吾何\n吟诗为把瘟神送\n风起大江扬洪波\n疫情减弱，遍邀亲友，无人相约，但闻昔日挚友，感怀往事邀吾往之。欲把殷勤牵挂诉，幸之。遂至友舍，诉之：帮忙装个监控吧～\n买物料 和朋友两个人出发，帮朋友邻居家装个监控，他这个监控是要求装在车库里，但是网线要从 4 楼下放下去。所以，我们首先要出门购买一下物料：\n带 RJ45 接口监控 足够长的网线 走了 10000 多步人都走傻了～\n布线 这个没啥好说的，纯粹体力活，感谢朋友的暴风之锤，提高了工作效率，加快了项目进度 感谢 感谢朋友，给我这次项目实践和锻炼的机会让我认识到了自己的能力的不足～\n欢迎关注我的博客www.jobcher.com\n","permalink":"https://test.jobcher.com/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E4%B8%8A%E9%97%A8%E6%89%93%E6%95%A3%E5%B7%A5.html","summary":"记录一次上门打散工 壬寅年头磨难多\n人间规则奈吾何\n吟诗为把瘟神送\n风起大江扬洪波\n疫情减弱，遍邀亲友，无人相约，但闻昔日挚友，感怀往事邀吾往之。欲把殷勤牵挂诉，幸之。遂至友舍，诉之：帮忙装个监控吧～\n买物料 和朋友两个人出发，帮朋友邻居家装个监控，他这个监控是要求装在车库里，但是网线要从 4 楼下放下去。所以，我们首先要出门购买一下物料：\n带 RJ45 接口监控 足够长的网线 走了 10000 多步人都走傻了～\n布线 这个没啥好说的，纯粹体力活，感谢朋友的暴风之锤，提高了工作效率，加快了项目进度 感谢 感谢朋友，给我这次项目实践和锻炼的机会让我认识到了自己的能力的不足～\n欢迎关注我的博客www.jobcher.com","title":"记录一次上门打散工"},{"content":"ansible 命令 Inventory：Ansible 管理的主机信息，包括 IP 地址、SSH 端口、账号、密码等 Modules：任务均有模块完成，也可以自定义模块，例如经常用的脚本。 Plugins：使用插件增加 Ansible 核心功能，自身提供了很多插件，也可以自定义插件。例如 connection 插件，用于连接目标主机。 Playbooks：“剧本”，模块化定义一系列任务，供外部统一调用。Ansible 核心功能。 编辑主机清单 [webservers] 192.168.0.20 ansible_ssh_user=root ansible_ssh_pass=’200271200’ 192.168.0.21 ansible_ssh_user=root ansible_ssh_pass=’200271200’ 192.168.0.22 ansible_ssh_user=root ansible_ssh_pass=’200271200’ [dbservers] 10.12.0.100 10.12.0.101 sed -i \u0026amp;#34;s/#host_key_checking = .*/host_key_checking = False/g\u0026amp;#34; /etc/ansible/ansible.cfg 命令行 ansible all -m ping ansible all -m shell -a \u0026amp;#34;ls /root\u0026amp;#34; -u root -k 常用模块 在目标主机执行 shell 命令。\nshell - name: 将命令结果输出到指定文件 shell: somescript.sh \u0026amp;gt;\u0026amp;gt; somelog.txt - name: 切换目录执行命令 shell: cmd: ls -l | grep log chdir: somedir/ - name: 编写脚本 shell: | if [ 0 -eq 0 ]; then echo yes \u0026amp;gt; /tmp/result else echo no \u0026amp;gt; /tmp/result fi args: executable: /bin/bash copy 将文件复制到远程主机。 - name: 拷贝文件 copy: src: /srv/myfiles/foo.conf dest: /etc/foo.conf owner: foo group:","permalink":"https://test.jobcher.com/ansible-%E5%91%BD%E4%BB%A4.html","summary":"ansible 命令 Inventory：Ansible 管理的主机信息，包括 IP 地址、SSH 端口、账号、密码等 Modules：任务均有模块完成，也可以自定义模块，例如经常用的脚本。 Plugins：使用插件增加 Ansible 核心功能，自身提供了很多插件，也可以自定义插件。例如 connection 插件，用于连接目标主机。 Playbooks：“剧本”，模块化定义一系列任务，供外部统一调用。Ansible 核心功能。 编辑主机清单 [webservers] 192.168.0.20 ansible_ssh_user=root ansible_ssh_pass=’200271200’ 192.168.0.21 ansible_ssh_user=root ansible_ssh_pass=’200271200’ 192.168.0.22 ansible_ssh_user=root ansible_ssh_pass=’200271200’ [dbservers] 10.12.0.100 10.12.0.101 sed -i \u0026#34;s/#host_key_checking = .*/host_key_checking = False/g\u0026#34; /etc/ansible/ansible.cfg 命令行 ansible all -m ping ansible all -m shell -a \u0026#34;ls /root\u0026#34; -u root -k 常用模块 在目标主机执行 shell 命令。\nshell - name: 将命令结果输出到指定文件 shell: somescript.sh \u0026gt;\u0026gt; somelog.txt - name: 切换目录执行命令 shell: cmd: ls -l | grep log chdir: somedir/ - name: 编写脚本 shell: | if [ 0 -eq 0 ]; then echo yes \u0026gt; /tmp/result else echo no \u0026gt; /tmp/result fi args: executable: /bin/bash copy 将文件复制到远程主机。 - name: 拷贝文件 copy: src: /srv/myfiles/foo.","title":"ansible 命令"},{"content":"Ant 中如何添加第三方 jar 包依赖 如果使用 ant 进行 java 项目的编译部署，那怎么添加第三方 jar 包的依赖呢？方法如下：\n在项目的根目录下创建 lib 目录，并把所有需要的第三方 jar 包放到此目录下。 在 build.xml 中依次添加：path、property，并在 javac 中添加 classpath，添加 unjar。完整配置如下： \u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;project name=\u0026amp;#34;MyTool\u0026amp;#34; default=\u0026amp;#34;build\u0026amp;#34; basedir=\u0026amp;#34;.\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;description\u0026amp;gt;The ant project to build MyTool.\u0026amp;lt;/description\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;srcDir\u0026amp;#34; location=\u0026amp;#34;src\u0026amp;#34; description=\u0026amp;#34;源文件的存放目录\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;libDir\u0026amp;#34; location=\u0026amp;#34;lib\u0026amp;#34; description=\u0026amp;#34;第三方jar包的存放目录\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;antDir\u0026amp;#34; location=\u0026amp;#34;ant\u0026amp;#34; description=\u0026amp;#34;编译后所有文件存放的根目录\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;binDir\u0026amp;#34; location=\u0026amp;#34;${antDir}/bin\u0026amp;#34; description=\u0026amp;#34;编译后class文件的存放目录\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;jarDir\u0026amp;#34; location=\u0026amp;#34;${antDir}/jar\u0026amp;#34; description=\u0026amp;#34;打包后jar包的存放目录\u0026amp;#34; /\u0026amp;gt; \u0026amp;lt;property name=\u0026amp;#34;jarFile\u0026amp;#34; location=\u0026amp;#34;${jarDir}/MyTool.jar\u0026amp;#34; description=\u0026amp;#34;打包后jar包存放的完整路","permalink":"https://test.jobcher.com/ant%E4%B8%AD%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E7%AC%AC%E4%B8%89%E6%96%B9jar%E5%8C%85%E4%BE%9D%E8%B5%96.html","summary":"Ant 中如何添加第三方 jar 包依赖 如果使用 ant 进行 java 项目的编译部署，那怎么添加第三方 jar 包的依赖呢？方法如下：\n在项目的根目录下创建 lib 目录，并把所有需要的第三方 jar 包放到此目录下。 在 build.xml 中依次添加：path、property，并在 javac 中添加 classpath，添加 unjar。完整配置如下： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project name=\u0026#34;MyTool\u0026#34; default=\u0026#34;build\u0026#34; basedir=\u0026#34;.\u0026#34;\u0026gt; \u0026lt;description\u0026gt;The ant project to build MyTool.\u0026lt;/description\u0026gt; \u0026lt;property name=\u0026#34;srcDir\u0026#34; location=\u0026#34;src\u0026#34; description=\u0026#34;源文件的存放目录\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;libDir\u0026#34; location=\u0026#34;lib\u0026#34; description=\u0026#34;第三方jar包的存放目录\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;antDir\u0026#34; location=\u0026#34;ant\u0026#34; description=\u0026#34;编译后所有文件存放的根目录\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;binDir\u0026#34; location=\u0026#34;${antDir}/bin\u0026#34; description=\u0026#34;编译后class文件的存放目录\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jarDir\u0026#34; location=\u0026#34;${antDir}/jar\u0026#34; description=\u0026#34;打包后jar包的存放目录\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jarFile\u0026#34; location=\u0026#34;${jarDir}/MyTool.jar\u0026#34; description=\u0026#34;打包后jar包存放的完整路","title":"Ant中如何添加第三方jar包依赖"},{"content":"k8s 本地联调神器 kt-connect 转载自 Bboysoul\u0026amp;rsquo;sBlog\nk8s 集群内部的服务网络怎么和我们本地网络打通。kt-connect 就是用来解决这个问题的\n使用方法 下载安装什么的都很简单，一个二进制而已\nhttps://github.com/alibaba/kt-connect 如果你安装好了，那么直接使用下面的命令使用就好了\nsudo ktctl connect 当然也可以指定配置文件\nsudo ktctl --kubeconfig ~/.kube/local connect 执行完成之后，这个集群的所有svc都可以直接在本地解析，当然直接 ping pod 的 ip 也是可以的\n","permalink":"https://test.jobcher.com/k8s%E6%9C%AC%E5%9C%B0%E8%81%94%E8%B0%83%E7%A5%9E%E5%99%A8kt-connect.html","summary":"k8s 本地联调神器 kt-connect 转载自 Bboysoul\u0026rsquo;sBlog\nk8s 集群内部的服务网络怎么和我们本地网络打通。kt-connect 就是用来解决这个问题的\n使用方法 下载安装什么的都很简单，一个二进制而已\nhttps://github.com/alibaba/kt-connect 如果你安装好了，那么直接使用下面的命令使用就好了\nsudo ktctl connect 当然也可以指定配置文件\nsudo ktctl --kubeconfig ~/.kube/local connect 执行完成之后，这个集群的所有svc都可以直接在本地解析，当然直接 ping pod 的 ip 也是可以的","title":"k8s本地联调神器kt-connect"},{"content":"OpenELB：云原生负载均衡器插件 OpenELB 是一个开源的云原生负载均衡器实现，可以在基于裸金属服务器、边缘以及虚拟化的 Kubernetes 环境中使用 LoadBalancer 类型的 Service 对外暴露服务。\n在 Kubernetes 中安装 OpenELB kubectl apply -f https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml 查看状态 kubectl get po -n openelb-system 使用 kubectl 删除 OpenELB kubectl delete -f https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml kubectl get ns 配置 OpenELB kubectl edit configmap kube-proxy -n kube-system # 修改 网卡 ipvs: strictARP: true 重启组件 kubectl rollout restart daemonset kube-proxy -n kube-system 为 master1 节点添加一个 annotation 来指定网卡： kubectl annotate nodes master1 layer2.openelb.kubesphere.io/v1alpha1=\u0026amp;#34;192.168.0.2\u0026amp;#34; 创建地址池 layer2-eip.yaml apiVersion: network.kubesphere.io/v1alpha2 kind: Eip metadata: name: layer2-eip spec: address: 192.168.0.91-192.168.0.100 interface: eth0 protocol: layer2 创建部署 jobcher-service.yaml #暴露端口 apiVersion: v1 kind: Service metadata: name: jobcher-service annotations: lb.kubesphere.io/v1alpha1: openelb","permalink":"https://test.jobcher.com/openelb%E8%AE%A9k8s%E7%A7%81%E6%9C%89%E7%8E%AF%E5%A2%83%E5%AF%B9%E5%A4%96%E6%9A%B4%E9%9C%B2%E7%AB%AF%E5%8F%A3.html","summary":"OpenELB：云原生负载均衡器插件 OpenELB 是一个开源的云原生负载均衡器实现，可以在基于裸金属服务器、边缘以及虚拟化的 Kubernetes 环境中使用 LoadBalancer 类型的 Service 对外暴露服务。\n在 Kubernetes 中安装 OpenELB kubectl apply -f https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml 查看状态 kubectl get po -n openelb-system 使用 kubectl 删除 OpenELB kubectl delete -f https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml kubectl get ns 配置 OpenELB kubectl edit configmap kube-proxy -n kube-system # 修改 网卡 ipvs: strictARP: true 重启组件 kubectl rollout restart daemonset kube-proxy -n kube-system 为 master1 节点添加一个 annotation 来指定网卡： kubectl annotate nodes master1 layer2.openelb.kubesphere.io/v1alpha1=\u0026#34;192.168.0.2\u0026#34; 创建地址池 layer2-eip.yaml apiVersion: network.kubesphere.io/v1alpha2 kind: Eip metadata: name: layer2-eip spec: address: 192.","title":"OpenELB：让k8s私有环境对外暴露端口"},{"content":"kubernetes ansible 自动化部署 服务器规划 角色 IP 组件 k8s-master1 10.12.12.15 kube-apiserver kube-controller-manager kube-scheduler etcd k8s-master2 10.12.12.17 kube-apiserver kube-controller-manager kube-scheduler etcd k8s-02 10.12.12.22 kubelet kube-proxy docker etcd k8s-03 10.12.12.21 kubelet kube-proxy docker etcd load Balancer(master) 10.12.12.15 10.12.12.23(VIP) nginx keepalived load Balancer(backup) 10.12.12.17 nginx keepalived 系统初始化 关闭 selinux，firewalld 关闭 swap 时间同步 写 hosts ssh 免密（可选） etcd 集群部署 生成 etcd 证书 部署三个 ETC 集群 查看集群状态 部署 Masterß 生成 apiserver 证书 部署 apiserver、controller-manager 和 scheduler 组件 启动 TLS Bootstrapping 部署 Node 安装 Docker 部署 Kubelet 和 kube-proxy 在 Master 上运行为新 Node 颁发证书 授权 apiserver 访问 kubelet 部署插件（准备好镜像） Flannel Web UI CoreDNS Ingress Controller Master 高可用 增加 Master 节点（与 Master1 一致） 部署 nginx 负载均衡器 Nginx+Keepalived 高可用 修改 Node 连接 VIP ","permalink":"https://test.jobcher.com/kubernetes-ansible%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2.html","summary":"kubernetes ansible 自动化部署 服务器规划 角色 IP 组件 k8s-master1 10.12.12.15 kube-apiserver kube-controller-manager kube-scheduler etcd k8s-master2 10.12.12.17 kube-apiserver kube-controller-manager kube-scheduler etcd k8s-02 10.12.12.22 kubelet kube-proxy docker etcd k8s-03 10.12.12.21 kubelet kube-proxy docker etcd load Balancer(master) 10.12.12.15 10.12.12.23(VIP) nginx keepalived load Balancer(backup) 10.12.12.17 nginx keepalived 系统初始化 关闭 selinux，firewalld 关闭 swap 时间同步 写 hosts ssh 免密（可选） etcd 集群部署 生成 etcd 证书 部署三个 ETC 集群 查看集群状态 部署 Masterß 生成 apiserver 证书 部署 apiserver、controller-manager 和 scheduler 组件 启动 TLS Bootstrapping 部署 Node 安装 Docker 部署 Kubelet 和 kube-proxy 在 Master 上运行为新 Node 颁发证书 授权 apiserver 访问 kubelet 部署插件（准备好镜像） Flannel Web UI CoreDNS Ingress Controller Master 高可用 增加 Master 节点（与 Master1 一致） 部署 nginx 负载均衡器 Nginx+Keepalived 高可用 修改 Node 连接 VIP ","title":"kubernetes ansible自动化部署"},{"content":"Git 飞行规则(Flight Rules) 编辑提交(editting commits) 我刚才提交了什么? 我的提交信息(commit message)写错了 我提交(commit)里的用户名和邮箱不对 我想从一个提交(commit)里移除一个文件 我想删除我的的最后一次提交(commit) 删除任意提交(commit) 我尝试推一个修正后的提交(amended commit)到远程，但是报错： 我意外的做了一次硬重置(hard reset)，我想找回我的内容 暂存(Staging) 我需要把暂存的内容添加到上一次的提交(commit) 我想要暂存一个新文件的一部分，而不是这个文件的全部 我想把在一个文件里的变化(changes)加到两个提交(commit)里 我想把暂存的内容变成未暂存，把未暂存的内容暂存起来 未暂存(Unstaged)的内容 我想把未暂存的内容移动到一个新分支 我想把未暂存的内容移动到另一个已存在的分支 我想丢弃本地未提交的变化(uncommitted changes) 我想丢弃某些未暂存的内容 分支(Branches) 我从错误的分支拉取了内容，或把内容拉取到了错误的分支 我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致 我需要提交到一个新分支，但错误的提交到了 main 我想保留来自另外一个 ref-ish 的整个文件 我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里 我想删除上游(upstream)分支被删除了的本地分支 我不小心删除了我的分支 我想删除一个分支 我想从别人正在工作的远程分支签出(checkout)一个分支 Rebasing 和合并(Merging) 我想撤销 rebase/merge 我已经 rebase 过, 但是我不想强推(force push) 我需要组合(combine)几个提交(commit) 安全合并(merging)策略 我需要将一个分支合并成一个提交(commit) 我只想组合(combine)未推的提交(unpushed commit) 检查是否分支上的所有提交(commit)都合并(merge)过了 交互式 rebase(interactive rebase)可能出现的问题 这个 rebase 编辑屏幕出现\u0026amp;rsquo;noop\u0026amp;rsquo; 有冲突的情况 Stash 暂存所有改动 暂存指定文件 暂","permalink":"https://test.jobcher.com/git-%E8%A7%84%E5%88%99.html","summary":"Git 飞行规则(Flight Rules) 编辑提交(editting commits) 我刚才提交了什么? 我的提交信息(commit message)写错了 我提交(commit)里的用户名和邮箱不对 我想从一个提交(commit)里移除一个文件 我想删除我的的最后一次提交(commit) 删除任意提交(commit) 我尝试推一个修正后的提交(amended commit)到远程，但是报错： 我意外的做了一次硬重置(hard reset)，我想找回我的内容 暂存(Staging) 我需要把暂存的内容添加到上一次的提交(commit) 我想要暂存一个新文件的一部分，而不是这个文件的全部 我想把在一个文件里的变化(changes)加到两个提交(commit)里 我想把暂存的内容变成未暂存，把未暂存的内容暂存起来 未暂存(Unstaged)的内容 我想把未暂存的内容移动到一个新分支 我想把未暂存的内容移动到另一个已存在的分支 我想丢弃本地未提交的变化(uncommitted changes) 我想丢弃某些未暂存的内容 分支(Branches) 我从错误的分支拉取了内容，或把内容拉取到了错误的分支 我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致 我需要提交到一个新分支，但错误的提交到了 main 我想保留来自另外一个 ref-ish 的整个文件 我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里 我想删除上游(upstream)分支被删除了的本地分支 我不小心删除了我的分支 我想删除一个分支 我想从别人正在工作的远程分支签出(checkout)一个分支 Rebasing 和合并(Merging) 我想撤销 rebase/merge 我已经 rebase 过, 但是我不想强推(force push) 我需要组合(combine)几个提交(commit) 安全合并(merging)策略 我需要将一个分支合并成一个提交(commit) 我只想组合(combine)未推的提交(unpushed commit) 检查是否分支上的所有提交(commit)都合并(merge)过了 交互式 rebase(interactive rebase)可能出现的问题 这个 rebase 编辑屏幕出现\u0026rsquo;noop\u0026rsquo; 有冲突的情况 Stash 暂存所有改动 暂存指定文件 暂","title":"Git 规则"},{"content":"shell 脚本之变量 变量替换 语法 说明 ${变量名#匹配规则} 从变量开头进行规则匹配，将符合最短的数据删除 ${变量名##匹配规则} 从变量开头进行规则匹配，将符合最长的数据删除 ${变量名%匹配规则} 从变量尾部进行规则匹配，将符合最短的数据删除 ${变量名%%匹配规则} 从变量尾部进行规则匹配，将符合最长的数据删除 ${变量名/旧字符串/新字符串} 变量内容符合旧字符串则，则第一个旧字符串会被新字符串取代 ${变量名//旧字符串/新字符串} 变量内容符合旧字符串则，则全部的旧字符串会被新字符串取代 字符串处理 计算字符串长度 - 语法 说明 方法一 ${#string} 无 方法二 expr length \u0026amp;ldquo;$string\u0026amp;rdquo; string 有空格，则必须加双引号 获取子串在字符串中的索引位置\n语法： expr index $string $substring\n计算子串长度\n语法： expr match $string substr\n抽取子串\n${string:position} ：从 string 中的 position 开始 ${string:position:length}：从 position 开始，匹配长度为 length ${string:-position}：从右边开始匹配 ${string:(position)}：从左边开始匹配 expr substr $string $position $length：从 position 开始，匹配长度为 length ","permalink":"https://test.jobcher.com/shell-%E8%84%9A%E6%9C%AC1.html","summary":"shell 脚本之变量 变量替换 语法 说明 ${变量名#匹配规则} 从变量开头进行规则匹配，将符合最短的数据删除 ${变量名##匹配规则} 从变量开头进行规则匹配，将符合最长的数据删除 ${变量名%匹配规则} 从变量尾部进行规则匹配，将符合最短的数据删除 ${变量名%%匹配规则} 从变量尾部进行规则匹配，将符合最长的数据删除 ${变量名/旧字符串/新字符串} 变量内容符合旧字符串则，则第一个旧字符串会被新字符串取代 ${变量名//旧字符串/新字符串} 变量内容符合旧字符串则，则全部的旧字符串会被新字符串取代 字符串处理 计算字符串长度 - 语法 说明 方法一 ${#string} 无 方法二 expr length \u0026ldquo;$string\u0026rdquo; string 有空格，则必须加双引号 获取子串在字符串中的索引位置\n语法： expr index $string $substring\n计算子串长度\n语法： expr match $string substr\n抽取子串\n${string:position} ：从 string 中的 position 开始 ${string:position:length}：从 position 开始，匹配长度为 length ${string:-position}：从右边开始匹配 ${string:(position)}：从左边开始匹配 expr substr $string $position $length：从 position 开始，匹配长度为 length ","title":"shell 脚本（1）"},{"content":"kubernetes 脚本快速安装 1、三台机器设置自己的 hostname（不能是 localhost） # 修改 hostname; k8s-01要变为自己的hostname hostnamectl set-hostname k8s-01 # 设置 hostname 解析 echo \u0026amp;#34;127.0.0.1 $(hostname)\u0026amp;#34; \u0026amp;gt;\u0026amp;gt; /etc/hosts 2、所有机器批量执行如下脚本\n#先在所有机器执行 vi k8s.sh # 进入编辑模式（输入i），把如下脚本复制 # 所有机器给脚本权限 chmod +x k8s.sh #执行脚本 ./k8s.sh #/bin/sh #######################开始设置环境##################################### \\n printf \u0026amp;#34;##################正在配置所有基础环境信息################## \\n\u0026amp;#34; printf \u0026amp;#34;##################关闭selinux################## \\n\u0026amp;#34; sed -i \u0026amp;#39;s/enforcing/disabled/\u0026amp;#39; /etc/selinux/config setenforce 0 printf \u0026amp;#34;##################关闭swap################## \\n\u0026amp;#34; swapoff -a sed -ri \u0026amp;#39;s/.*swap.*/#\u0026amp;amp;/\u0026amp;#39; /etc/fstab printf \u0026amp;#34;##################配置路由转发################## \\n\u0026amp;#34; cat \u0026amp;lt;\u0026amp;lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF echo \u0026amp;#39;net.ipv4.ip_forward = 1\u0026amp;#39; \u0026amp;gt;\u0026amp;gt; /etc/sysctl.d/k8s.conf ## 必须 ipv6流量桥接 echo \u0026amp;#39;net.bridge.bridge-nf-call-ip6tables = 1\u0026amp;#39; \u0026amp;gt;\u0026amp;gt; /etc/sysctl.d/k8s.conf ## 必须 ipv4流","permalink":"https://test.jobcher.com/kubernetes-%E8%84%9A%E6%9C%AC%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85.html","summary":"kubernetes 脚本快速安装 1、三台机器设置自己的 hostname（不能是 localhost） # 修改 hostname; k8s-01要变为自己的hostname hostnamectl set-hostname k8s-01 # 设置 hostname 解析 echo \u0026#34;127.0.0.1 $(hostname)\u0026#34; \u0026gt;\u0026gt; /etc/hosts 2、所有机器批量执行如下脚本\n#先在所有机器执行 vi k8s.sh # 进入编辑模式（输入i），把如下脚本复制 # 所有机器给脚本权限 chmod +x k8s.sh #执行脚本 ./k8s.sh #/bin/sh #######################开始设置环境##################################### \\n printf \u0026#34;##################正在配置所有基础环境信息################## \\n\u0026#34; printf \u0026#34;##################关闭selinux################## \\n\u0026#34; sed -i \u0026#39;s/enforcing/disabled/\u0026#39; /etc/selinux/config setenforce 0 printf \u0026#34;##################关闭swap################## \\n\u0026#34; swapoff -a sed -ri \u0026#39;s/.*swap.*/#\u0026amp;/\u0026#39; /etc/fstab printf \u0026#34;##################配置路由转发################## \\n\u0026#34; cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF echo \u0026#39;net.","title":"kubernetes 脚本快速安装"},{"content":"Maven 安装编译 Maven 就是专门为 Java 项目打造的管理和构建工具，它的主要功能有：\n提供了一套标准化的项目结构； 提供了一套标准化的构建流程（编译，测试，打包，发布……）； 提供了一套依赖管理机制。 默认结构：\na-maven-project ├── pom.xml ├── src │ ├── main │ │ ├── java │ │ └── resources │ └── test │ ├── java │ └── resources └── target 项目的根目录a-maven-project是项目名，\n它有一个项目描述文件pom.xml，\n存放Java源码的目录是src/main/java，\n存放资源文件的目录是src/main/resources，\n存放测试源码的目录是src/test/java，\n存放测试资源的目录是src/test/resources，\n最后，所有编译、打包生成的文件都放在target目录里。\n这些就是一个 Maven 项目的标准目录结构。\npom.xml 文件:\n\u0026amp;lt;project ...\u0026amp;gt; \u0026amp;lt;modelVersion\u0026amp;gt;4.0.0\u0026amp;lt;/modelVersion\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.itranswarp.learnjava\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;hello\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;packaging\u0026amp;gt;jar\u0026amp;lt;/packaging\u0026amp;gt; \u0026amp;lt;properties\u0026amp;gt; ... \u0026amp;lt;/properties\u0026amp;gt; \u0026amp;lt;dependencies\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;commons-logging\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;commons-logging\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.2\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;/dependencies\u0026amp;gt; \u0026amp;lt;/project\u0026amp;gt; groupId类似于 Java 的包名，通常是公司或组织名称，\nartifactId类","permalink":"https://test.jobcher.com/maven-%E5%AE%89%E8%A3%85%E7%BC%96%E8%AF%91.html","summary":"Maven 安装编译 Maven 就是专门为 Java 项目打造的管理和构建工具，它的主要功能有：\n提供了一套标准化的项目结构； 提供了一套标准化的构建流程（编译，测试，打包，发布……）； 提供了一套依赖管理机制。 默认结构：\na-maven-project ├── pom.xml ├── src │ ├── main │ │ ├── java │ │ └── resources │ └── test │ ├── java │ └── resources └── target 项目的根目录a-maven-project是项目名，\n它有一个项目描述文件pom.xml，\n存放Java源码的目录是src/main/java，\n存放资源文件的目录是src/main/resources，\n存放测试源码的目录是src/test/java，\n存放测试资源的目录是src/test/resources，\n最后，所有编译、打包生成的文件都放在target目录里。\n这些就是一个 Maven 项目的标准目录结构。\npom.xml 文件:\n\u0026lt;project ...\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.itranswarp.learnjava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hello\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;properties\u0026gt; ... \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-logging\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-logging\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; groupId类似于 Java 的包名，通常是公司或组织名称，","title":"Maven 安装编译"},{"content":"Nodejs 安装编译 Node.js 平台是在后端运行 JavaScript 代码，必须首先在本机安装 Node 环境。\n安装 Node.js 安装 npm npm 其实是 Node.js 的包管理工具（package manager）。\n","permalink":"https://test.jobcher.com/nodejs-%E5%AE%89%E8%A3%85%E7%BC%96%E8%AF%91.html","summary":"Nodejs 安装编译 Node.js 平台是在后端运行 JavaScript 代码，必须首先在本机安装 Node 环境。\n安装 Node.js 安装 npm npm 其实是 Node.js 的包管理工具（package manager）。","title":"Nodejs 安装编译"},{"content":"基础环境安装 # docker 脚本安装 curl -sSL https://get.daocloud.io/docker | sh #docker compose 脚本安装 curl -L https://get.daocloud.io/docker/compose/releases/download/v2.4.1/docker-compose-`uname -s`-`uname -m` \u0026amp;gt; /usr/local/bin/docker-compose #可执行权限 sudo chmod +x /usr/local/bin/docker-compose #创建软链： sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose #测试是否安装成功 docker-compose --version 下载安装 git clone https://gitlab.sanjiang.com/it-group/ruoyi-cloud.git 编译 cd ruoyi-cloud mvn clean install -DskipTests 复制 jar 包 cd ./docker ./copy.sh 部署 docker ./deploy.sh base ./deploy.sh modules 检查 docker docker ps -a | grep ruoyi docker logs -f ruoyi-auth docker logs -f ruoyi-gateway docker logs -f ruoyi-modules-system ","permalink":"https://test.jobcher.com/ruoyi-cloud-docker%E9%83%A8%E7%BD%B2.html","summary":"基础环境安装 # docker 脚本安装 curl -sSL https://get.daocloud.io/docker | sh #docker compose 脚本安装 curl -L https://get.daocloud.io/docker/compose/releases/download/v2.4.1/docker-compose-`uname -s`-`uname -m` \u0026gt; /usr/local/bin/docker-compose #可执行权限 sudo chmod +x /usr/local/bin/docker-compose #创建软链： sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose #测试是否安装成功 docker-compose --version 下载安装 git clone https://gitlab.sanjiang.com/it-group/ruoyi-cloud.git 编译 cd ruoyi-cloud mvn clean install -DskipTests 复制 jar 包 cd ./docker ./copy.sh 部署 docker ./deploy.sh base ./deploy.sh modules 检查 docker docker ps -a | grep ruoyi docker logs -f ruoyi-auth docker logs -f ruoyi-gateway docker logs -f ruoyi-modules-system ","title":"ruoyi-cloud docker部署"},{"content":"git 版本控制 版本回退 1.查看 git 提交历史 #查看git提交历史 git log 如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline参数\ngit log --pretty=oneline 2.回退到上一个版本 Git必须知道当前版本是哪个版本，在 Git 中，用HEAD表示当前版本，也就是最新的提交b534d741..（注意我的提交 ID 和你的肯定不一样），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上 100 个版本写 100 个^比较容易数不过来，所以写成HEAD~100\ngit reset --hard HEAD^ 最新的那个版本已经看不到了，可以顺着往上找，找到那个版本的 ID\ngit reset --hard c8275ca Git 在内部有个指向当前版本的HEAD指针,当你回退版本的时候，Git 仅仅是把HEAD从指向update\n┌────┐ │HEAD│ └────┘ │ └──\u0026amp;gt; ○ update │ ○ Create README.md │ ○ init 改为指向 Create README.md：\n┌────┐ │HEAD│ └────┘ │ │ ○ update │ │ └──\u0026amp;gt; ○ Create README.md │ ○ init 现在，你回退到了某个版本，关掉了电脑，第二天早上就后悔了，想恢复到新版本怎么办？找不到新版本的commit id怎么办？\n在 Git 中，总是有后悔药可以吃的。当你用$ git reset --hard HEAD^回退到Create README.md版本时，再想恢复到update，就必须找到update的 commit id。Git 提供了一个命令git reflog用来记录你的每一次命令：\ngit reflog 3.总结一下： HEAD指向的版本就是当前版本，因此，Git 允许我们在版本的历史之间穿梭，使用命令git reset --hard commit_id。 穿梭前，用git log可以查看提交历史，以便确定要回退到哪个版本。 要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。 工作区和暂存区 工作区（Working Directory）\n就是你在电脑里能看到的目录，比如我的shell文件夹就是一个工作区\n版本库（Repository）\n工作区有一","permalink":"https://test.jobcher.com/git%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6.html","summary":"git 版本控制 版本回退 1.查看 git 提交历史 #查看git提交历史 git log 如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline参数\ngit log --pretty=oneline 2.回退到上一个版本 Git必须知道当前版本是哪个版本，在 Git 中，用HEAD表示当前版本，也就是最新的提交b534d741..（注意我的提交 ID 和你的肯定不一样），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上 100 个版本写 100 个^比较容易数不过来，所以写成HEAD~100\ngit reset --hard HEAD^ 最新的那个版本已经看不到了，可以顺着往上找，找到那个版本的 ID\ngit reset --hard c8275ca Git 在内部有个指向当前版本的HEAD指针,当你回退版本的时候，Git 仅仅是把HEAD从指向update\n┌────┐ │HEAD│ └────┘ │ └──\u0026gt; ○ update │ ○ Create README.md │ ○ init 改为指向 Create README.md：\n┌────┐ │HEAD│ └────┘ │ │ ○ update │ │ └──\u0026gt; ○ Create README.md │ ○ init 现在，你回退到了某个版本，关掉了电脑，第二天早上就后悔了，想恢复到新版本怎么办？找不到新版本的commit id怎么办？","title":"git版本控制"},{"content":"Linux crontab 命令 Linux crontab是用来定期执行程序的命令。\n系统执行的工作：系统周期性所要执行的工作，如备份系统数据、清理缓存 个人执行的工作：某个用户定期要做的工作，例如每隔10分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置 语法 crontab [ -u user ] file crontab [ -u user ] { -l | -r | -e } 说明：\ncrontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。\n-u user 是指设定指定 user 的时程表，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的时程表。\n参数说明：\n-e : 执行文字编辑器来设定时程表，内定的文字编辑器是 VI，如果你想用别的文字编辑器，则请先设定 VISUAL 环境变数来指定使用那个文字编辑器(比如说 setenv VISUAL joe)\n-r : 删除目前的时程表\n-l : 列出目前的时程表\n时间格式如下：\nf1 f2 f3 f4 f5 program * * * * * - - - - - | | | | | | | | | +----- 星期中星期几 (0 - 6) (星期天 为0) | | | +---------- 月份 (1 - 12) | | +--------------- 一个月中的第几天 (1 - 31) | +-------------------- 小时 (0 - 23) +------------------------- 分钟 (0 - 59) 其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程序。 当 f1 为 * 时表示每分钟都要执行 program，f2 为 * 时表示每小时都要执行程序，其馀类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次，f2 为 */n 表示每 n 小时个时间间隔执行一次，其馀类推 当 f1 为 a, b, c,... 时表示第 a, b, c,... 分钟要执","permalink":"https://test.jobcher.com/linux-crontab-%E5%91%BD%E4%BB%A4.html","summary":"Linux crontab 命令 Linux crontab是用来定期执行程序的命令。\n系统执行的工作：系统周期性所要执行的工作，如备份系统数据、清理缓存 个人执行的工作：某个用户定期要做的工作，例如每隔10分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置 语法 crontab [ -u user ] file crontab [ -u user ] { -l | -r | -e } 说明：\ncrontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。\n-u user 是指设定指定 user 的时程表，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的时程表。\n参数说明：\n-e : 执行文字编辑器来设定时程表，内定的文字编辑器是 VI，如果你想用别的文字编辑器，则请先设定 VISUAL 环境变数来指定使用那个文字编辑器(比如说 setenv VISUAL joe)\n-r : 删除目前的时程表\n-l : 列出目前的时程表\n时间格式如下：\nf1 f2 f3 f4 f5 program * * * * * - - - - - | | | | | | | | | +----- 星期中星期几 (0 - 6) (星期天 为0) | | | +---------- 月份 (1 - 12) | | +--------------- 一个月中的第几天 (1 - 31) | +-------------------- 小时 (0 - 23) +------------------------- 分钟 (0 - 59) 其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程序。 当 f1 为 * 时表示每分钟都要执行 program，f2 为 * 时表示每小时都要执行程序，其馀类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次，f2 为 */n 表示每 n 小时个时间间隔执行一次，其馀类推 当 f1 为 a, b, c,.","title":"Linux crontab 命令"},{"content":"linux 网络测速 一键测试脚本bench.sh 适用于各种 Linux 发行版的网络（下行）和 IO 测试：\n显示当前测试的各种系统信息 取自世界多处的知名数据中心的测试点，下载测试比较全面 支持 IPv6 下载测速 IO 测试三次，并显示平均值 wget -qO- bench.sh | bash #或者下面这命令下载执行 curl -Lso- bench.sh | bash 欢迎关注我的博客www.jobcher.com\n","permalink":"https://test.jobcher.com/linux-%E7%BD%91%E7%BB%9C%E6%B5%8B%E9%80%9F.html","summary":"linux 网络测速 一键测试脚本bench.sh 适用于各种 Linux 发行版的网络（下行）和 IO 测试：\n显示当前测试的各种系统信息 取自世界多处的知名数据中心的测试点，下载测试比较全面 支持 IPv6 下载测速 IO 测试三次，并显示平均值 wget -qO- bench.sh | bash #或者下面这命令下载执行 curl -Lso- bench.sh | bash 欢迎关注我的博客www.jobcher.com","title":"linux 网络测速"},{"content":"docker 命令(2) docker ps 命令 docker ps 能查看所有运行中的容器\ndocker ps -a 能查看所有的容器\ndocker rm -f $(docker ps -aq) 强制删除所有容器\ndocker run和docker create有什么区别 docker create命令能够基于镜像创建容器。\n该命令执行的效果类似于docker run -d，即创建一个将在系统后台运行的容器。\n但是与docker run -d不同的是，docker create创建的容器并未实际启动，还需要执行docker start命令或docker run命令以启动容器。\n事实上，docker create 命令常用于在启动容器之前进行必要的设置。\n","permalink":"https://test.jobcher.com/docker-%E5%91%BD%E4%BB%A42.html","summary":"docker 命令(2) docker ps 命令 docker ps 能查看所有运行中的容器\ndocker ps -a 能查看所有的容器\ndocker rm -f $(docker ps -aq) 强制删除所有容器\ndocker run和docker create有什么区别 docker create命令能够基于镜像创建容器。\n该命令执行的效果类似于docker run -d，即创建一个将在系统后台运行的容器。\n但是与docker run -d不同的是，docker create创建的容器并未实际启动，还需要执行docker start命令或docker run命令以启动容器。\n事实上，docker create 命令常用于在启动容器之前进行必要的设置。","title":"docker 命令(2)"},{"content":"CICD 概念 DevOps Devlopment 和 Operation 的组合词\n规划-》代码-》构建-》测试-》发布-》部署-》运营-》监控-》再次规划\ndevOps 看作开发（软件工程）、技术运营和质量保障（QA）三者的交集 突出重视软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。 DevOps 希望做到的是软件产品交付过程中IT工具链的打通，使得各个团队减少时间损耗。更加高效的协同工作。良好的闭环可以大大增加整体的产出。 CICD 持续集成 持续部署\n持续集成\n持续集成是指软件个人研发的部分向软件整体部分交付，频繁进行集成以便更快地发现其中的错误。“持续集成”源自于极限编程（XP），是 12 最初的 12 种实践之一 Ci 需要具备这些： 全面的自动化测试，这是实践持续集成和持续部署的基础，同时，选择合适的自动化测试工具也极其重要； 灵活的基础设施。容器，虚拟化的存在让开发人员和QA不必再大费周折 版本控制工具。如git，cvs，svn等 自动化的构建和软件发布流程工具，如 Jenkins，flow.ci; 反馈机制，如构建/测试的失败，可以快速地反馈到相关负责人，以尽快解决达到一个更稳定的版本。 ","permalink":"https://test.jobcher.com/cicd-%E6%A6%82%E5%BF%B5.html","summary":"CICD 概念 DevOps Devlopment 和 Operation 的组合词\n规划-》代码-》构建-》测试-》发布-》部署-》运营-》监控-》再次规划\ndevOps 看作开发（软件工程）、技术运营和质量保障（QA）三者的交集 突出重视软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。 DevOps 希望做到的是软件产品交付过程中IT工具链的打通，使得各个团队减少时间损耗。更加高效的协同工作。良好的闭环可以大大增加整体的产出。 CICD 持续集成 持续部署\n持续集成\n持续集成是指软件个人研发的部分向软件整体部分交付，频繁进行集成以便更快地发现其中的错误。“持续集成”源自于极限编程（XP），是 12 最初的 12 种实践之一 Ci 需要具备这些： 全面的自动化测试，这是实践持续集成和持续部署的基础，同时，选择合适的自动化测试工具也极其重要； 灵活的基础设施。容器，虚拟化的存在让开发人员和QA不必再大费周折 版本控制工具。如git，cvs，svn等 自动化的构建和软件发布流程工具，如 Jenkins，flow.ci; 反馈机制，如构建/测试的失败，可以快速地反馈到相关负责人，以尽快解决达到一个更稳定的版本。 ","title":"CICD 概念"},{"content":"git 使用方法 一、git 安装配置 Debian/Ubuntu apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev apt-get install git git --version git version 1.8.1.2 Centos/RedHat yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel yum -y install git-core git --version git version 1.7.1 二、git 拉取异常如何重新拉取 1.同一文件有修改，产生冲突。 先将本地修改存储起来 使用git stash命令，这样本地的所有修改就都被暂时存储起来 。其中stash@{0}就是刚才保存的标记。后续可以通过此标记访问。 再次拉取代码 git pull 还原暂存的内容 git stash pop stash@{0} 解决冲突 在存在冲突的文件中，Updated upstream 和=====之间的内容为拉取下来的代码，=====和stashed changes之间的内容就为本地修改的代码。解决完成之后，就可以正常的提交了。 5.删除stash 使用git stash drop stash@{0}命令，如果不加stash编号，默认的就是删除最新的，即编号为 0 的。或者git stash clear命令，清除所有stash。 2.想要让某一个文件放弃修改，同步服务器。 git checkout [本地变动文件的路径] 3.服务器代码完全替换和覆盖本地的代码改动。 git fetch --all git reset --hard origin/master git pull 三、git 命令表格 专用名词 含义 Workspace 工作区 Index/Stage 暂存区 Repository 仓库区（或本地仓库） Remote 远程仓库 1.新建代码仓库 # 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url] 2.配置 Git 的设","permalink":"https://test.jobcher.com/git%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95.html","summary":"git 使用方法 一、git 安装配置 Debian/Ubuntu apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev apt-get install git git --version git version 1.8.1.2 Centos/RedHat yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel yum -y install git-core git --version git version 1.7.1 二、git 拉取异常如何重新拉取 1.同一文件有修改，产生冲突。 先将本地修改存储起来 使用git stash命令，这样本地的所有修改就都被暂时存储起来 。其中stash@{0}就是刚才保存的标记。后续可以通过此标记访问。 再次拉取代码 git pull 还原暂存的内容 git stash pop stash@{0} 解决冲突 在存在冲突的文件中，Updated upstream 和=====之间的内容为拉取下来的代码，=====和stashed changes之间的内容就为本地修改的代码。解决完成之后，就可以正常的提交了。 5.删除stash 使用git stash drop stash@{0}命令，如果不加stash编号，默认的就是删除最新的，即编号为 0 的。或者git stash clear命令，清除所有stash。 2.想要让某一个文件放弃修改，同步服务器。 git checkout [本地变动文件的路径] 3.","title":"git使用方法"},{"content":"kubernetes 面试题汇总 1、 k8s 是什么？请说出你的了解？ 答：Kubenetes 是一个针对容器应用，进行自动部署，弹性伸缩和管理的开源系统。主要功能是生产环境中的容器编排。\nK8S 是 Google 公司推出的，它来源于由 Google 公司内部使用了 15 年的 Borg 系统，集结了 Borg 的精华。\n2、 K8s 架构的组成是什么？ 答：和大多数分布式系统一样，K8S 集群至少需要一个主节点（Master）和多个计算节点（Node）。\n主节点主要用于暴露 API，调度部署和节点的管理；\n计算节点运行一个容器运行环境，一般是 docker 环境（类似 docker 环境的还有 rkt），同时运行一个 K8s 的代理（kubelet）用于和 master 通信。计算节点也会运行一些额外的组件，像记录日志，节点监控，服务发现等等。计算节点是 k8s 集群中真正工作的节点。\nK8S架构细分： 1、Master节点（默认不参加实际工作）： Kubectl：客户端命令行工具，作为整个K8s集群的操作入口； Api Server：在K8s架构中承担的是“桥梁”的角色，作为资源操作的唯一入口，它提供了认证、授权、访问控制、API注册和发现等机制。客户端与k8s群集及K8s内部组件的通信，都要通过Api Server这个组件； Controller-manager：负责维护群集的状态，比如故障检测、自动扩展、滚动更新等； Scheduler：负责资源的调度，按照预定的调度策略将pod调度到相应的node节点上； Etcd：担任数据中心的角色，保存了整个群集的状态； 2、Node节点： Kubelet：负责维护容器的生命周期，同时也负责Volume和网络的管理，一般运行在所有的节点，是Node节点的代理，当Scheduler确定某个node上运行pod之后，会将pod的具体信息（image，volume）等发送给该节点的kubelet，kubelet根据这些信息创建和运行容器，并向master返回运行状态。（自动修复功能：如果某个节点中的容器宕机，它会尝试重启该容器，若重启无效，则会将该pod杀死，然后重新创建一个容器）； Kube-proxy：Service在逻辑上代表了后端的多个pod。负责为Service提供cluster内部的服务发现和负载均衡（外界通过Service访问pod提供的服务","permalink":"https://test.jobcher.com/kubernetes%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB.html","summary":"kubernetes 面试题汇总 1、 k8s 是什么？请说出你的了解？ 答：Kubenetes 是一个针对容器应用，进行自动部署，弹性伸缩和管理的开源系统。主要功能是生产环境中的容器编排。\nK8S 是 Google 公司推出的，它来源于由 Google 公司内部使用了 15 年的 Borg 系统，集结了 Borg 的精华。\n2、 K8s 架构的组成是什么？ 答：和大多数分布式系统一样，K8S 集群至少需要一个主节点（Master）和多个计算节点（Node）。\n主节点主要用于暴露 API，调度部署和节点的管理；\n计算节点运行一个容器运行环境，一般是 docker 环境（类似 docker 环境的还有 rkt），同时运行一个 K8s 的代理（kubelet）用于和 master 通信。计算节点也会运行一些额外的组件，像记录日志，节点监控，服务发现等等。计算节点是 k8s 集群中真正工作的节点。\nK8S架构细分： 1、Master节点（默认不参加实际工作）： Kubectl：客户端命令行工具，作为整个K8s集群的操作入口； Api Server：在K8s架构中承担的是“桥梁”的角色，作为资源操作的唯一入口，它提供了认证、授权、访问控制、API注册和发现等机制。客户端与k8s群集及K8s内部组件的通信，都要通过Api Server这个组件； Controller-manager：负责维护群集的状态，比如故障检测、自动扩展、滚动更新等； Scheduler：负责资源的调度，按照预定的调度策略将pod调度到相应的node节点上； Etcd：担任数据中心的角色，保存了整个群集的状态； 2、Node节点： Kubelet：负责维护容器的生命周期，同时也负责Volume和网络的管理，一般运行在所有的节点，是Node节点的代理，当Scheduler确定某个node上运行pod之后，会将pod的具体信息（image，volume）等发送给该节点的kubelet，kubelet根据这些信息创建和运行容器，并向master返回运行状态。（自动修复功能：如果某个节点中的容器宕机，它会尝试重启该容器，若重启无效，则会将该pod杀死，然后重新创建一个容器）； Kube-proxy：Service在逻辑上代表了后端的多个pod。负责为Service提供cluster内部的服务发现和负载均衡（外界通过Service访问pod提供的服务","title":"kubernetes面试题汇总"},{"content":"Kubernetes 安装 环境配置 关闭防火墙： 如果是云服务器，需要设置安全组策略放行端口 systemctl stop firewalld systemctl disable firewalld 修改 hostname hostnamectl set-hostname k8s-01 echo \u0026amp;#34;127.0.0.1 $(hostname)\u0026amp;#34; \u0026amp;gt;\u0026amp;gt; /etc/hosts reboot 关闭 selinux： sed -i \u0026amp;#39;s/enforcing/disabled/\u0026amp;#39; /etc/selinux/config setenforce 0 关闭 swap： swapoff -a sed -ri \u0026amp;#39;s/.*swap.*/#\u0026amp;amp;/\u0026amp;#39; /etc/fstab 修改 /etc/sysctl.conf # 如果有配置，则修改 sed -i \u0026amp;#34;s#^net.ipv4.ip_forward.*#net.ipv4.ip_forward=1#g\u0026amp;#34; /etc/sysctl.conf sed -i \u0026amp;#34;s#^net.bridge.bridge-nf-call-ip6tables.*#net.bridge.bridge-nf-call-ip6tables=1#g\u0026amp;#34; /etc/sysctl.conf sed -i \u0026amp;#34;s#^net.bridge.bridge-nf-call-iptables.*#net.bridge.bridge-nf-call-iptables=1#g\u0026amp;#34; /etc/sysctl.conf sed -i \u0026amp;#34;s#^net.ipv6.conf.all.disable_ipv6.*#net.ipv6.conf.all.disable_ipv6=1#g\u0026amp;#34; /etc/sysctl.conf sed -i \u0026amp;#34;s#^net.ipv6.conf.default.disable_ipv6.*#net.ipv6.conf.default.disable_ipv6=1#g\u0026amp;#34; /etc/sysctl.conf sed -i \u0026amp;#34;s#^net.ipv6.conf.lo.disable_ipv6.*#net.ipv6.conf.lo.disable_ipv6=1#g\u0026amp;#34; /etc/sysctl.conf","permalink":"https://test.jobcher.com/kubernetes-%E5%AE%89%E8%A3%85.html","summary":"Kubernetes 安装 环境配置 关闭防火墙： 如果是云服务器，需要设置安全组策略放行端口 systemctl stop firewalld systemctl disable firewalld 修改 hostname hostnamectl set-hostname k8s-01 echo \u0026#34;127.0.0.1 $(hostname)\u0026#34; \u0026gt;\u0026gt; /etc/hosts reboot 关闭 selinux： sed -i \u0026#39;s/enforcing/disabled/\u0026#39; /etc/selinux/config setenforce 0 关闭 swap： swapoff -a sed -ri \u0026#39;s/.*swap.*/#\u0026amp;/\u0026#39; /etc/fstab 修改 /etc/sysctl.conf # 如果有配置，则修改 sed -i \u0026#34;s#^net.ipv4.ip_forward.*#net.ipv4.ip_forward=1#g\u0026#34; /etc/sysctl.conf sed -i \u0026#34;s#^net.bridge.bridge-nf-call-ip6tables.*#net.bridge.bridge-nf-call-ip6tables=1#g\u0026#34; /etc/sysctl.conf sed -i \u0026#34;s#^net.bridge.bridge-nf-call-iptables.*#net.bridge.bridge-nf-call-iptables=1#g\u0026#34; /etc/sysctl.conf sed -i \u0026#34;s#^net.ipv6.conf.all.disable_ipv6.*#net.ipv6.conf.all.disable_ipv6=1#g\u0026#34; /etc/sysctl.conf sed -i \u0026#34;s#^net.ipv6.conf.default.disable_ipv6.*#net.ipv6.conf.default.disable_ipv6=1#g\u0026#34; /etc/sysctl.conf sed -i \u0026#34;s#^net.ipv6.conf.lo.disable_ipv6.*#net.ipv6.conf.lo.disable_ipv6=1#g\u0026#34; /etc/sysctl.conf","title":"Kubernetes 安装"},{"content":"linux 常用命令 软件操作命令 #软件包管理器 yum # 安装软件 yum install xxxx # 卸载软件 yum remove xxx # 搜索软件 yum search xxx # 清理缓存 yum clean packages # 列出已安装 yum list # 软件包信息 yum info 服务器硬件资源和磁盘操作 # 内存 free -h # 硬盘 df -h # 负载 w/top/htop # 查看cpu cat /proc/cpuinfo # 查看磁盘 fdisk -l 文件和文件夹操作命令 命令 解释 ls 查看目录下的文件 touch 新建文件 mkdir 新建目录 cd 进入目录 rm 删除文件和目录 cp 复制 mv 移动 pwd 显示路径 系统用户操作命令 防火墙相关设置 提权操作 sudo 和文件传输 ","permalink":"https://test.jobcher.com/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html","summary":"linux 常用命令 软件操作命令 #软件包管理器 yum # 安装软件 yum install xxxx # 卸载软件 yum remove xxx # 搜索软件 yum search xxx # 清理缓存 yum clean packages # 列出已安装 yum list # 软件包信息 yum info 服务器硬件资源和磁盘操作 # 内存 free -h # 硬盘 df -h # 负载 w/top/htop # 查看cpu cat /proc/cpuinfo # 查看磁盘 fdisk -l 文件和文件夹操作命令 命令 解释 ls 查看目录下的文件 touch 新建文件 mkdir 新建目录 cd 进入目录 rm 删除文件和目录 cp 复制 mv 移动 pwd 显示路径 系统用户操作命令 防火墙相关设置 提权操作 sudo 和文件传输 ","title":"linux常用命令"},{"content":"linux 基础知识 1、简述 Linux 权限划分原则。 给文件或目录分配权限时，先考虑所有者和所属组 遵循最小化权限，用啥权限给啥权限 修改目录和子文件归属权限，注意递归 文件权限分配是最常用的安全防护手段 2、当用户 user1，对/testdir 目录有写和执行权限时，该目录下的只读文件 file1 是否可修改和删除？ 对 file1 不能修改也不能删除。（如果对目录有写权限和执行权限，则对 file1 不能修改可以删除）\n3、如果一个系统没有任何的备份策略，请写出一个较为全面合理的备份方案！ 增量备份：将相较于前一天增加的内容备份，适合每天改变量较大的数据。\n差异备份：将相较于第一天改变的内容备份，适合原始数据量比较大，但是之后改变的比较小，即使中间哪一天的丢了也没事，只要最后一天，和第一天的在就行。\n4、网站服务器每天产生的日志数量较大，请问如何备份? 使用 logrotate 滚动日志 split 大文件切分处理 shell 脚本处理日志 5、简述 Raid 0、Raid 1、Raid 5 的特点与原理。 RAID 等级 最少硬盘 最大容错 可用容量 读取性能 写入性能 安全性 目的 应用产业 单一硬盘 (参考) 0 1 1 1 无 JBOD 1 0 n 1 1 无（同 RAID 0） 增加容量 个人（暂时） 存储备份 0 2 0 n n n 一个硬盘异常，全部硬盘都会异常 追求最大容量、速度 视频剪接缓存用途 1 2 n-1 1 n 1 高，一个正常即可 追求最大安全性 个人、企业备份 5 3 1 n-1 n-1 n-1 中下至中 追求最大容量、最小预算 个人、小型企业备份 6 4 2 n-2 n-2 n-2 中至中高,仅安全性较 RAID 5 高 同 RAID 5，但较安全 个人、企业备份 10 4 高 综合 RAID 0/1 优点，理论速度较快 大型数据库、服务器 50 6 高 提升资料安全 60 8 高 提升资料安全 6、简述 Raid6、Raid 10 的特点与原理。 与 RAID 5 相比，RAID 6增加第二个独立的奇偶校验信息块。两个独立的奇偶系统使用不同的算法，数据的可靠性非常高，任意两块磁盘同时失效时不会影响数据完整性。RAID 6 需要分配给奇偶校验信息更大的磁盘空间和额外的校验计算，相对于 RAID 5 有更大的 IO 操作量和计算量，其“写性能”强烈取决于具体的实现方案，因","permalink":"https://test.jobcher.com/linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html","summary":"linux 基础知识 1、简述 Linux 权限划分原则。 给文件或目录分配权限时，先考虑所有者和所属组 遵循最小化权限，用啥权限给啥权限 修改目录和子文件归属权限，注意递归 文件权限分配是最常用的安全防护手段 2、当用户 user1，对/testdir 目录有写和执行权限时，该目录下的只读文件 file1 是否可修改和删除？ 对 file1 不能修改也不能删除。（如果对目录有写权限和执行权限，则对 file1 不能修改可以删除）\n3、如果一个系统没有任何的备份策略，请写出一个较为全面合理的备份方案！ 增量备份：将相较于前一天增加的内容备份，适合每天改变量较大的数据。\n差异备份：将相较于第一天改变的内容备份，适合原始数据量比较大，但是之后改变的比较小，即使中间哪一天的丢了也没事，只要最后一天，和第一天的在就行。\n4、网站服务器每天产生的日志数量较大，请问如何备份? 使用 logrotate 滚动日志 split 大文件切分处理 shell 脚本处理日志 5、简述 Raid 0、Raid 1、Raid 5 的特点与原理。 RAID 等级 最少硬盘 最大容错 可用容量 读取性能 写入性能 安全性 目的 应用产业 单一硬盘 (参考) 0 1 1 1 无 JBOD 1 0 n 1 1 无（同 RAID 0） 增加容量 个人（暂时） 存储备份 0 2 0 n n n 一个硬盘异常，全部硬盘都会异常 追求最大容量、速度 视频剪接缓存用途 1 2 n-1 1 n 1 高，一个正常即可 追求最大安全性 个人、企业备份 5 3 1 n-1 n-1 n-1 中下至中 追求最大容量、最小预算 个人、小型企业备份 6 4 2 n-2 n-2 n-2 中至中高,仅安全性较 RAID 5 高 同 RAID 5，但较安全 个人、企业备份 10 4 高 综合 RAID 0/1 优点，理论速度较快 大型数据库、服务器 50 6 高 提升资料安全 60 8 高 提升资料安全 6、简述 Raid6、Raid 10 的特点与原理。 与 RAID 5 相比，RAID 6增加第二个独立的奇偶校验信息块。两个独立的奇偶系统使用不同的算法，数据的可靠性非常高，任意两块磁盘同时失效时不会影响数据完整性。RAID 6 需要分配给奇偶校验信息更大的磁盘空间和额外的校验计算，相对于 RAID 5 有更大的 IO 操作量和计算量，其“写性能”强烈取决于具体的实现方案，因","title":"linux基础知识"},{"content":"网心云挂机教程 | 轻松实现睡后收入~ 首先，本文章只是分享，造成一切的后果，博主概不负责！都是成年人了……\n我采用 docker 容器魔方来挂载网心云\ndocker 部署 /mnt/money/wxedge_storage这个路径改为自己的存储路径建议\u0026amp;gt;200G\ndocker run \\ --name=wxedge \\ --restart=always \\ --privileged \\ --net=host \\ --tmpfs /run \\ --tmpfs /tmp \\ -v /mnt/money/wxedge_storage:/storage:rw \\ -d \\ registry.cn-hangzhou.aliyuncs.com/onething/wxedge 设备绑定 进入 dockerip 地址 （http://127.0.0.1:18888) 下载 app 扫码绑定 成功 然后坐等第二天收益到账就可以了，记得19:00-23:00是收益高峰期尽量保持在线~\n","permalink":"https://test.jobcher.com/%E7%BD%91%E5%BF%83%E4%BA%91%E6%8C%82%E6%9C%BA%E6%95%99%E7%A8%8B-%E8%BD%BB%E6%9D%BE%E5%AE%9E%E7%8E%B0%E7%9D%A1%E5%90%8E%E6%94%B6%E5%85%A5~.html","summary":"网心云挂机教程 | 轻松实现睡后收入~ 首先，本文章只是分享，造成一切的后果，博主概不负责！都是成年人了……\n我采用 docker 容器魔方来挂载网心云\ndocker 部署 /mnt/money/wxedge_storage这个路径改为自己的存储路径建议\u0026gt;200G\ndocker run \\ --name=wxedge \\ --restart=always \\ --privileged \\ --net=host \\ --tmpfs /run \\ --tmpfs /tmp \\ -v /mnt/money/wxedge_storage:/storage:rw \\ -d \\ registry.cn-hangzhou.aliyuncs.com/onething/wxedge 设备绑定 进入 dockerip 地址 （http://127.0.0.1:18888) 下载 app 扫码绑定 成功 然后坐等第二天收益到账就可以了，记得19:00-23:00是收益高峰期尽量保持在线~","title":"网心云挂机教程 | 轻松实现睡后收入~"},{"content":"清理 Docker 的 container，image 与 volume Docker 的镜像（image）、容器（container）、数据卷（volume）， 都是由 daemon 托管的。 因此，在需要清理时，也需要使用其自带的手段。\n清理技巧 清理所有停止运行的容器：\ndocker container prune # or docker rm $(docker ps -aq) 清理所有悬挂（\u0026amp;lt;none\u0026amp;gt;）镜像：\ndocker image prune # or docker rmi $(docker images -qf \u0026amp;#34;dangling=true\u0026amp;#34;) 清理所有无用数据卷：\ndocker volume prune 由于prune操作是批量删除类的危险操作，所以会有一次确认。 如果不想输入y\u0026amp;lt;CR\u0026amp;gt;来确认，可以添加-f操作。慎用！\n清理停止的容器 docker rm -lv CONTAINER -l是清理 link，v是清理 volume。 这里的 CONTAINER 是容器的 name 或 ID，可以是一个或多个。\n参数列表：\nName shorthand Default Description –force,-f false Force the removal of a running container (uses SIGKILL) –link, -l false Remove the specified link –volumes, -v false Remove the volumes associated with the container 清理所有停止的容器 通过docker ps可以查询当前运行的容器信息。 而通过docker ps -a，可以查询所有的容器信息，包括已停止的。\n在需要清理所有已停止的容器时，通常利用 shell 的特性，组合一下就好。\ndocker rm $(docker ps -aq) 其中，ps的-q，是只输出容器 ID，方便作为参数让rm使用。 假如给rm指定-f，则可以清理所有容器，包括正在运行的。\n这条组合命令，等价于另一条命令：\ndocker container prune container子命令，下面包含了所有和容器相关的子命令。 包括docker ps，等价于docker container ps或docker","permalink":"https://test.jobcher.com/%E6%B8%85%E7%90%86docker%E7%9A%84containerimage%E4%B8%8Evolume.html","summary":"清理 Docker 的 container，image 与 volume Docker 的镜像（image）、容器（container）、数据卷（volume）， 都是由 daemon 托管的。 因此，在需要清理时，也需要使用其自带的手段。\n清理技巧 清理所有停止运行的容器：\ndocker container prune # or docker rm $(docker ps -aq) 清理所有悬挂（\u0026lt;none\u0026gt;）镜像：\ndocker image prune # or docker rmi $(docker images -qf \u0026#34;dangling=true\u0026#34;) 清理所有无用数据卷：\ndocker volume prune 由于prune操作是批量删除类的危险操作，所以会有一次确认。 如果不想输入y\u0026lt;CR\u0026gt;来确认，可以添加-f操作。慎用！\n清理停止的容器 docker rm -lv CONTAINER -l是清理 link，v是清理 volume。 这里的 CONTAINER 是容器的 name 或 ID，可以是一个或多个。\n参数列表：\nName shorthand Default Description –force,-f false Force the removal of a running container (uses SIGKILL) –link, -l false Remove the specified link –volumes, -v false Remove the volumes associated with the container 清理所有停止的容器 通过docker ps可以查询当前运行的容器信息。 而通过docker ps -a，可以查询所有的容器信息，包括已停止的。","title":"清理Docker的container，image与volume"},{"content":"Jenkins 安装与使用 代码在本地修改\u0026amp;mdash;-》提交到远程 gitlab\u0026amp;mdash;-》触发 jenkins 整个自动化构建流程（打包，测试，发布，部署）\n安装 docker 安装 docker\ndocker 安装 jenkins docker run \\ -u root \\ -d \\ -p 8080:8080 \\ -p 50000:50000 \\ -v jenkins-data:/var/jenkins_home \\ -v /etc/localtime:/etc/localtime:ro \\ -v /var/run/docker.sock:/var/run/docker.sock \\ --restart=always \\ jenkinsci/blueocean 访问 http://localhost:8080\n显示初始密码\ndocker exec -ti \u0026amp;lt;容器名称\u0026amp;gt; sh cat /var/jenkins_home/secrets/initialAdminPassword 工作流程 先定义一个流水线项目，指定项目的 git 位置 git 位置自动拉取代码 解析拉取代码里面的 Jenkinsfile 文件 按照 Jenkinsfile 指定的流水线开始加工项目 Jenkinsfile 语法 基础语法,在仓库创建一个 Jenkinsfile 文件\npipeline { /* 全部的CICD流程都在这里定义 */ //任意代理可用就可以执行 agent any //定义流水线的加工流程 stages { /* 流水线的所有阶段 1.编译 \u0026amp;#34;常量\u0026amp;#34;\u0026amp;#39;变量\u0026amp;#39; 2.测试 3.打包 4.部署 */ stage(\u0026amp;#39;代码编译\u0026amp;#39;){ steps { //要做的所有事情 echo \u0026amp;#34;编译……\u0026amp;#34; } } stage(\u0026amp;#39;代码测试\u0026amp;#39;){ steps { //要做的所有事情 echo \u0026amp;#34;测试……\u0026amp;#34; } } stage(\u0026amp;#39;打包\u0026amp;#39;){ steps { //要做的所有事情 echo \u0026amp;#34;打包……\u0026amp;#34; } } stage(\u0026amp;#39;部署\u0026amp;#39;){ steps { //要做的所有事情 echo \u0026amp;#34;部署……\u0026amp;#34; } } } } 构建远程触发 在 jenkins 上选择:项目-\u0026amp;gt;配","permalink":"https://test.jobcher.com/jenkins-%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8.html","summary":"Jenkins 安装与使用 代码在本地修改\u0026mdash;-》提交到远程 gitlab\u0026mdash;-》触发 jenkins 整个自动化构建流程（打包，测试，发布，部署）\n安装 docker 安装 docker\ndocker 安装 jenkins docker run \\ -u root \\ -d \\ -p 8080:8080 \\ -p 50000:50000 \\ -v jenkins-data:/var/jenkins_home \\ -v /etc/localtime:/etc/localtime:ro \\ -v /var/run/docker.sock:/var/run/docker.sock \\ --restart=always \\ jenkinsci/blueocean 访问 http://localhost:8080\n显示初始密码\ndocker exec -ti \u0026lt;容器名称\u0026gt; sh cat /var/jenkins_home/secrets/initialAdminPassword 工作流程 先定义一个流水线项目，指定项目的 git 位置 git 位置自动拉取代码 解析拉取代码里面的 Jenkinsfile 文件 按照 Jenkinsfile 指定的流水线开始加工项目 Jenkinsfile 语法 基础语法,在仓库创建一个 Jenkinsfile 文件\npipeline { /* 全部的CICD流程都在这里定义 */ //任意代理可用就可以执行 agent any //定义流水线的加工流程 stages { /* 流水线的所有阶段 1.","title":"Jenkins 安装与使用"},{"content":"Navicat 查看密码方案 解决问题： 我们经常使用 navicat 连接数据库，有时候时间久了之后，会忘记之前的密码，那么现在我们有办法获得只要正常连接的数据库的密码\n步骤： 导出连接 connections.ncx，拿到保存到本地的 connections.ncx 文件中的 Password，粘贴到下面的代码中 登陆https://tool.lu/coderunner/，使用 PHP 在线运行工具，粘贴下面添加密码后的代码\n备用工具网址（https://zixuephp.net/tool-runcode.html） \u0026amp;lt;?php class NavicatPassword { protected $version = 0; protected $aesKey = \u0026amp;#39;libcckeylibcckey\u0026amp;#39;; protected $aesIv = \u0026amp;#39;libcciv libcciv \u0026amp;#39;; protected $blowString = \u0026amp;#39;3DC5CA39\u0026amp;#39;; protected $blowKey = null; protected $blowIv = null; public function __construct($version = 12) { $this-\u0026amp;gt;version = $version; $this-\u0026amp;gt;blowKey = sha1(\u0026amp;#39;3DC5CA39\u0026amp;#39;, true); $this-\u0026amp;gt;blowIv = hex2bin(\u0026amp;#39;d9c7c3c8870d64bd\u0026amp;#39;); } public function encrypt($string) { $result = FALSE; switch ($this-\u0026amp;gt;version) { case 11: $result = $this-\u0026amp;gt;encryptEleven($string); break; case 12: $result = $this-\u0026amp;gt;encryptTwelve($string); break; default: break; } return $result; } protected function encryptEleven($string) { $round = intval(floor(strlen($string) / 8));","permalink":"https://test.jobcher.com/navicat-%E6%9F%A5%E7%9C%8B%E5%AF%BC%E5%87%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%AF%86%E7%A0%81-navicat%E6%9F%A5%E7%9C%8B%E5%AF%86%E7%A0%81%E6%96%B9%E6%A1%88.html","summary":"Navicat 查看密码方案 解决问题： 我们经常使用 navicat 连接数据库，有时候时间久了之后，会忘记之前的密码，那么现在我们有办法获得只要正常连接的数据库的密码\n步骤： 导出连接 connections.ncx，拿到保存到本地的 connections.ncx 文件中的 Password，粘贴到下面的代码中 登陆https://tool.lu/coderunner/，使用 PHP 在线运行工具，粘贴下面添加密码后的代码\n备用工具网址（https://zixuephp.net/tool-runcode.html） \u0026lt;?php class NavicatPassword { protected $version = 0; protected $aesKey = \u0026#39;libcckeylibcckey\u0026#39;; protected $aesIv = \u0026#39;libcciv libcciv \u0026#39;; protected $blowString = \u0026#39;3DC5CA39\u0026#39;; protected $blowKey = null; protected $blowIv = null; public function __construct($version = 12) { $this-\u0026gt;version = $version; $this-\u0026gt;blowKey = sha1(\u0026#39;3DC5CA39\u0026#39;, true); $this-\u0026gt;blowIv = hex2bin(\u0026#39;d9c7c3c8870d64bd\u0026#39;); } public function encrypt($string) { $result = FALSE; switch ($this-\u0026gt;version) { case 11: $result = $this-\u0026gt;encryptEleven($string); break; case 12: $result = $this-\u0026gt;encryptTwelve($string); break; default: break; } return $result; } protected function encryptEleven($string) { $round = intval(floor(strlen($string) / 8));","title":"Navicat 查看导出连接的密码 | navicat查看密码方案"},{"content":"ProXmoX VE 升级 apt-get update 报错 解决方法 vim /etc/apt/sources.list.d/pve-enterprise.list #注释掉 #deb https://enterprise.proxmox.com/debian/pve stretch pve-enterprise 添加内容 echo \u0026amp;#34;deb http://download.proxmox.com/debian/pve stretch pve-no-subscription\u0026amp;#34; \u0026amp;gt; /etc/apt/sources.list.d/pve-install-repo.list wget http://download.proxmox.com/debian/proxmox-ve-release-5.x.gpg -O /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg 更新系统 apt update \u0026amp;amp;\u0026amp;amp; apt dist-upgrade 结尾 升级完成后，可以执行pveversion -v查看下最新的软件版本。然后执行reboot重启物理服务器\n","permalink":"https://test.jobcher.com/proxmox-ve%E5%8D%87%E7%BA%A7-apt-get-update-%E6%8A%A5%E9%94%99.html","summary":"ProXmoX VE 升级 apt-get update 报错 解决方法 vim /etc/apt/sources.list.d/pve-enterprise.list #注释掉 #deb https://enterprise.proxmox.com/debian/pve stretch pve-enterprise 添加内容 echo \u0026#34;deb http://download.proxmox.com/debian/pve stretch pve-no-subscription\u0026#34; \u0026gt; /etc/apt/sources.list.d/pve-install-repo.list wget http://download.proxmox.com/debian/proxmox-ve-release-5.x.gpg -O /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg 更新系统 apt update \u0026amp;\u0026amp; apt dist-upgrade 结尾 升级完成后，可以执行pveversion -v查看下最新的软件版本。然后执行reboot重启物理服务器","title":"ProXmoX VE升级 apt-get update 报错"},{"content":"mysql 学习笔记（2） mysql 主从复制 MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。MySQL 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。\nMySQL 主从复制的主要用途 读写分离 数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换(主从切换) 高可用（HA） 架构扩展 MySQL 主从复制的原理 MySQL 主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点，如下图所示:\n主节点 log dump 线程\n当从节点连接主节点时，主节点会为其创建一个 log dump 线程，用于发送和读取 bin-log 的内容。在读取 bin-log 中的操作时，log dump 线程会对主节点上的 bin-log 加锁，当读取完成，在发送给从节点之前，锁会被释放。主节点会为自己的每一个从节点创建一个log dump 线程。\n从节点 I/O 线程\n当从节点上执行start slave命令之后，从节点会创建一个 I/O 线程用来连接主节点，请求主库中更新的 bin-log。I/O 线程接收到主节点的 blog dump 进程发来的更新之后，保存在本地relay-log（中继日志）中。\n从节点 SQL 线程\nSQL 线程负责读取 relay-log 中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。\n对于每一个主从连接，都需要这三个进程来完成。当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个log dump 进程，而每个从节点都有自己的I/O进程，SQL进程。从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候，不会降低读操作的性能。比如，如果从节点没有运行，此时 I/O 进程可以很快从主节点获取更新，尽管 SQL 进程还没有执行。如果在 SQL 进程执行之前从节点服务停止，至少 I/O 进程已经从主节点拉取到了最新的变更并且保存在本地 relay 日志中，当服务再次起来之后，就可以完成数据的同步。\n要实施复制，首先必须打开Master 端的binary log（bin-log）功能，否则无法实","permalink":"https://test.jobcher.com/mysql-%E7%AC%94%E8%AE%B02.html","summary":"mysql 学习笔记（2） mysql 主从复制 MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。MySQL 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。\nMySQL 主从复制的主要用途 读写分离 数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换(主从切换) 高可用（HA） 架构扩展 MySQL 主从复制的原理 MySQL 主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点，如下图所示:\n主节点 log dump 线程\n当从节点连接主节点时，主节点会为其创建一个 log dump 线程，用于发送和读取 bin-log 的内容。在读取 bin-log 中的操作时，log dump 线程会对主节点上的 bin-log 加锁，当读取完成，在发送给从节点之前，锁会被释放。主节点会为自己的每一个从节点创建一个log dump 线程。\n从节点 I/O 线程\n当从节点上执行start slave命令之后，从节点会创建一个 I/O 线程用来连接主节点，请求主库中更新的 bin-log。I/O 线程接收到主节点的 blog dump 进程发来的更新之后，保存在本地relay-log（中继日志）中。\n从节点 SQL 线程\nSQL 线程负责读取 relay-log 中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。\n对于每一个主从连接，都需要这三个进程来完成。当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个log dump 进程，而每个从节点都有自己的I/O进程，SQL进程。从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候，不会降低读操作的性能。比如，如果从节点没有运行，此时 I/O 进程可以很快从主节点获取更新，尽管 SQL 进程还没有执行。如果在 SQL 进程执行之前从节点服务停止，至少 I/O 进程已经从主节点拉取到了最新的变更并且保存在本地 relay 日志中，当服务再次起来之后，就可以完成数据的同步。","title":"mysql 笔记（2）"},{"content":"Proxmox VE 在线扩容磁盘分区 添加磁盘大小 在 VM 上做扩容操作 安装 growpart yum install -y epel-release yum install -y cloud-utils 查看系统盘 路径 fdisk -l df -h 扩容设备并重启 growpart /dev/sda 2 #2代表是第二块系统分区，不是sda2,中间有空格 reboot 重启执行命令 xfs_growfs /dev/sda2 #(xfs 文件系统) resize2fs /dev/sda2 #(ext4 文件系统) 更新完成 df -h ","permalink":"https://test.jobcher.com/proxmox-ve-%E5%9C%A8%E7%BA%BF%E6%89%A9%E5%AE%B9%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA.html","summary":"Proxmox VE 在线扩容磁盘分区 添加磁盘大小 在 VM 上做扩容操作 安装 growpart yum install -y epel-release yum install -y cloud-utils 查看系统盘 路径 fdisk -l df -h 扩容设备并重启 growpart /dev/sda 2 #2代表是第二块系统分区，不是sda2,中间有空格 reboot 重启执行命令 xfs_growfs /dev/sda2 #(xfs 文件系统) resize2fs /dev/sda2 #(ext4 文件系统) 更新完成 df -h ","title":"Proxmox VE 在线扩容磁盘分区"},{"content":"Gitlab 批量导出用户 登陆 Gitlab 服务器进行数据库登陆、数据查询及信息导出操作。\n操作步骤 根据配置文件，定位数据库相关信息 cat /var/opt/gitlab/gitlab-rails/etc/database.yml 查看 Gitlab 对应的系统用户 cat /etc/passwd | grep gitlab 切换用户 gitlab-psql su - gitlab-psql 登陆数据库（-h 指定 host，-d 指定数据库） 使用第 1 步获取的信息 psql -h /var/opt/gitlab/postgresql -d gitlabhq_production (1) 查看帮助信息\ngitlabhq_production=# \\h (2) 查看数据库\ngitlabhq_production=# \\l (3) 查看库中的表（执行命令后，按回车键显示更多表信息）\ngitlabhq_production=# \\dt (4) 通过筛查，可在库中找到 users 表，相关用户信息都记录在表中！\ngitlabhq_production=# \\d users (5) 查看表信息\ngitlabhq_production=# SELECT * FROM users; (6) 查看 users 表中的 name 字段\ngitlabhq_production=# SELECT name FROM users; (7)登出数据库\ngitlabhq_production=# \\q 根据需要提取的信息，确定表 users 中的字段，进行导出操作 echo \u0026amp;#39;select name,username,email,state from users;\u0026amp;#39; |psql -h /var/opt/gitlab/postgresql -d gitlabhq_production \u0026amp;gt; userinfo.txt 存储在/var/opt/gitlab/postgresql/userinfo.txt\n","permalink":"https://test.jobcher.com/gitlab%E6%89%B9%E9%87%8F%E5%AF%BC%E5%87%BA%E7%94%A8%E6%88%B7.html","summary":"Gitlab 批量导出用户 登陆 Gitlab 服务器进行数据库登陆、数据查询及信息导出操作。\n操作步骤 根据配置文件，定位数据库相关信息 cat /var/opt/gitlab/gitlab-rails/etc/database.yml 查看 Gitlab 对应的系统用户 cat /etc/passwd | grep gitlab 切换用户 gitlab-psql su - gitlab-psql 登陆数据库（-h 指定 host，-d 指定数据库） 使用第 1 步获取的信息 psql -h /var/opt/gitlab/postgresql -d gitlabhq_production (1) 查看帮助信息\ngitlabhq_production=# \\h (2) 查看数据库\ngitlabhq_production=# \\l (3) 查看库中的表（执行命令后，按回车键显示更多表信息）\ngitlabhq_production=# \\dt (4) 通过筛查，可在库中找到 users 表，相关用户信息都记录在表中！\ngitlabhq_production=# \\d users (5) 查看表信息\ngitlabhq_production=# SELECT * FROM users; (6) 查看 users 表中的 name 字段\ngitlabhq_production=# SELECT name FROM users; (7)登出数据库","title":"Gitlab批量导出用户"},{"content":"Harbor 搭建 Harbor 是一个开源可信的云原生注册表项目，用于存储、签名和扫描内容。用于存储 docker image\n要求 Linux 主机 docker 17.06.0-ce 以上 docker-compose 1.18.0 以上 链接跳转：docker 安装\n安装 下载程序 在线安装包\nwget https://github.com/goharbor/harbor/releases/download/v1.10.10/harbor-online-installer-v1.10.10.tgz 离线安装包\nwget https://github.com/goharbor/harbor/releases/download/v1.10.10/harbor-offline-installer-v1.10.10.tgz 安装 mkdir -p /data cd /data tar -zxvf harbor-offline-installer-v1.10.10.tgz cd /harbor ./install.sh 接下来只要安静的等待安装就可以了\n配置 # Configuration file of Harbor # The IP address or hostname to access admin UI and registry service. # DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients. hostname: \u0026amp;lt;域名\u0026amp;gt; # http related config http: # port for http, default is 80. If https enabled, this port will redirect to https port port: 80 # https related config https: # https port for harbor, default is 443 port: 443 # SSL证书 certificate: /hub/ssl/bundle.pem private_key: /hub/ssl/key # Uncomment external_url if you want to enable","permalink":"https://test.jobcher.com/harbor-%E6%90%AD%E5%BB%BA.html","summary":"Harbor 搭建 Harbor 是一个开源可信的云原生注册表项目，用于存储、签名和扫描内容。用于存储 docker image\n要求 Linux 主机 docker 17.06.0-ce 以上 docker-compose 1.18.0 以上 链接跳转：docker 安装\n安装 下载程序 在线安装包\nwget https://github.com/goharbor/harbor/releases/download/v1.10.10/harbor-online-installer-v1.10.10.tgz 离线安装包\nwget https://github.com/goharbor/harbor/releases/download/v1.10.10/harbor-offline-installer-v1.10.10.tgz 安装 mkdir -p /data cd /data tar -zxvf harbor-offline-installer-v1.10.10.tgz cd /harbor ./install.sh 接下来只要安静的等待安装就可以了\n配置 # Configuration file of Harbor # The IP address or hostname to access admin UI and registry service. # DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.","title":"Harbor 搭建"},{"content":"prometheus+grafana+alertmanager 安装配置 服务器监控告警系统搭建，通过 exporter 获取节点信息到 prometheus。prometheus 配置规则，使 garfana 和 alertmanager 能够接受到数据，分别展示数据和发送告警\n参数 VM :192.168.99.78\n端口 服务 9100 node_exporter 3000 grafana 9090 prometheus 9115 blackbox_exporter 安装 grafa 安装 docker 安装 docker run -d -p 3000:3000 \\ --name=grafana \\ -v grafana-storage:/var/lib/grafana \\ grafana/grafana:8.3.3 prometheus 安装 下载 wget https://github.com/prometheus/prometheus/releases/download/v2.32.1/prometheus-2.32.1.linux-amd64.tar.gz tar -zxvf prometheus-2.32.1.linux-amd64.tar.gz cd prometheus-2.32.1.linux-amd64 mkdir -p file_sd mkdir -p rules 运行 prometheus killall prometheus nohup ./prometheus --config.file=prometheus.yml \u0026amp;amp; # 查看运行状况 tail -f nohup.out node_exporter 安装 docker-compose 安装 version: \u0026amp;#34;3\u0026amp;#34; services: node-exporter: image: prom/node-exporter:v1.3.1 container_name: node-exporter restart: always ports: - \u0026amp;#34;9100:9100\u0026amp;#34; docker-compose up -d 二进制安装 wget","permalink":"https://test.jobcher.com/prometheus-grafana-alertmanager-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE.html","summary":"prometheus+grafana+alertmanager 安装配置 服务器监控告警系统搭建，通过 exporter 获取节点信息到 prometheus。prometheus 配置规则，使 garfana 和 alertmanager 能够接受到数据，分别展示数据和发送告警\n参数 VM :192.168.99.78\n端口 服务 9100 node_exporter 3000 grafana 9090 prometheus 9115 blackbox_exporter 安装 grafa 安装 docker 安装 docker run -d -p 3000:3000 \\ --name=grafana \\ -v grafana-storage:/var/lib/grafana \\ grafana/grafana:8.3.3 prometheus 安装 下载 wget https://github.com/prometheus/prometheus/releases/download/v2.32.1/prometheus-2.32.1.linux-amd64.tar.gz tar -zxvf prometheus-2.32.1.linux-amd64.tar.gz cd prometheus-2.32.1.linux-amd64 mkdir -p file_sd mkdir -p rules 运行 prometheus killall prometheus nohup ./prometheus --config.file=prometheus.yml \u0026amp; # 查看运行状况 tail -f nohup.out node_exporter 安装 docker-compose 安装 version: \u0026#34;3\u0026#34; services: node-exporter: image: prom/node-exporter:v1.","title":"prometheus grafana alertmanager 安装配置"},{"content":"prometheus 配置 Prometheus 是由 SoundCloud 开源监控告警解决方案\n组件 Prometheus Server， 主要用于抓取数据和存储时序数据，另外还提供查询和 Alert Rule 配置管理。 client libraries，用于对接 Prometheus Server, 可以查询和上报数据。 push gateway ，用于批量，短期的监控数据的汇总节点，主要用于业务数据汇报等。 各种汇报数据的 exporters ，例如汇报机器数据的 node_exporter, 汇报 MongoDB 信息的 MongoDB exporter 等等。 用于告警通知管理的 alertmanager 。 运行逻辑 Prometheus server 定期从静态配置的 targets 或者服务发现的 targets 拉取数据。 当新拉取的数据大于配置内存缓存区的时候，Prometheus 会将数据持久化到磁盘（如果使用 remote storage 将持久化到云端）。 Prometheus 可以配置 rules，然后定时查询数据，当条件触发的时候，会将 alert 推送到配置的 Alertmanager。 Alertmanager 收到警告的时候，可以根据配置，聚合，去重，降噪，最后发送警告。 可以使用 API， Prometheus Console 或者 Grafana 查询和聚合数据。 安装 prometheus 使用预编译的二进制文件安装 wget https://github.com/prometheus/prometheus/releases/download/v2.32.1/prometheus-2.32.1.linux-amd64.tar.gz tar -zxvf prometheus-2.32.1.linux-amd64.tar.gz cd prometheus-2.32.1.linux-amd64 使用 docker 安装 mkdir -p opt/prometheus vim prometheus.yml docker run \\ -p 9090:9090 \\ -v /path/to/prometheus.yml:/opt/prometheus/prometheus.yml \\ prom/prometheus ","permalink":"https://test.jobcher.com/prometheus-%E9%85%8D%E7%BD%AE.html","summary":"prometheus 配置 Prometheus 是由 SoundCloud 开源监控告警解决方案\n组件 Prometheus Server， 主要用于抓取数据和存储时序数据，另外还提供查询和 Alert Rule 配置管理。 client libraries，用于对接 Prometheus Server, 可以查询和上报数据。 push gateway ，用于批量，短期的监控数据的汇总节点，主要用于业务数据汇报等。 各种汇报数据的 exporters ，例如汇报机器数据的 node_exporter, 汇报 MongoDB 信息的 MongoDB exporter 等等。 用于告警通知管理的 alertmanager 。 运行逻辑 Prometheus server 定期从静态配置的 targets 或者服务发现的 targets 拉取数据。 当新拉取的数据大于配置内存缓存区的时候，Prometheus 会将数据持久化到磁盘（如果使用 remote storage 将持久化到云端）。 Prometheus 可以配置 rules，然后定时查询数据，当条件触发的时候，会将 alert 推送到配置的 Alertmanager。 Alertmanager 收到警告的时候，可以根据配置，聚合，去重，降噪，最后发送警告。 可以使用 API， Prometheus Console 或者 Grafana 查询和聚合数据。 安装 prometheus 使用预编译的二进制文件安装 wget https://github.com/prometheus/prometheus/releases/download/v2.32.1/prometheus-2.32.1.linux-amd64.tar.gz tar -zxvf prometheus-2.32.1.linux-amd64.tar.gz cd prometheus-2.","title":"prometheus 配置"},{"content":"centos7.9 网络配置 解决 centos 新机器网络不通的问题，CentOS7 默认不启动网卡的。CentOS 安装成功后,进行一下 ping 的操作,验证网络是否联通.\nping 1.1.1.1 ip addr # 查看ip网络名称 启用网卡 进入 /etc/sysconfig/network-scipts 文件夹下，找到 IP 网卡名称 cd /etc/sysconfig/network-scipts vim ifcfg-eth0 启用 ONBOOT #vim ifcfg-eth0 #修改 ONBOOT=YES # esc 并:wq退出保存 重启机器 shutdown -r now 结尾 centos 用的挺别扭，不考虑性能和性价比，我还是喜欢用 ubuntu……，简单的配置，初学者我建议还是先用 ubuntu，会少踩很多坑。当然了，用 x86 不然初学者用树莓派和 arm 设备，会碰到很多兼容性的问题。\n","permalink":"https://test.jobcher.com/centos7.9-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE.html","summary":"centos7.9 网络配置 解决 centos 新机器网络不通的问题，CentOS7 默认不启动网卡的。CentOS 安装成功后,进行一下 ping 的操作,验证网络是否联通.\nping 1.1.1.1 ip addr # 查看ip网络名称 启用网卡 进入 /etc/sysconfig/network-scipts 文件夹下，找到 IP 网卡名称 cd /etc/sysconfig/network-scipts vim ifcfg-eth0 启用 ONBOOT #vim ifcfg-eth0 #修改 ONBOOT=YES # esc 并:wq退出保存 重启机器 shutdown -r now 结尾 centos 用的挺别扭，不考虑性能和性价比，我还是喜欢用 ubuntu……，简单的配置，初学者我建议还是先用 ubuntu，会少踩很多坑。当然了，用 x86 不然初学者用树莓派和 arm 设备，会碰到很多兼容性的问题。","title":"centos7.9 网络配置"},{"content":"安装 docker 出现 ERROR: Unsupported distribution \u0026amp;lsquo;ol\u0026amp;rsquo; 问题 部署 docker 安装出现 ERROR: Unsupported distribution \u0026amp;lsquo;ol\u0026amp;rsquo;\n确认是不是 arm 架构 uname -r 确认使用的是不是 oracle 服务器系统,如果是请继续操作，安装依赖： dnf install -y dnf-utils zip unzip dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo 安装 docker dnf remove -y runc dnf install -y docker-ce --nobest 完成 docker 安装并检查 systemctl enable docker.service systemctl start docker.service #检查 systemctl status docker.service docker info docker version 结尾 该问题主要是 oracle 没有支持依赖导致的~oracle 还是很不错的~\n","permalink":"https://test.jobcher.com/%E5%AE%89%E8%A3%85-docker-%E5%87%BA%E7%8E%B0-error-unsupported-distribution-ol-%E9%97%AE%E9%A2%98.html","summary":"安装 docker 出现 ERROR: Unsupported distribution \u0026lsquo;ol\u0026rsquo; 问题 部署 docker 安装出现 ERROR: Unsupported distribution \u0026lsquo;ol\u0026rsquo;\n确认是不是 arm 架构 uname -r 确认使用的是不是 oracle 服务器系统,如果是请继续操作，安装依赖： dnf install -y dnf-utils zip unzip dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo 安装 docker dnf remove -y runc dnf install -y docker-ce --nobest 完成 docker 安装并检查 systemctl enable docker.service systemctl start docker.service #检查 systemctl status docker.service docker info docker version 结尾 该问题主要是 oracle 没有支持依赖导致的~oracle 还是很不错的~","title":"安装 docker 出现 ERROR: Unsupported distribution 'ol' 问题"},{"content":"Kubernetes 实验手册（1） 通过在 pve 创建 5 台虚拟机：\n节点 IP 作用 node0 192.168.99.69 k8s-master01 node1 192.168.99.9 k8s-master02 node2 192.168.99.53 k8s-master03 node3 192.168.99.41 k8s-node01 node4 192.168.99.219 k8s-node02 node5 192.168.99.42 k8s-master-lb 配置信息 备注 系统版本 Ubuntu Docker 20.10.12 pod 网段 172.168.0.0/12 service 网段 10.96.0.0/12 VIP 不要和内网 IP 重复，VIP 需要和主机在同一个局域网内\n更新 ansible 连接 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.155 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.199 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.87 #ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.41 #ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.219 vim /etc/hosts 192.168.99.155 k8s-master01 192.168.99.199 k8s-master02 192.168.99.87 k8s-master03 #192.168.99.41 k8s-node01 #192.168.99.219 k8s-node02 基本配置 安装基本软件包 apt install wget jq psmisc vim net-tools telnet lvm2 git -y # 关闭swap分区 vim /etc/fstab 注释掉swap 内容 并重启 reboot # 时间同步 apt install ntpdate -y # 查看时区 timedatectl set-timezone \u0026amp;#39;Asia/Shanghai\u0026amp;#39; timedatectl date 安装 docker","permalink":"https://test.jobcher.com/kubernetes-%E5%AE%9E%E9%AA%8C%E6%89%8B%E5%86%8C1.html","summary":"Kubernetes 实验手册（1） 通过在 pve 创建 5 台虚拟机：\n节点 IP 作用 node0 192.168.99.69 k8s-master01 node1 192.168.99.9 k8s-master02 node2 192.168.99.53 k8s-master03 node3 192.168.99.41 k8s-node01 node4 192.168.99.219 k8s-node02 node5 192.168.99.42 k8s-master-lb 配置信息 备注 系统版本 Ubuntu Docker 20.10.12 pod 网段 172.168.0.0/12 service 网段 10.96.0.0/12 VIP 不要和内网 IP 重复，VIP 需要和主机在同一个局域网内\n更新 ansible 连接 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.155 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.199 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.87 #ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.41 #ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.219 vim /etc/hosts 192.","title":"Kubernetes 实验手册（1）"},{"content":"RocketMQ 安装和部署 部署 RocketMQ\n单机安装构建 安装 JDK 1.8.0 yum install java-1.8.0-openjdk* 安装 Maven wget http://dlcdn.apache.org/maven/maven-3/3.8.4/binaries/apache-maven-3.8.4-bin.tar.gz tar -zxvf apache-maven-3.8.4-bin.tar.gz mv -f apache-maven-3.8.4 /usr/local/ vim /etc/profile # 末尾添加 export MAVEN_HOME=/usr/local/apache-maven-3.8.4 export PATH=${PATH}:${MAVEN_HOME}/bin # 保存 source /etc/profile # 查看maven是否正常 mvn -v 快速部署 #构建 DLedger git clone https://github.com/openmessaging/openmessaging-storage-dledger.git cd openmessaging-storage-dledger mvn clean install -DskipTests # 构建 RocketMQ git clone https://github.com/apache/rocketmq.git cd rocketmq git checkout -b store_with_dledger origin/store_with_dledger mvn -Prelease-all -DskipTests clean install -U # 部署 cd rocketmq/distribution/target/apache-rocketmq sh bin/dledger/fast-try.sh start # 通过 mqadmin 运维命令查看集群状态 sh bin/mqadmin clusterList -n 127.0.0.1:9876 启动单节点\ncd distribution/target/rocketmq-4.9.3-SNAPSHOT/rocketmq-4.9.3-SNAPSHOT nohup sh bin/mqnamesrv \u0026amp;amp; # 查看 Namesrv 日","permalink":"https://test.jobcher.com/rocketmq-%E5%AE%89%E8%A3%85%E5%92%8C%E5%90%AF%E5%8A%A8.html","summary":"RocketMQ 安装和部署 部署 RocketMQ\n单机安装构建 安装 JDK 1.8.0 yum install java-1.8.0-openjdk* 安装 Maven wget http://dlcdn.apache.org/maven/maven-3/3.8.4/binaries/apache-maven-3.8.4-bin.tar.gz tar -zxvf apache-maven-3.8.4-bin.tar.gz mv -f apache-maven-3.8.4 /usr/local/ vim /etc/profile # 末尾添加 export MAVEN_HOME=/usr/local/apache-maven-3.8.4 export PATH=${PATH}:${MAVEN_HOME}/bin # 保存 source /etc/profile # 查看maven是否正常 mvn -v 快速部署 #构建 DLedger git clone https://github.com/openmessaging/openmessaging-storage-dledger.git cd openmessaging-storage-dledger mvn clean install -DskipTests # 构建 RocketMQ git clone https://github.com/apache/rocketmq.git cd rocketmq git checkout -b store_with_dledger origin/store_with_dledger mvn -Prelease-all -DskipTests clean install -U # 部署 cd rocketmq/distribution/target/apache-rocketmq sh bin/dledger/fast-try.","title":"RocketMQ 安装和启动"},{"content":"安装 minIO 通过 docker 安装 docker run -p 9000:9000 -p 41863:41863 -d --name azure-s3 \\ -e \u0026amp;#34;MINIO_ACCESS_KEY=azure存储账户\u0026amp;#34; \\ -e \u0026amp;#34;MINIO_SECRET_KEY=azure存储密码\u0026amp;#34; \\ minio/minio gateway azure --console-address \u0026amp;#34;:41863\u0026amp;#34; 通过 docker-compose 安装 version: \u0026amp;#34;3\u0026amp;#34; services: minio: image: \u0026amp;#34;minio/minio:RELEASE.2022-01-04T07-41-07Z.fips\u0026amp;#34; container_name: \u0026amp;#34;minio\u0026amp;#34; restart: \u0026amp;#34;always\u0026amp;#34; volumes: - \u0026amp;#34;/etc/localtime:/etc/localtime\u0026amp;#34; ports: - \u0026amp;#34;9000:9000\u0026amp;#34; - \u0026amp;#34;9001:9001\u0026amp;#34; environment: - \u0026amp;#34;MINIO_ROOT_USER=azure存储账户\u0026amp;#34; - \u0026amp;#34;MINIO_ROOT_PASSWORD=azure存储密码\u0026amp;#34; command: - --console-address \u0026amp;#34;:41863\u0026amp;#34; ","permalink":"https://test.jobcher.com/%E5%AE%89%E8%A3%85-minio-azure-s3%E7%BD%91%E5%85%B3.html","summary":"安装 minIO 通过 docker 安装 docker run -p 9000:9000 -p 41863:41863 -d --name azure-s3 \\ -e \u0026#34;MINIO_ACCESS_KEY=azure存储账户\u0026#34; \\ -e \u0026#34;MINIO_SECRET_KEY=azure存储密码\u0026#34; \\ minio/minio gateway azure --console-address \u0026#34;:41863\u0026#34; 通过 docker-compose 安装 version: \u0026#34;3\u0026#34; services: minio: image: \u0026#34;minio/minio:RELEASE.2022-01-04T07-41-07Z.fips\u0026#34; container_name: \u0026#34;minio\u0026#34; restart: \u0026#34;always\u0026#34; volumes: - \u0026#34;/etc/localtime:/etc/localtime\u0026#34; ports: - \u0026#34;9000:9000\u0026#34; - \u0026#34;9001:9001\u0026#34; environment: - \u0026#34;MINIO_ROOT_USER=azure存储账户\u0026#34; - \u0026#34;MINIO_ROOT_PASSWORD=azure存储密码\u0026#34; command: - --console-address \u0026#34;:41863\u0026#34; ","title":"安装 minIO Azure S3网关"},{"content":"Keepalived 高可用 配置文件存放位置：/usr/share/doc/keepalived/samples\nVVRP 虚拟路由冗余协议\n组成 LB 集群：Load Balancing，负载均衡集群，平均分配给多个节点\nHA 集群：High Availability，高可用集群，保证服务可用\nHPC 集群：High Performance Computing，高性能集群\n配置 keepalived+LVS+nginx\n各节点时间必须同步：ntp, chrony 关闭防火墙及 SELinux 同步各节点时间 #安装ntpdate apt install ntpdate #更改时区 timedatectl set-timezone \u0026amp;#39;Asia/Shanghai\u0026amp;#39; #查看时间 timedatectl datetime 安装 keepalived #安装 apt install keepalived #更改模板 cd /usr/share/doc/keepalived/samples ","permalink":"https://test.jobcher.com/keepalived%E9%AB%98%E5%8F%AF%E7%94%A8.html","summary":"Keepalived 高可用 配置文件存放位置：/usr/share/doc/keepalived/samples\nVVRP 虚拟路由冗余协议\n组成 LB 集群：Load Balancing，负载均衡集群，平均分配给多个节点\nHA 集群：High Availability，高可用集群，保证服务可用\nHPC 集群：High Performance Computing，高性能集群\n配置 keepalived+LVS+nginx\n各节点时间必须同步：ntp, chrony 关闭防火墙及 SELinux 同步各节点时间 #安装ntpdate apt install ntpdate #更改时区 timedatectl set-timezone \u0026#39;Asia/Shanghai\u0026#39; #查看时间 timedatectl datetime 安装 keepalived #安装 apt install keepalived #更改模板 cd /usr/share/doc/keepalived/samples ","title":"Keepalived高可用"},{"content":"ansible 安装和部署 Ansible 默认通过 SSH 协议管理机器.\n安装 ansible 下载安装 # ubuntu 安装 apt-get install software-properties-common apt-add-repository ppa:ansible/ansible apt-get update apt-get install ansible # centos 安装 yum install ansible 检查文件 #检查 ansible --version ansible 配置 添加主机 vim /etc/ansible/hosts #添加你需要添加的被控主机地址和IP 配置 SSH key 授权访问 # 控制主机生成ssh 密钥对（一路回车） ssh-keygen -t rsa # 复制公钥IP到被控主机 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.2 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.3 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.4 # ssh-copy-id命令会自动将id_rsa.pub文件的内容追加到远程主机root用户下.ssh/authorized_keys文件中。 更改 ansible 配置 vim /etc/ansible/ansible.cfg #禁用每次执行ansbile命令检查ssh key host host_key_checking = False # 开启日志记录 log_path = /var/log/ansible.log 测试 # 控制主机 ansible all -m ping Inventory 配置组别 vim /etc/ansible/hosts # 添加组别 [pve] 192.168.0.2 192.168.0.3 192.168.0.4 #测试 ansible pve -m ping Inventory 参数 把你的 inventory 文件 和 变量 放入 git repo 中,以便跟踪他们的更新,这是一种非常推荐的方式. 参数 作用 ansible_ssh_host 将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置.","permalink":"https://test.jobcher.com/ansible-%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2.html","summary":"ansible 安装和部署 Ansible 默认通过 SSH 协议管理机器.\n安装 ansible 下载安装 # ubuntu 安装 apt-get install software-properties-common apt-add-repository ppa:ansible/ansible apt-get update apt-get install ansible # centos 安装 yum install ansible 检查文件 #检查 ansible --version ansible 配置 添加主机 vim /etc/ansible/hosts #添加你需要添加的被控主机地址和IP 配置 SSH key 授权访问 # 控制主机生成ssh 密钥对（一路回车） ssh-keygen -t rsa # 复制公钥IP到被控主机 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.2 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.3 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.4 # ssh-copy-id命令会自动将id_rsa.pub文件的内容追加到远程主机root用户下.ssh/authorized_keys文件中。 更改 ansible 配置 vim /etc/ansible/ansible.cfg #禁用每次执行ansbile命令检查ssh key host host_key_checking = False # 开启日志记录 log_path = /var/log/ansible.","title":"ansible 安装和部署"},{"content":"yaml 语法 我们使用 YAML 是因为它像 XML 或 JSON 是一种利于人们读写的数据格式. 此外在大多数变成语言中有使用 YAML 的库.YAML 语法的基本概述, 它被用来描述一个 playbooks(我们的配置管理语言).\n基本的 YAML 对于 Ansible, 每一个 YAML 文件都是从一个列表开始. 列表中的每一项都是一个键值对, 通常它们被称为一个 “哈希” 或 “字典”. 所以, 我们需要知道如何在 YAML 中编写列表和字典.\nYAML 还有一个小的怪癖. 所有的 YAML 文件(无论和 Ansible 有没有关系)开始行都应该是 \u0026amp;mdash;. 这是 YAML 格式的一部分, 表明一个文件的开始.\n--- # 一个美味水果的列表 - Apple - Orange - Strawberry - Mango ","permalink":"https://test.jobcher.com/yaml-%E8%AF%AD%E6%B3%95.html","summary":"yaml 语法 我们使用 YAML 是因为它像 XML 或 JSON 是一种利于人们读写的数据格式. 此外在大多数变成语言中有使用 YAML 的库.YAML 语法的基本概述, 它被用来描述一个 playbooks(我们的配置管理语言).\n基本的 YAML 对于 Ansible, 每一个 YAML 文件都是从一个列表开始. 列表中的每一项都是一个键值对, 通常它们被称为一个 “哈希” 或 “字典”. 所以, 我们需要知道如何在 YAML 中编写列表和字典.\nYAML 还有一个小的怪癖. 所有的 YAML 文件(无论和 Ansible 有没有关系)开始行都应该是 \u0026mdash;. 这是 YAML 格式的一部分, 表明一个文件的开始.\n--- # 一个美味水果的列表 - Apple - Orange - Strawberry - Mango ","title":"yaml 语法"},{"content":"logrotate 日志滚动的使用 logrotate 日志滚动切割工具，是 linux 默认安装的工具，配置文件位置：\n/etc/logrotate.conf /etc/logrotate.d/ 参数 以 nginx 配置为例\n/opt/log/nginx/*.log { daily missingok rotate 14 errors \u0026amp;#34;nb@nbtyfood.com\u0026amp;#34; compress delaycompress notifempty create 0640 www-data adm sharedscripts prerotate if [ -d /etc/logrotate.d/httpd-prerotate ]; then \\ run-parts /etc/logrotate.d/httpd-prerotate; \\ fi \\ endscript postrotate invoke-rc.d nginx rotate \u0026amp;gt;/dev/null 2\u0026amp;gt;\u0026amp;amp;1 endscript } 参数 作用 compress 压缩日志文件的所有非当前版本 daily,weekly,monthly 按指定计划轮换日志文件 delaycompress 压缩所有版本，除了当前和下一个最近的 endscript 标记 prerotate 或 postrotate 脚本的结束 errors \u0026amp;ldquo;emailid\u0026amp;rdquo; 给指定邮箱发送错误通知 missingok 如果日志文件丢失，不要显示错误 notifempty 如果日志文件为空，则不轮换日志文件 olddir \u0026amp;ldquo;dir\u0026amp;rdquo; 指定日志文件的旧版本放在 “dir” 中 postrotate 引入一个在日志被轮换后执行的脚本 prerotate 引入一个在日志被轮换前执行的脚本 rotate \u0026amp;rsquo;n\u0026#39; 在轮换方案中包含日志的 n 个版本 sharedscripts 对于整个日志组只运行一次脚本 size=\u0026amp;lsquo;logsize\u0026amp;rsquo; 在日志大小大于 logsize（例如 100K，4M）时轮换 ","permalink":"https://test.jobcher.com/logrotate-%E6%97%A5%E5%BF%97%E6%BB%9A%E5%8A%A8%E7%9A%84%E4%BD%BF%E7%94%A8.html","summary":"logrotate 日志滚动的使用 logrotate 日志滚动切割工具，是 linux 默认安装的工具，配置文件位置：\n/etc/logrotate.conf /etc/logrotate.d/ 参数 以 nginx 配置为例\n/opt/log/nginx/*.log { daily missingok rotate 14 errors \u0026#34;nb@nbtyfood.com\u0026#34; compress delaycompress notifempty create 0640 www-data adm sharedscripts prerotate if [ -d /etc/logrotate.d/httpd-prerotate ]; then \\ run-parts /etc/logrotate.d/httpd-prerotate; \\ fi \\ endscript postrotate invoke-rc.d nginx rotate \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 endscript } 参数 作用 compress 压缩日志文件的所有非当前版本 daily,weekly,monthly 按指定计划轮换日志文件 delaycompress 压缩所有版本，除了当前和下一个最近的 endscript 标记 prerotate 或 postrotate 脚本的结束 errors \u0026ldquo;emailid\u0026rdquo; 给指定邮箱发送错误通知 missingok 如果日志文件丢失，不要显示错误 notifempty 如果日志文件为空，则不轮换日志文件 olddir \u0026ldquo;dir\u0026rdquo; 指定日志文件的旧版本放在 “dir” 中 postrotate 引入一个在日志被轮换后执行的脚本 prerotate 引入一个在日志被轮换前执行的脚本 rotate \u0026rsquo;n' 在轮换方案中包含日志的 n 个版本 sharedscripts 对于整个日志组只运行一次脚本 size=\u0026lsquo;logsize\u0026rsquo; 在日志大小大于 logsize（例如 100K，4M）时轮换 ","title":"logrotate 日志滚动的使用"},{"content":"安装 docker 通过 docker 脚本安装\ncurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun curl -sSL https://get.daocloud.io/docker | sh docker-compose 安装 #下载安装 sudo curl -L \u0026amp;#34;https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)\u0026amp;#34; -o /usr/local/bin/docker-compose #可执行权限 sudo chmod +x /usr/local/bin/docker-compose #创建软链： sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose #测试是否安装成功 docker-compose --version docker 命令 常用 docker 命令\n#查看容器 docker ps #查看镜像 docker images #停止当前所有容器 docker stop $(docker ps -aq) #删除当前停止的所有容器 docker rm $(docker ps -aq) #删除镜像 docker rmi nginx ","permalink":"https://test.jobcher.com/docker-%E5%91%BD%E4%BB%A4.html","summary":"安装 docker 通过 docker 脚本安装\ncurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun curl -sSL https://get.daocloud.io/docker | sh docker-compose 安装 #下载安装 sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose #可执行权限 sudo chmod +x /usr/local/bin/docker-compose #创建软链： sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose #测试是否安装成功 docker-compose --version docker 命令 常用 docker 命令\n#查看容器 docker ps #查看镜像 docker images #停止当前所有容器 docker stop $(docker ps -aq) #删除当前停止的所有容器 docker rm $(docker ps -aq) #删除镜像 docker rmi nginx ","title":"docker 命令"},{"content":"gitlab 与 github 同步项目 本地同步项目 git clone 创建一个同名的项目,命令行终端中添加 remote 地址 git remote add githubOrigin git@github.com:sjtfreaks/blog.git 项目同步到 Github 上 git push -u githubOrigin main 分别同步 github 与 gitlab 即可 git push -u githubOrigin main git push -u origin main ","permalink":"https://test.jobcher.com/gitlab%E4%B8%8Egithub%E5%90%8C%E6%AD%A5%E9%A1%B9%E7%9B%AE.html","summary":"gitlab 与 github 同步项目 本地同步项目 git clone 创建一个同名的项目,命令行终端中添加 remote 地址 git remote add githubOrigin git@github.com:sjtfreaks/blog.git 项目同步到 Github 上 git push -u githubOrigin main 分别同步 github 与 gitlab 即可 git push -u githubOrigin main git push -u origin main ","title":"gitlab与github同步项目"},{"content":"iptables 基础知识 内核包过滤与 NAT 管理工具.是 linux 系统中在用户空间中运行的运来配置内核防火墙的工具。它可以设置，维护和检查 linux 内核中的 ipv4 包过滤规则和管理网络地址转换（NAT）。\nipatbles 命令仅支持 ipv4，如果使用的 IP 协议是 ipv6 则需要使用专门的管理工具 ip6tables。\n常用参数 参数 作用 -t\u0026amp;lt;表\u0026amp;gt; 指定要操纵的表 -A 向规则链中追加条目 -D 从规则链中删除条目 -I 向规则链中插入条目 -R 替换规则链中的相应条目 -L 显示规则链中的已有条目 -F 清除规则链中的现有条目。不改变规则链的默认目标策略 -Z 清空规则链中的数据包计数器和字节计数器 -N 创建新的用户自定义规则链 -P 定义规则链中的默认目标（策略） -h 显示帮助信息 -p\u0026amp;lt;协议\u0026amp;gt; 指定要匹配的数据包的协议类型 -s\u0026amp;lt;源地址\u0026amp;gt; 指定要匹配的数据包的源 IP 地址 -j\u0026amp;lt;目标\u0026amp;gt; 指定要跳转的目标 -i\u0026amp;lt;网络接口\u0026amp;gt; 指定数据包进入本机的网络接口 -o\u0026amp;lt;网络接口\u0026amp;gt; 指定数据包离开本机做使用的网络接口 -c\u0026amp;lt;包计数\u0026amp;gt; 在执行插入、追加和替换操作时初始化包计数器和字节计数器 参考实例 显示内核当前的 filter 表：\niptables -L 显示内核当前的 nat 表：\niptables -L -t nat 禁止本机对 192.168.20.20 地址的访问：\niptables -t filter -A OUTPUT -d 192.168.20.20 -j DROP 显示 filter 表的 OUTPUT 链：\niptables -L OUTPUT -t filter ","permalink":"https://test.jobcher.com/iptables-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html","summary":"iptables 基础知识 内核包过滤与 NAT 管理工具.是 linux 系统中在用户空间中运行的运来配置内核防火墙的工具。它可以设置，维护和检查 linux 内核中的 ipv4 包过滤规则和管理网络地址转换（NAT）。\nipatbles 命令仅支持 ipv4，如果使用的 IP 协议是 ipv6 则需要使用专门的管理工具 ip6tables。\n常用参数 参数 作用 -t\u0026lt;表\u0026gt; 指定要操纵的表 -A 向规则链中追加条目 -D 从规则链中删除条目 -I 向规则链中插入条目 -R 替换规则链中的相应条目 -L 显示规则链中的已有条目 -F 清除规则链中的现有条目。不改变规则链的默认目标策略 -Z 清空规则链中的数据包计数器和字节计数器 -N 创建新的用户自定义规则链 -P 定义规则链中的默认目标（策略） -h 显示帮助信息 -p\u0026lt;协议\u0026gt; 指定要匹配的数据包的协议类型 -s\u0026lt;源地址\u0026gt; 指定要匹配的数据包的源 IP 地址 -j\u0026lt;目标\u0026gt; 指定要跳转的目标 -i\u0026lt;网络接口\u0026gt; 指定数据包进入本机的网络接口 -o\u0026lt;网络接口\u0026gt; 指定数据包离开本机做使用的网络接口 -c\u0026lt;包计数\u0026gt; 在执行插入、追加和替换操作时初始化包计数器和字节计数器 参考实例 显示内核当前的 filter 表：\niptables -L 显示内核当前的 nat 表：\niptables -L -t nat 禁止本机对 192.","title":"iptables 基础知识"},{"content":"k3s 升级版本 停止所有的 K3s 容器（慎用） 从 server 节点运行 killall 脚本\n/usr/local/bin/k3s-killall.sh 开始升级 使用安装脚本升级 K3s curl -sfL https://get.k3s.io | sh - #国内可用 curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - 重启 k3s sudo systemctl restart k3s ","permalink":"https://test.jobcher.com/k3s-%E5%8D%87%E7%BA%A7%E7%89%88%E6%9C%AC.html","summary":"k3s 升级版本 停止所有的 K3s 容器（慎用） 从 server 节点运行 killall 脚本\n/usr/local/bin/k3s-killall.sh 开始升级 使用安装脚本升级 K3s curl -sfL https://get.k3s.io | sh - #国内可用 curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - 重启 k3s sudo systemctl restart k3s ","title":"k3s 升级版本"},{"content":"安装配置 Terraform 安装 macOS 苹果系统安装 #安装 brew tap hashicorp/tap brew install hashicorp/tap/terraform # 更新 brew update brew upgrade hashicorp/tap/terraform #验证安装 terraform -help windows 系统安装 #安装 choco install terraform #直接到这个url里下载64位系统 https://www.terraform.io/downloads #验证安装 terraform -help Linux 安装 curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - sudo apt-add-repository \u0026amp;#34;deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026amp;#34; sudo apt-get update \u0026amp;amp;\u0026amp;amp; sudo apt-get install terraform #验证安装 terraform -help wget -O- https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo | sudo tee /etc/yum.repos.d/hashicorp.repo sudo yum install terraform -y terrafrom 控制 proxmox 虚拟机 来源：https://github.com/Telmate/terraform-provider-proxmox\n首先你要有一台 pve 主机 安装过程本篇文章就不想了，主要是要写一下关于他的配置\nhttps://pve.proxmox.com/pve-docs/\n下载 wget https://github.com/Telmate/terraform-provider-proxmox/releases/download/v2.9.3/terraform-provider-proxmox_2.9.3_linux_amd64.zip unzip","permalink":"https://test.jobcher.com/%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-terraform.html","summary":"安装配置 Terraform 安装 macOS 苹果系统安装 #安装 brew tap hashicorp/tap brew install hashicorp/tap/terraform # 更新 brew update brew upgrade hashicorp/tap/terraform #验证安装 terraform -help windows 系统安装 #安装 choco install terraform #直接到这个url里下载64位系统 https://www.terraform.io/downloads #验证安装 terraform -help Linux 安装 curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - sudo apt-add-repository \u0026#34;deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026#34; sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install terraform #验证安装 terraform -help wget -O- https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo | sudo tee /etc/yum.repos.d/hashicorp.repo sudo yum install terraform -y terrafrom 控制 proxmox 虚拟机 来源：https://github.","title":"安装配置 Terraform"},{"content":"孜然杏鲍菇-素食 准备食材 杏鲍菇 蒜 糖 白芝麻 孜然粉 老抽 生抽 蚝油 步骤 杏鲍菇切片 蒜切成末 热油下蒜爆香 杏鲍菇下锅把水分炒干 加一勺生抽、半勺老抽，半勺蚝油，一勺孜然粉，一勺白芝麻，半勺糖炒匀 ","permalink":"https://test.jobcher.com/%E5%AD%9C%E7%84%B6%E6%9D%8F%E9%B2%8D%E8%8F%87-%E7%B4%A0%E9%A3%9F.html","summary":"孜然杏鲍菇-素食 准备食材 杏鲍菇 蒜 糖 白芝麻 孜然粉 老抽 生抽 蚝油 步骤 杏鲍菇切片 蒜切成末 热油下蒜爆香 杏鲍菇下锅把水分炒干 加一勺生抽、半勺老抽，半勺蚝油，一勺孜然粉，一勺白芝麻，半勺糖炒匀 ","title":"孜然杏鲍菇-素食"},{"content":"mysql 数据库备份迁移 使用 mydumper 做数据备份迁移\n备份数据库 安装 # 安装 centos yum install https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper-0.11.5-1.el7.x86_64.rpm yum install https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper-0.11.5-1.el8.x86_64.rpm # 安装 ubuntu apt-get install libatomic1 wget https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper_0.11.5-1.$(lsb_release -cs)_amd64.deb dpkg -i mydumper_0.11.5-1.$(lsb_release -cs)_amd64.deb 备份 nohup mydumper -h \u0026amp;#39;备份数据库\u0026amp;#39; \\ -u \u0026amp;#39;用户名\u0026amp;#39; \\ -p \u0026amp;#39;密码\u0026amp;#39; \\ --threads=16 \\ -B 备份数据库 \\ -v 3 \\ --outputdir=./backup --rows=100000 \\ -L mydumper-logs.log \u0026amp;amp; 迁移数据库 还原数据 nohup myloader -h \u0026amp;#39;迁移数据库\u0026amp;#39; \\ -u \u0026amp;#39;用户名\u0026amp;#39; \\ -p \u0026amp;#39;密码\u0026amp;#39; \\ --directory=./backup \\ -s 来源数据库 \\ -B 还原数据库 \\ -t 16 \\ -v 3 \\ -e 2\u0026amp;gt;myloader-logs.log \u0026amp;amp; mydumper/myloader 参数 mydumper Usage: mydumper [OPTION...] multi-threaded MySQL dumping Help Options: -?, --help Show help options Application Options: -B, --database 需要备份的数据库，一个数据库一条命令备份，要不就是备份所有","permalink":"https://test.jobcher.com/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E8%BF%81%E7%A7%BB.html","summary":"mysql 数据库备份迁移 使用 mydumper 做数据备份迁移\n备份数据库 安装 # 安装 centos yum install https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper-0.11.5-1.el7.x86_64.rpm yum install https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper-0.11.5-1.el8.x86_64.rpm # 安装 ubuntu apt-get install libatomic1 wget https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper_0.11.5-1.$(lsb_release -cs)_amd64.deb dpkg -i mydumper_0.11.5-1.$(lsb_release -cs)_amd64.deb 备份 nohup mydumper -h \u0026#39;备份数据库\u0026#39; \\ -u \u0026#39;用户名\u0026#39; \\ -p \u0026#39;密码\u0026#39; \\ --threads=16 \\ -B 备份数据库 \\ -v 3 \\ --outputdir=./backup --rows=100000 \\ -L mydumper-logs.log \u0026amp; 迁移数据库 还原数据 nohup myloader -h \u0026#39;迁移数据库\u0026#39; \\ -u \u0026#39;用户名\u0026#39; \\ -p \u0026#39;密码\u0026#39; \\ --directory=./backup \\ -s 来源数据库 \\ -B 还原数据库 \\ -t 16 \\ -v 3 \\ -e 2\u0026gt;myloader-logs.","title":"mysql数据库备份迁移"},{"content":"nginx 编译参数详解 nginx 编译参数 作用 –prefix= 指向安装目录 –sbin-path 指向（执行）程序文件（nginx） –conf-path= 指向配置文件（nginx.conf） –error-log-path= 指向错误日志目录 –pid-path= 指向 pid 文件（nginx.pid） –lock-path= 指向 lock 文件（nginx.lock）（安装文件锁定，防止安装文件被别人利用，或自己误操作。） –user= 指定程序运行时的非特权用户 –group= 指定程序运行时的非特权用户组 –builddir= 指向编译目录 –with-rtsig_module 启用 rtsig 模块支持（实时信号） –with-select_module 启用 select 模块支持（一种轮询模式,不推荐在高载环境下使用）禁用：–withoutselect_module –with-poll_module 启用 poll 模块支持（功能与 select 相同，与 select 特性相同，为一种轮询模式,不推荐在高载环境下使用） –with-file-aio 启用 file aio 支持（一种 APL 文件传输格式） –with-ipv6 启用 ipv6 支持 –with-http_ssl_module 启用 ngx_http_ssl_module 支持（使支持 https 请求，需已安装 openssl） –with-http_realip_module 启用 ngx_http_realip_module 支持（这个模块允许从请求标头更改客户端的 IP 地址值，默认为关） –with-http_addition_module 启用 ngx_http_addition_module 支持（作为一个输出过滤器，支持不完全缓冲，分部分响应请求） –with-http_xslt_module 启用 ngx_http_xslt_module 支持（过滤转换 XML 请求 –with-http_image_filter_module 启用 ngx_http_image_filter_module 支持（传输 JPEG/GIF/PNG 图片的一个过滤器）（默认为不启用。gd 库要用到） –with-http_geoip_module 启用 ngx_http_geoip_module 支持（该模块创建基","permalink":"https://test.jobcher.com/nginx-%E7%BC%96%E8%AF%91%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3.html","summary":"nginx 编译参数详解 nginx 编译参数 作用 –prefix= 指向安装目录 –sbin-path 指向（执行）程序文件（nginx） –conf-path= 指向配置文件（nginx.conf） –error-log-path= 指向错误日志目录 –pid-path= 指向 pid 文件（nginx.pid） –lock-path= 指向 lock 文件（nginx.lock）（安装文件锁定，防止安装文件被别人利用，或自己误操作。） –user= 指定程序运行时的非特权用户 –group= 指定程序运行时的非特权用户组 –builddir= 指向编译目录 –with-rtsig_module 启用 rtsig 模块支持（实时信号） –with-select_module 启用 select 模块支持（一种轮询模式,不推荐在高载环境下使用）禁用：–withoutselect_module –with-poll_module 启用 poll 模块支持（功能与 select 相同，与 select 特性相同，为一种轮询模式,不推荐在高载环境下使用） –with-file-aio 启用 file aio 支持（一种 APL 文件传输格式） –with-ipv6 启用 ipv6 支持 –with-http_ssl_module 启用 ngx_http_ssl_module 支持（使支持 https 请求，需已安装 openssl） –with-http_realip_module 启用 ngx_http_realip_module 支持（这个模块允许从请求标头更改客户端的 IP 地址值，默认为关） –with-http_addition_module 启用 ngx_http_addition_module 支持（作为一个输出过滤器，支持不完全缓冲，分部分响应请求） –with-http_xslt_module 启用 ngx_http_xslt_module 支持（过滤转换 XML 请求 –with-http_image_filter_module 启用 ngx_http_image_filter_module 支持（传输 JPEG/GIF/PNG 图片的一个过滤器）（默认为不启用。gd 库要用到） –with-http_geoip_module 启用 ngx_http_geoip_module 支持（该模块创建基","title":"nginx 编译参数详解"},{"content":"nginx 重写规则 rewrite 模块 语法 语法 默认值 使用字段 作用 break none server, location, if 完成当前设置的重写规则，停止执行其他的重写规则。 set variable value none server, location, if 为给定的变量设置一个特定值。 return code none server, location, if 停止处理并为客户端返回状态码。非标准的 444 状态码将关闭连接，不发送任何响应头。可以使用的状态码有：204，400，402-406，408，410, 411, 413, 416 与 500-504。如果状态码附带文字段落，该文本将被放置在响应主体。相反，如果状态码后面是一个 URL，该 URL 将成为 location 头补值。没有状态码的 URL 将被视为一个 302 状态码。 rewrite_log on rewrite_log off server, location, if 启用时将在 error log 中记录 notice 级别的重写日志。 rewrite regex replacement flag none server, location, if 按照相关的正则表达式与字符串修改 URI，指令按照在配置文件中出现的顺序执行。可以在重写指令后面添加标记。注意：如果替换的字符串以 http://开头，请求将被重定向，并且不再执行多余的 rewrite 指令。尾部的标记(flag)可以是以下的值：last – 停止处理重写模块指令，之后搜索 location 与更改后的 URI 匹配.break – 完成重写指令。redirect – 返回 302 临时重定向，如果替换字段用 http://开头则被使用。permanent – 返回 301 永久重定向。 if (condition) { … } none server, location 尽量考虑使用 trp_files 代替。判断的条件可以有以下值 一个变量的名称：空字符传”“或者一些“0”开始的字符串为 false。 字符串比较：使用=或!=运算符 正则表达式匹配：使用~(区分大小写)和~(不区分大小写)，取反运算!~和!~。 文件是否存在：使用-f 和!-f 操作符 目录是否存在：使用-d 和!-d 操作符 文件、目录、符号链接是否存在：使用-e 和!-e ","permalink":"https://test.jobcher.com/nginx-%E9%87%8D%E5%86%99%E8%A7%84%E5%88%99-rewrite%E6%A8%A1%E5%9D%97.html","summary":"nginx 重写规则 rewrite 模块 语法 语法 默认值 使用字段 作用 break none server, location, if 完成当前设置的重写规则，停止执行其他的重写规则。 set variable value none server, location, if 为给定的变量设置一个特定值。 return code none server, location, if 停止处理并为客户端返回状态码。非标准的 444 状态码将关闭连接，不发送任何响应头。可以使用的状态码有：204，400，402-406，408，410, 411, 413, 416 与 500-504。如果状态码附带文字段落，该文本将被放置在响应主体。相反，如果状态码后面是一个 URL，该 URL 将成为 location 头补值。没有状态码的 URL 将被视为一个 302 状态码。 rewrite_log on rewrite_log off server, location, if 启用时将在 error log 中记录 notice 级别的重写日志。 rewrite regex replacement flag none server, location, if 按照相关的正则表达式与字符串修改 URI，指令按照在配置文件中出现的顺序执行。可以在重写指令后面添加标记。注意：如果替换的字符串以 http://开头，请求将被重定向，并且不再执行多余的 rewrite 指令。尾部的标记(flag)可以是以下的值：last – 停止处理重写模块指令，之后搜索 location 与更改后的 URI 匹配.","title":"nginx 重写规则 rewrite模块"},{"content":"nginx.conf 配置文件详解 # vim nginx.conf user nobody nobody; # 运行 nginx 的所属组和所有者 worker_processes 2; # 开启两个 nginx 工作进程,一般几个 CPU 核心就写几 error_log logs/error.log notice; # 错误日志路径 pid logs/nginx.pid; # pid 路径 events { worker_connections 1024; # 一个进程能同时处理 1024 个请求 } http { include mime.types; default_type application/octet-stream; log_format main ‘$remote_addr – $remote_user [$time_local] “$request” ‘ ‘$status $body_bytes_sent “$http_referer” ‘ ‘”$http_user_agent” “$http_x_forwarded_for”‘; access_log logs/access.log main; # 默认访问日志路径 sendfile on; keepalive_timeout 65; # keepalive 超市时间 # 开始配置一个域名,一个 server 配置段一般对应一个域名 server { listen 80; # # 在本机所有 ip 上监听 80,也可以写为 192.168.1.202:80,这样的话,就只监听 192.168.1.202 上的 80 口 server_name www.nbtyfood.com; # 域名 root /www/html/www.nbtyfood.com; # 站点根目录（程序目录） index index.html index.htm; # 索引文件 location / { # 可以有多个 location root /www/html/www.nbtyfood.com; # 站点根目录（程序目录） } error_page 500 502 503 504 /50x.html; # 定义错误页面,如果是 500 错误,则把站点根目录下的 50x.html 返回给用户 location = /50x.html { root","permalink":"https://test.jobcher.com/nginx.conf-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3.html","summary":"nginx.conf 配置文件详解 # vim nginx.conf user nobody nobody; # 运行 nginx 的所属组和所有者 worker_processes 2; # 开启两个 nginx 工作进程,一般几个 CPU 核心就写几 error_log logs/error.log notice; # 错误日志路径 pid logs/nginx.pid; # pid 路径 events { worker_connections 1024; # 一个进程能同时处理 1024 个请求 } http { include mime.types; default_type application/octet-stream; log_format main ‘$remote_addr – $remote_user [$time_local] “$request” ‘ ‘$status $body_bytes_sent “$http_referer” ‘ ‘”$http_user_agent” “$http_x_forwarded_for”‘; access_log logs/access.log main; # 默认访问日志路径 sendfile on; keepalive_timeout 65; # keepalive 超市时间 # 开始配置一个域名,一个 server 配置段一般对应一个域名 server { listen 80; # # 在本机所有 ip 上监听 80,也可以写为 192.","title":"nginx.conf 配置文件详解"},{"content":"网络基础知识 1、简述 ISO/OSI 七层模型的分层与作用 分层 作用 应用层 应用系统，提供用户服务 例如：HTTP、HTTPS、FTP、Telnet、SSH、SMTP、POP3 表示层 把数据转换为能与接收者的系统格式兼容并适合传输的格式，数据表示，加密，压缩 会话层 负责在数据传输中设置和维护计算机网络中两台计算机之间的通信连接。确定数据是否需要进行网络传递 分流网络传递还是本地保存 传输层 对数据分组，对报文进行分组(发送时)、组装(接收时)提供传输协议的选择：TCP (传输控制协议) :可靠的，面向连接的传输协议 (可靠，准确) (慢)UDP (用户数据报协议) :不可靠的，面向无连接的传输协议 (快) (不可靠)。端口封装，差错校验，滑动窗口，留空 网络层 网络层（Network Layer）决定数据的路径选择和转寄，将网络表头（NH）加至数据包，以形成分组。网络表头包含了网络资料。例如:互联网协议（IP）等。1.IP 地址编址 2.路由选择 3.静态路由 4.动态路由 数据链路层 数据链路层（Data Link Layer）负责网络寻址、错误侦测和改错。1.MAC 地址编址 2.MAC 地址寻址 3.差错校验 物理层 物理层（Physical Layer）在局域网上发送数据帧（Data Frame）1.数据实际传输 2.电气特性定义 2、TCP/IP 四层模型与作用？ 分层 协议 应用层 HTTP、HTTPS、FTP、Telnet、SSH、SMTP、DNS 传输层 TCP、UDP 网络层 ICMP、IGMP、IP、ARP、RARP 数据链路层、物理层 PPP、PPPOE 3、TCP 协议与 UDP 协议工作在哪一层，作用是什么？ 传输层，对报文进行分组(发送时)、组装(接收时)提供\n当进程需要传输可靠的数据时应使用 TCP，当进程需要高效传输数据，可以忽略可靠性时应使用 UDP 协议。\n4、简述 TCP 三次握手的过程。 第一次握手：Client 将标志位 SYN 置为 1，随机产生一个值 seq=J，并将该数据包发送给 Server，Client 进入 SYN_SENT 状态，等待 Server 确认。 第二次握手：Server 收到数据包后由标志位 SYN=1 知道 Client 请求建立连接，Server 将标志位 SYN 和 ACK 都置为 1，ack=J+1，随机产生一个值 seq=K，","permalink":"https://test.jobcher.com/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html","summary":"网络基础知识 1、简述 ISO/OSI 七层模型的分层与作用 分层 作用 应用层 应用系统，提供用户服务 例如：HTTP、HTTPS、FTP、Telnet、SSH、SMTP、POP3 表示层 把数据转换为能与接收者的系统格式兼容并适合传输的格式，数据表示，加密，压缩 会话层 负责在数据传输中设置和维护计算机网络中两台计算机之间的通信连接。确定数据是否需要进行网络传递 分流网络传递还是本地保存 传输层 对数据分组，对报文进行分组(发送时)、组装(接收时)提供传输协议的选择：TCP (传输控制协议) :可靠的，面向连接的传输协议 (可靠，准确) (慢)UDP (用户数据报协议) :不可靠的，面向无连接的传输协议 (快) (不可靠)。端口封装，差错校验，滑动窗口，留空 网络层 网络层（Network Layer）决定数据的路径选择和转寄，将网络表头（NH）加至数据包，以形成分组。网络表头包含了网络资料。例如:互联网协议（IP）等。1.IP 地址编址 2.路由选择 3.静态路由 4.动态路由 数据链路层 数据链路层（Data Link Layer）负责网络寻址、错误侦测和改错。1.MAC 地址编址 2.MAC 地址寻址 3.差错校验 物理层 物理层（Physical Layer）在局域网上发送数据帧（Data Frame）1.数据实际传输 2.电气特性定义 2、TCP/IP 四层模型与作用？ 分层 协议 应用层 HTTP、HTTPS、FTP、Telnet、SSH、SMTP、DNS 传输层 TCP、UDP 网络层 ICMP、IGMP、IP、ARP、RARP 数据链路层、物理层 PPP、PPPOE 3、TCP 协议与 UDP 协议工作在哪一层，作用是什么？ 传输层，对报文进行分组(发送时)、组装(接收时)提供\n当进程需要传输可靠的数据时应使用 TCP，当进程需要高效传输数据，可以忽略可靠性时应使用 UDP 协议。\n4、简述 TCP 三次握手的过程。 第一次握手：Client 将标志位 SYN 置为 1，随机产生一个值 seq=J，并将该数据包发送给 Server，Client 进入 SYN_SENT 状态，等待 Server 确认。 第二次握手：Server 收到数据包后由标志位 SYN=1 知道 Client 请求建立连接，Server 将标志位 SYN 和 ACK 都置为 1，ack=J+1，随机产生一个值 seq=K，","title":"网络基础知识"},{"content":"docker 安装 kong 网关 建立数据库 创建网络 docker network create kong-net 建立数据库 docker run -d --name kong-database \\ --network=kong-net \\ -p 5432:5432 \\ -e \u0026amp;#34;POSTGRES_USER=kong\u0026amp;#34; \\ -e \u0026amp;#34;POSTGRES_DB=kong\u0026amp;#34; \\ -e \u0026amp;#34;POSTGRES_PASSWORD=kong123\u0026amp;#34; \\ postgres:9.6 创建 kong 数据 docker run --rm --network=kong-net \\ -e \u0026amp;#34;KONG_DATABASE=postgres\u0026amp;#34; \\ -e \u0026amp;#34;KONG_PG_HOST=kong-database\u0026amp;#34; \\ -e \u0026amp;#34;KONG_PG_PASSWORD=kong123\u0026amp;#34; \\ -e \u0026amp;#34;KONG_PASSWORD=kong123\u0026amp;#34; \\ kong:latest kong migrations bootstrap 创建 kong 创建 kong gateway docker run -d --name kong \\ --network=kong-net \\ -e \u0026amp;#34;KONG_DATABASE=postgres\u0026amp;#34; \\ -e \u0026amp;#34;KONG_PG_HOST=kong-database\u0026amp;#34; \\ -e \u0026amp;#34;KONG_PG_USER=kong\u0026amp;#34; \\ -e \u0026amp;#34;KONG_PG_PASSWORD=kong123\u0026amp;#34; \\ -e \u0026amp;#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database\u0026amp;#34; \\ -e \u0026amp;#34;KONG_PROXY_ACCESS_LOG=/dev/stdout\u0026amp;#34; \\ -e \u0026amp;#34;KONG_ADMIN_ACCESS_LOG=/dev/stdout\u0026amp;#34; \\ -e \u0026amp;#34;KONG_PROXY_ERROR_LOG=/dev/stderr\u0026amp;#34; \\ -e \u0026amp;#34;KONG_ADMIN_ERROR_LOG=/dev/stderr\u0026amp;#34; \\ -e \u0026amp;#34;KONG_ADMIN_LISTEN=0.0.0.0:8001,","permalink":"https://test.jobcher.com/docker-%E5%AE%89%E8%A3%85kong-%E7%BD%91%E5%85%B3.html","summary":"docker 安装 kong 网关 建立数据库 创建网络 docker network create kong-net 建立数据库 docker run -d --name kong-database \\ --network=kong-net \\ -p 5432:5432 \\ -e \u0026#34;POSTGRES_USER=kong\u0026#34; \\ -e \u0026#34;POSTGRES_DB=kong\u0026#34; \\ -e \u0026#34;POSTGRES_PASSWORD=kong123\u0026#34; \\ postgres:9.6 创建 kong 数据 docker run --rm --network=kong-net \\ -e \u0026#34;KONG_DATABASE=postgres\u0026#34; \\ -e \u0026#34;KONG_PG_HOST=kong-database\u0026#34; \\ -e \u0026#34;KONG_PG_PASSWORD=kong123\u0026#34; \\ -e \u0026#34;KONG_PASSWORD=kong123\u0026#34; \\ kong:latest kong migrations bootstrap 创建 kong 创建 kong gateway docker run -d --name kong \\ --network=kong-net \\ -e \u0026#34;KONG_DATABASE=postgres\u0026#34; \\ -e \u0026#34;KONG_PG_HOST=kong-database\u0026#34; \\ -e \u0026#34;KONG_PG_USER=kong\u0026#34; \\ -e \u0026#34;KONG_PG_PASSWORD=kong123\u0026#34; \\ -e \u0026#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database\u0026#34; \\ -e \u0026#34;KONG_PROXY_ACCESS_LOG=/dev/stdout\u0026#34; \\ -e \u0026#34;KONG_ADMIN_ACCESS_LOG=/dev/stdout\u0026#34; \\ -e \u0026#34;KONG_PROXY_ERROR_LOG=/dev/stderr\u0026#34; \\ -e \u0026#34;KONG_ADMIN_ERROR_LOG=/dev/stderr\u0026#34; \\ -e \u0026#34;KONG_ADMIN_LISTEN=0.","title":"docker 安装kong 网关"},{"content":"搭建 docker registry 镜像仓库 获取镜像 docker pull registry:2.7.1 docker pull hyper/docker-registry-web 容器运行 mkdir -p /opt/data/registry docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry --name registry registry:2.7.1 docker run -d -p 8080:8080 --name registry-web --link registry \\ -e REGISTRY_URL=http://192.168.99.146:5000/v2 \\ -e REGISTRY_TRUST_ANY_SSL=true \\ -e REGISTRY_BASIC_AUTH=\u0026amp;#34;GjhYGDGi2HhkJB\u0026amp;#34; \\ -e REGISTRY_NAME=192.168.99.146:5000 \\ hyper/docker-registry-web 上传容器 vim /etc/docker/daemon.json { \u0026amp;#34;insecure-registries\u0026amp;#34;: [\u0026amp;#34;192.168.99.146:5000\u0026amp;#34;] } docker tag sjtfreaks/hogo-nginx:v1.1 192.168.99.146:5000/sjtfreaks/hogo-nginx:v1.1 docker push 192.168.99.146:5000/sjtfreaks/hogo-nginx:v1.1 ","permalink":"https://test.jobcher.com/%E6%90%AD%E5%BB%BAdocker-registry-%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93.html","summary":"搭建 docker registry 镜像仓库 获取镜像 docker pull registry:2.7.1 docker pull hyper/docker-registry-web 容器运行 mkdir -p /opt/data/registry docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry --name registry registry:2.7.1 docker run -d -p 8080:8080 --name registry-web --link registry \\ -e REGISTRY_URL=http://192.168.99.146:5000/v2 \\ -e REGISTRY_TRUST_ANY_SSL=true \\ -e REGISTRY_BASIC_AUTH=\u0026#34;GjhYGDGi2HhkJB\u0026#34; \\ -e REGISTRY_NAME=192.168.99.146:5000 \\ hyper/docker-registry-web 上传容器 vim /etc/docker/daemon.json { \u0026#34;insecure-registries\u0026#34;: [\u0026#34;192.168.99.146:5000\u0026#34;] } docker tag sjtfreaks/hogo-nginx:v1.1 192.168.99.146:5000/sjtfreaks/hogo-nginx:v1.1 docker push 192.168.99.146:5000/sjtfreaks/hogo-nginx:v1.1 ","title":"搭建docker registry 镜像仓库"},{"content":"rsync 文件同步 rsync 是一个常用的 Linux 应用程序，用于文件同步\n安装 # Debian or Ubuntu $ sudo apt-get install rsync # Red Hat $ sudo yum install rsync # Arch Linux $ sudo pacman -S rsync 基本用法 使用 rsync 命令时，可以作为 cp 和 mv 命令的替代方法，将源目录同步到目标目录。\n-r 表示递归，即包含子目录。注意，-r 是必须的，否则 rsync 运行不会成功。source 目录表示源目录，destination 表示目标目录。\n-a 参数可以替代-r，除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）。由于 rsync 默认使用文件大小和修改时间决定文件是否需要更新\nrsync -r source destination 远程同步\nrsync -av \u0026amp;lt;源地址\u0026amp;gt;/ \u0026amp;lt;用户名\u0026amp;gt;@\u0026amp;lt;ip地址\u0026amp;gt;:/\u0026amp;lt;目标地址\u0026amp;gt; 友情地址：mysql 迁移 ","permalink":"https://test.jobcher.com/rsync-%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5.html","summary":"rsync 文件同步 rsync 是一个常用的 Linux 应用程序，用于文件同步\n安装 # Debian or Ubuntu $ sudo apt-get install rsync # Red Hat $ sudo yum install rsync # Arch Linux $ sudo pacman -S rsync 基本用法 使用 rsync 命令时，可以作为 cp 和 mv 命令的替代方法，将源目录同步到目标目录。\n-r 表示递归，即包含子目录。注意，-r 是必须的，否则 rsync 运行不会成功。source 目录表示源目录，destination 表示目标目录。\n-a 参数可以替代-r，除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）。由于 rsync 默认使用文件大小和修改时间决定文件是否需要更新\nrsync -r source destination 远程同步\nrsync -av \u0026lt;源地址\u0026gt;/ \u0026lt;用户名\u0026gt;@\u0026lt;ip地址\u0026gt;:/\u0026lt;目标地址\u0026gt; 友情地址：mysql 迁移 ","title":"rsync 文件同步"},{"content":"helm 安装 脚本安装 curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 chmod 700 get_helm.sh ./get_helm.sh #或者可以使用这个命令 curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash helm help 二进制安装 wget https://get.helm.sh/helm-v3.7.2-linux-amd64.tar.gz tar -zxvf helm-v3.7.2-linux-amd64.tar.gz cd helm-v3.7.2-linux-amd64 mv linux-amd64/helm /usr/local/bin/helm helm help ","permalink":"https://test.jobcher.com/helm-%E5%AE%89%E8%A3%85.html","summary":"helm 安装 脚本安装 curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 chmod 700 get_helm.sh ./get_helm.sh #或者可以使用这个命令 curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash helm help 二进制安装 wget https://get.helm.sh/helm-v3.7.2-linux-amd64.tar.gz tar -zxvf helm-v3.7.2-linux-amd64.tar.gz cd helm-v3.7.2-linux-amd64 mv linux-amd64/helm /usr/local/bin/helm helm help ","title":"helm 安装"},{"content":"k8s 部署 loki 日志 helm 拉取 loki #加源 helm repo add grafana https://grafana.github.io/helm-charts helm repo update #拉取 helm fetch grafana/loki-stack --untar --untardir . cd loki-stack # 生成 k8s 配置 helm template loki . \u0026amp;gt; loki.yaml # 部署（如果要修改默认配置必须要修改一下yaml） k3s kubectl apply -f loki.yaml ","permalink":"https://test.jobcher.com/k8s-%E9%83%A8%E7%BD%B2loki%E6%97%A5%E5%BF%97.html","summary":"k8s 部署 loki 日志 helm 拉取 loki #加源 helm repo add grafana https://grafana.github.io/helm-charts helm repo update #拉取 helm fetch grafana/loki-stack --untar --untardir . cd loki-stack # 生成 k8s 配置 helm template loki . \u0026gt; loki.yaml # 部署（如果要修改默认配置必须要修改一下yaml） k3s kubectl apply -f loki.yaml ","title":"k8s 部署loki日志"},{"content":"自动判断跳转不同网站 根据用户目前的浏览器配置语言进行显示 供语言切换按钮，用户自定义选择不同的语言显示 根据识别用户的浏览器语言，自动判断并跳转到相应的语言网页，让你的网站更加灵动。\n以下需要将代码放在 HTML 的内即可，然后自行制作多语言页面。\n代码如下：\n\u0026amp;lt;script type=\u0026amp;#34;text/javascript\u0026amp;#34;\u0026amp;gt; //获取用户语言的顺序是 //1.获取本地缓存里的内容 //2.用户浏览器的语言设置 //如果上面2个都没有获取到，就直接使用\u0026amp;#39;en\u0026amp;#39;作为用户选择的语言 var language = localStorage.getItem(\u0026amp;#34;locale\u0026amp;#34;) || window.navigator.language.toLowerCase() || \u0026amp;#34;en\u0026amp;#34;; //把用户的语言写入缓存，供下次获取使用 localStorage.setItem(\u0026amp;#34;locale\u0026amp;#34;, language); //判断用户的语言，跳转到不同的地方 if (language.indexOf(\u0026amp;#34;zh-\u0026amp;#34;) !== -1) { window.location = \u0026amp;#34;/zh-cn/index.html\u0026amp;#34;; } else if (language.indexOf(\u0026amp;#34;en\u0026amp;#34;) !== -1) { window.location = \u0026amp;#34;/en/index.html\u0026amp;#34;; } else { //其它的都使用英文 window.location = \u0026amp;#34;/en/index.html\u0026amp;#34;; } \u0026amp;lt;/script\u0026amp;gt; 核心代码\n其实核心代码就是利用 navigator 的 language 属性\nnavigator.language 第二种解决方案 可以通过获取用户的 IP，然后把 IP 放到 IP 库里查询所在地，从而加载对应的资源，这样的方案回更加准确！有的第三方会直接返回所在国家的编码，比如 cn / en 等就更好了\n但是这样的方案也有一个弊端：如果用户通过科学上网，全局模式下，会被认为属于美国 / 日本等等（看梯子的 IP 而定了），那么会导致访问非常慢；但是这种偏差，很多翻墙的人都是了解的，没人会故意用美国的 IP 访问国内的淘宝 / 百度等网站的，除非是忘记切换回来","permalink":"https://test.jobcher.com/%E8%8E%B7%E5%8F%96%E7%94%A8%E6%88%B7%E6%B5%8F%E8%A7%88%E5%99%A8%E9%BB%98%E8%AE%A4%E8%AF%AD%E8%A8%80%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%8A%A8%E5%88%A4%E6%96%AD%E8%B7%B3%E8%BD%AC%E4%B8%8D%E5%90%8C%E7%BD%91%E7%AB%99.html","summary":"自动判断跳转不同网站 根据用户目前的浏览器配置语言进行显示 供语言切换按钮，用户自定义选择不同的语言显示 根据识别用户的浏览器语言，自动判断并跳转到相应的语言网页，让你的网站更加灵动。\n以下需要将代码放在 HTML 的内即可，然后自行制作多语言页面。\n代码如下：\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; //获取用户语言的顺序是 //1.获取本地缓存里的内容 //2.用户浏览器的语言设置 //如果上面2个都没有获取到，就直接使用\u0026#39;en\u0026#39;作为用户选择的语言 var language = localStorage.getItem(\u0026#34;locale\u0026#34;) || window.navigator.language.toLowerCase() || \u0026#34;en\u0026#34;; //把用户的语言写入缓存，供下次获取使用 localStorage.setItem(\u0026#34;locale\u0026#34;, language); //判断用户的语言，跳转到不同的地方 if (language.indexOf(\u0026#34;zh-\u0026#34;) !== -1) { window.location = \u0026#34;/zh-cn/index.html\u0026#34;; } else if (language.indexOf(\u0026#34;en\u0026#34;) !== -1) { window.location = \u0026#34;/en/index.html\u0026#34;; } else { //其它的都使用英文 window.location = \u0026#34;/en/index.html\u0026#34;; } \u0026lt;/script\u0026gt; 核心代码\n其实核心代码就是利用 navigator 的 language 属性\nnavigator.language 第二种解决方案 可以通过获取用户的 IP，然后把 IP 放到 IP 库里查询所在地，从而加载对应的资源，这样的方案回更加准确！有的第三方会直接返回所在国家的编码，比如 cn / en 等就更好了","title":"获取用户浏览器默认语言设置，自动判断跳转不同网站"},{"content":"linux 服务基础知识 1、哪些设置能够提升 SSH 远程管理的安全等级 2、ssh 连接时认证时间过长如何解决？ 3、scp 和 rsync 进行远程文件复制有什么区别？ 4、请描述通过 DHCP 服务器获取 IP 地址的过程。 5、简单描述 FTP 的主动模式和被动模式的区别？ 6、集群环境中，如何保证所有服务器之间的时间误差较小。 7、请描述用户访问网站时 DNS 的解析过程。 8、解释权威 DNS 和递归 DNS 的含义，并描述智能 DNS 的实现原理。 9、公司里有一台服务器，需要在上面跑两个网站，并且其中一个网站需要更换新域名，请问如何处理？ 网站1：www.a.com 网站2：www.b.com（旧） www.d.com（新） 10、简述 Apache 的三种工作模式？ 11、请写出工作中常见的 Apache 优化策略。 12、有哪些技术可以提高网站的安全和效率？ 13、Apache 和 Nginx 各有什么优缺点，应该如何选择？ 14、为什么 Nginx 的并发能力强，资源消耗低？ 15、写出几个 Nginx 的常用模块，并描述其功能。 16、请解释 Nginx 是如何连接 PHP 进行页面解析的？ 17、请描述 Nginx 和 Tomcat 之间的数据传输过程？ 18、请写出几个常见的 HTTP 状态码，并解释出现原因。 ","permalink":"https://test.jobcher.com/linux%E6%9C%8D%E5%8A%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html","summary":"linux 服务基础知识 1、哪些设置能够提升 SSH 远程管理的安全等级 2、ssh 连接时认证时间过长如何解决？ 3、scp 和 rsync 进行远程文件复制有什么区别？ 4、请描述通过 DHCP 服务器获取 IP 地址的过程。 5、简单描述 FTP 的主动模式和被动模式的区别？ 6、集群环境中，如何保证所有服务器之间的时间误差较小。 7、请描述用户访问网站时 DNS 的解析过程。 8、解释权威 DNS 和递归 DNS 的含义，并描述智能 DNS 的实现原理。 9、公司里有一台服务器，需要在上面跑两个网站，并且其中一个网站需要更换新域名，请问如何处理？ 网站1：www.a.com 网站2：www.b.com（旧） www.d.com（新） 10、简述 Apache 的三种工作模式？ 11、请写出工作中常见的 Apache 优化策略。 12、有哪些技术可以提高网站的安全和效率？ 13、Apache 和 Nginx 各有什么优缺点，应该如何选择？ 14、为什么 Nginx 的并发能力强，资源消耗低？ 15、写出几个 Nginx 的常用模块，并描述其功能。 16、请解释 Nginx 是如何连接 PHP 进行页面解析的？ 17、请描述 Nginx 和 Tomcat 之间的数据传输过程？ 18、请写出几个常见的 HTTP 状态码，并解释出现原因。 ","title":"linux服务基础知识"},{"content":"mysql 基础知识 1、库表 student.report,有 3 个字段，姓名、学科、成绩，记录如下，根据要求完成 SQL 语句： Name Subject Result 李白 Math 95 张三 English 83 王五 Math 79 李六 Math 85 张二 English 74 查询姓李的同学的个数。 查询表中数学成绩大于 80 的前 2 名同学的名字，并按分数从大到小的顺序排列。 2、MYSQL 集群一主多从，主库宕机，如何合理切换到从库，其它从库如何处理？ 3、单台 MySQL 达到性能瓶颈时，如何击碎性能瓶颈？ 4、MySQL 什么时候创建索引？ 5、误操作 drop 语句导致数据库数据破坏，请给出恢复的实际大体步骤。 6、如何保证 Redis 能永久保存数据？ 7、如何利用 Redis 对 MySQL 进行性能优化？ ","permalink":"https://test.jobcher.com/mysql%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html","summary":"mysql 基础知识 1、库表 student.report,有 3 个字段，姓名、学科、成绩，记录如下，根据要求完成 SQL 语句： Name Subject Result 李白 Math 95 张三 English 83 王五 Math 79 李六 Math 85 张二 English 74 查询姓李的同学的个数。 查询表中数学成绩大于 80 的前 2 名同学的名字，并按分数从大到小的顺序排列。 2、MYSQL 集群一主多从，主库宕机，如何合理切换到从库，其它从库如何处理？ 3、单台 MySQL 达到性能瓶颈时，如何击碎性能瓶颈？ 4、MySQL 什么时候创建索引？ 5、误操作 drop 语句导致数据库数据破坏，请给出恢复的实际大体步骤。 6、如何保证 Redis 能永久保存数据？ 7、如何利用 Redis 对 MySQL 进行性能优化？ ","title":"mysql基础知识"},{"content":"shell 基础知识 1、有一个 b.txt 文本(内容如下)，要求将所有域名截取出来，并统计重复域名出现的次数： http://www.baidu.com/index.html\nhttps://www.atguigu.com/index.html\nhttp://www.sina.com.cn/1024.html\nhttps://www.atguigu.com/2048.html\nhttp://www.sina.com.cn/4096.html\nhttps://www.atguigu.com/8192.html\n2、统计当前服务器正在连接的 IP 地址，并按连接次数排序 3、使用循环在/atguigu 目录下创建 10 个 txt 文件，要求文件名称由 6 位随机小写字母加固定字符串（_gg）组成，例如：pzjebg_gg.txt。 4、生成随机数字。 5、批量检查多个网站是否可以正常访问，要求使用 shell 数组实现，检测策略尽量模拟用户真实访问模式。 http://www.atguigu.com\nhttp://www.gulixueyuan.com\nhttp://www.baidu.com\n","permalink":"https://test.jobcher.com/shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html","summary":"shell 基础知识 1、有一个 b.txt 文本(内容如下)，要求将所有域名截取出来，并统计重复域名出现的次数： http://www.baidu.com/index.html\nhttps://www.atguigu.com/index.html\nhttp://www.sina.com.cn/1024.html\nhttps://www.atguigu.com/2048.html\nhttp://www.sina.com.cn/4096.html\nhttps://www.atguigu.com/8192.html\n2、统计当前服务器正在连接的 IP 地址，并按连接次数排序 3、使用循环在/atguigu 目录下创建 10 个 txt 文件，要求文件名称由 6 位随机小写字母加固定字符串（_gg）组成，例如：pzjebg_gg.txt。 4、生成随机数字。 5、批量检查多个网站是否可以正常访问，要求使用 shell 数组实现，检测策略尽量模拟用户真实访问模式。 http://www.atguigu.com\nhttp://www.gulixueyuan.com\nhttp://www.baidu.com","title":"shell基础知识"},{"content":"Kubernetes 创建 nfs 存储类 首先你需要在别的终端上创建 nfs 服务并能提供 nfs 访问\nKubernetes 不包含内部 NFS 驱动。你需要使用外部驱动为 NFS 创建 StorageClass。\nhttps://github.com/kubernetes-sigs/nfs-subdir-external-provisioner\n安装 nfs 驱动\n安装 nfs 驱动 #安装nfs客户端 apt-get install nfs-common git clone https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner.git cd nfs-subdir-external-provisioner/deploy k3s kubectl create -f rbac.yaml vim deployment.yaml 编辑 deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nfs-client-provisioner labels: app: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default spec: replicas: 1 strategy: type: Recreate selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2 volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME","permalink":"https://test.jobcher.com/kubernetes-%E5%88%9B%E5%BB%BAnfs%E5%AD%98%E5%82%A8%E7%B1%BB.html","summary":"Kubernetes 创建 nfs 存储类 首先你需要在别的终端上创建 nfs 服务并能提供 nfs 访问\nKubernetes 不包含内部 NFS 驱动。你需要使用外部驱动为 NFS 创建 StorageClass。\nhttps://github.com/kubernetes-sigs/nfs-subdir-external-provisioner\n安装 nfs 驱动\n安装 nfs 驱动 #安装nfs客户端 apt-get install nfs-common git clone https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner.git cd nfs-subdir-external-provisioner/deploy k3s kubectl create -f rbac.yaml vim deployment.yaml 编辑 deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nfs-client-provisioner labels: app: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default spec: replicas: 1 strategy: type: Recreate selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: k8s.","title":"Kubernetes 创建nfs存储类"},{"content":"nginx 日志配置 语法 access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; # 设置访问日志 access_log off; # 关闭访问日志 例子：\naccess_log /var/logs/nginx-access.log access_log /var/logs/nginx-access.log buffer=32k gzip flush=1m 使用 log_format 自定义日志格式 Nginx 预定义了名为 combined 日志格式，如果没有明确指定日志格式默认使用该格式：\nlog_format combined \u0026amp;#39;$remote_addr - $remote_user [$time_local] \u0026amp;#39; \u0026amp;#39;\u0026amp;#34;$request\u0026amp;#34; $status $body_bytes_sent \u0026amp;#39; \u0026amp;#39;\u0026amp;#34;$http_referer\u0026amp;#34; \u0026amp;#34;$http_user_agent\u0026amp;#34;\u0026amp;#39;; 如果不想使用 Nginx 预定义的格式，可以通过 log_format 指令来自定义。\n语法 log_format name [escape=default|json] string ...; 变量 含义 $bytes_sent 发送给客户端的总字节数 $body_bytes_sent 发送给客户端的字节数，不包括响应头的大小 $connection 连接序列号 $connection_requests 当前通过连接发出的请求数量 $msec 日志写入时间，单位为秒，精度是毫秒 $pipe 如果请求是通过 http 流水线发送，则其值为\u0026amp;quot;p\u0026amp;quot;，否则为“.\u0026amp;quot; $request_length 请求长度（包括请求行，请求头和请求体） $request_time 请求处理时长，单位为秒，精度为毫秒，从读入客户端的第一个字节开始，直到把最后一个字符发送张客户端进行日志写入为止 $status 响应状态码 $time_iso8601 标准格式的本地时间,形如“2017-05-24T18:31:27+08:00” $time_local 通用日志格式下的本地时间，如\u0026amp;quot;24/May/2017:18:31:27","permalink":"https://test.jobcher.com/nginx-%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F%E6%95%B4%E7%90%86.html","summary":"nginx 日志配置 语法 access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; # 设置访问日志 access_log off; # 关闭访问日志 例子：\naccess_log /var/logs/nginx-access.log access_log /var/logs/nginx-access.log buffer=32k gzip flush=1m 使用 log_format 自定义日志格式 Nginx 预定义了名为 combined 日志格式，如果没有明确指定日志格式默认使用该格式：\nlog_format combined \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#39; \u0026#39;\u0026#34;$request\u0026#34; $status $body_bytes_sent \u0026#39; \u0026#39;\u0026#34;$http_referer\u0026#34; \u0026#34;$http_user_agent\u0026#34;\u0026#39;; 如果不想使用 Nginx 预定义的格式，可以通过 log_format 指令来自定义。\n语法 log_format name [escape=default|json] string ...; 变量 含义 $bytes_sent 发送给客户端的总字节数 $body_bytes_sent 发送给客户端的字节数，不包括响应头的大小 $connection 连接序列号 $connection_requests 当前通过连接发出的请求数量 $msec 日志写入时间，单位为秒，精度是毫秒 $pipe 如果请求是通过 http 流水线发送，则其值为\u0026quot;p\u0026quot;，否则为“.","title":"nginx 日志格式整理"},{"content":"linux 系统开启 root 权限 修改 ssh 服务配置文件 sudo su - sudo vim /etc/ssh/sshd_config 增加权限\n在# Authentication: 下输入 PermitRootLogin yes 更改 root 密码，重启服务 sudo passwd root service sshd restart ","permalink":"https://test.jobcher.com/linux%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%90%AFroot%E6%9D%83%E9%99%90.html","summary":"linux 系统开启 root 权限 修改 ssh 服务配置文件 sudo su - sudo vim /etc/ssh/sshd_config 增加权限\n在# Authentication: 下输入 PermitRootLogin yes 更改 root 密码，重启服务 sudo passwd root service sshd restart ","title":"linux系统开启root权限"},{"content":"mysql 学习笔记（1） 本文章不涉及到关于 mysql 开放上的问题，主要记录关于 mysql 出现的问题，以及如何去维护 mysql 数据的日常。\nmysql 各类信息的收集 收集变量信息 show global variables; 收集进程信息 show PROCESSLIST; 收集错误日志 show global variables like \u0026amp;#39;log_error\u0026amp;#39;; 收集慢日志信息 show global variables like \u0026amp;#39;slow_querry_log_file\u0026amp;#39;; 收集锁信息，高峰时期运行三次，每次间隔 10s SELECT locked_table, locked_index, locked_type, blocking_pid, T2.USER blocking_user, T2.HOST blocking_host, blocking_lock_mode, blocking_trx_rows_modified, waiting_pid, T3.USER waiting_user, T3.HOST waiting_host, waiting_lock_mode, waiting_trx_row_modified, wait_age_secs, waiting_query FROM sys.x$innodb_lock_waits T1 LEFT JOIN INFROMATION_SCHEMA.processlist T2 ON T1.blocking_pid=T2.ID LEFT JOIN INFROMATION_SCHEMA.processlist T3 ON T3.ID=T1.waiting_pid; 收集 mysql 状态信息 show global status; show engine innodb status; show engine innodb mutex; mysql 基础语法 连接数据库 mysql -u \u0026amp;lt;用户名\u0026amp;gt; -p 创建数据库 CREATE DATABASE \u0026amp;lt;数据库名称\u0026amp;gt;; 删除数据库 drop database \u0026amp;lt;数据库名称\u0026amp;gt;; 选择数据库 use \u0026amp;lt;数据库名称\u0026amp;gt;; 创建表 CREATE table \u0026amp;lt;数据表名\u0026amp;gt; ( \u0026amp;lt;字段名1\u0026amp;gt; \u0026amp;lt;数","permalink":"https://test.jobcher.com/mysql-%E7%AC%94%E8%AE%B01.html","summary":"mysql 学习笔记（1） 本文章不涉及到关于 mysql 开放上的问题，主要记录关于 mysql 出现的问题，以及如何去维护 mysql 数据的日常。\nmysql 各类信息的收集 收集变量信息 show global variables; 收集进程信息 show PROCESSLIST; 收集错误日志 show global variables like \u0026#39;log_error\u0026#39;; 收集慢日志信息 show global variables like \u0026#39;slow_querry_log_file\u0026#39;; 收集锁信息，高峰时期运行三次，每次间隔 10s SELECT locked_table, locked_index, locked_type, blocking_pid, T2.USER blocking_user, T2.HOST blocking_host, blocking_lock_mode, blocking_trx_rows_modified, waiting_pid, T3.USER waiting_user, T3.HOST waiting_host, waiting_lock_mode, waiting_trx_row_modified, wait_age_secs, waiting_query FROM sys.x$innodb_lock_waits T1 LEFT JOIN INFROMATION_SCHEMA.processlist T2 ON T1.blocking_pid=T2.ID LEFT JOIN INFROMATION_SCHEMA.processlist T3 ON T3.ID=T1.waiting_pid; 收集 mysql 状态信息 show global status; show engine innodb status; show engine innodb mutex; mysql 基础语法 连接数据库 mysql -u \u0026lt;用户名\u0026gt; -p 创建数据库 CREATE DATABASE \u0026lt;数据库名称\u0026gt;; 删除数据库 drop database \u0026lt;数据库名称\u0026gt;; 选择数据库 use \u0026lt;数据库名称\u0026gt;; 创建表 CREATE table \u0026lt;数据表名\u0026gt; ( \u0026lt;字段名1\u0026gt; \u0026lt;数","title":"mysql 笔记（1）"},{"content":"163 企业邮箱设置教程 请进入这个网站 https://qiye.163.com/help/l-11.html\n","permalink":"https://test.jobcher.com/163%E4%BC%81%E4%B8%9A%E9%82%AE%E7%AE%B1%E8%AE%BE%E7%BD%AE%E6%95%99%E7%A8%8B.html","summary":"163 企业邮箱设置教程 请进入这个网站 https://qiye.163.com/help/l-11.html","title":"163企业邮箱设置教程"},{"content":"git 技巧 Git 是一个 “分布式版本管理工具”，简单的理解版本管理工具：大家在写东西的时候都用过 “回撤” 这个功能，但是回撤只能回撤几步，假如想要找回我三天之前的修改，光用 “回撤” 是找不回来的。而 “版本管理工具” 能记录每次的修改，只要提交到版本仓库，你就可以找到之前任何时刻的状态（文本状态）。\n下面的内容就是列举了常用的 Git 命令和一些小技巧，可以通过 \u0026amp;ldquo;页面内查找\u0026amp;rdquo; 的方式进行快速查询：Ctrl/Command+f。\n开卷必读 如果之前未使用过 Git，可以学习 Git 小白教程入门\n一定要先测试命令的效果后，再用于工作环境中，以防造成不能弥补的后果！到时候别拿着砍刀来找我 所有的命令都在git version 2.7.4 (Apple Git-66)下测试通过 统一概念： 工作区：改动（增删文件和内容） 暂存区：输入命令：git add 改动的文件名，此次改动就放到了 ‘暂存区’ 本地仓库(简称：本地)：输入命令：git commit 此次修改的描述，此次改动就放到了 ’本地仓库’，每个 commit，我叫它为一个 ‘版本’。 远程仓库(简称：远程)：输入命令：git push 远程仓库，此次改动就放到了 ‘远程仓库’（GitHub 等) commit-id：输出命令：git log，最上面那行 commit xxxxxx，后面的字符串就是 commit-id 如果喜欢这个项目，欢迎 Star、提交 Pr、反馈问题😊 目录 脑图 展示帮助信息 回到远程仓库的状态 重设第一个 commit 查看冲突文件列表 展示工作区和暂存区的不同 展示暂存区和最近版本的不同 展示暂存区、工作区和最近版本的不同 快速切换到上一个分支 删除已经合并到 master 的分支 展示本地分支关联远程仓库的情况 关联远程分支 列出所有远程分支 列出本地和远程分支 查看远程分支和本地分支的对应关系 远程删除了分支本地也想删除 创建并切换到本地分支 从远程分支中创建并切换到本地分支 删除本地分支 删除远程分支 重命名本地分支 查看标签 查看标签详细信息 本地创建标签 推送标签到远程仓库 删除本地标签 删除远程标签 切回到某个标签 放弃工作区的修改 恢复删除的文件 以新增一个 commit 的方式还原某一个 commit 的修改 回到某个 commit 的状态，并删除后面的 commit","permalink":"https://test.jobcher.com/git%E6%8A%80%E5%B7%A7.html","summary":"git 技巧 Git 是一个 “分布式版本管理工具”，简单的理解版本管理工具：大家在写东西的时候都用过 “回撤” 这个功能，但是回撤只能回撤几步，假如想要找回我三天之前的修改，光用 “回撤” 是找不回来的。而 “版本管理工具” 能记录每次的修改，只要提交到版本仓库，你就可以找到之前任何时刻的状态（文本状态）。\n下面的内容就是列举了常用的 Git 命令和一些小技巧，可以通过 \u0026ldquo;页面内查找\u0026rdquo; 的方式进行快速查询：Ctrl/Command+f。\n开卷必读 如果之前未使用过 Git，可以学习 Git 小白教程入门\n一定要先测试命令的效果后，再用于工作环境中，以防造成不能弥补的后果！到时候别拿着砍刀来找我 所有的命令都在git version 2.7.4 (Apple Git-66)下测试通过 统一概念： 工作区：改动（增删文件和内容） 暂存区：输入命令：git add 改动的文件名，此次改动就放到了 ‘暂存区’ 本地仓库(简称：本地)：输入命令：git commit 此次修改的描述，此次改动就放到了 ’本地仓库’，每个 commit，我叫它为一个 ‘版本’。 远程仓库(简称：远程)：输入命令：git push 远程仓库，此次改动就放到了 ‘远程仓库’（GitHub 等) commit-id：输出命令：git log，最上面那行 commit xxxxxx，后面的字符串就是 commit-id 如果喜欢这个项目，欢迎 Star、提交 Pr、反馈问题😊 目录 脑图 展示帮助信息 回到远程仓库的状态 重设第一个 commit 查看冲突文件列表 展示工作区和暂存区的不同 展示暂存区和最近版本的不同 展示暂存区、工作区和最近版本的不同 快速切换到上一个分支 删除已经合并到 master 的分支 展示本地分支关联远程仓库的情况 关联远程分支 列出所有远程分支 列出本地和远程分支 查看远程分支和本地分支的对应关系 远程删除了分支本地也想删除 创建并切换到本地分支 从远程分支中创建并切换到本地分支 删除本地分支 删除远程分支 重命名本地分支 查看标签 查看标签详细信息 本地创建标签 推送标签到远程仓库 删除本地标签 删除远程标签 切回到某个标签 放弃工作区的修改 恢复删除的文件 以新增一个 commit 的方式还原某一个 commit 的修改 回到某个 commit 的状态，并删除后面的 commit","title":"git技巧"},{"content":"docker image 镜像上传 登入 docker hub，在https://hub.docker.com上注册你的账号。\ndocker login username：#输入你的用户名 password：#输入你的密码 上传镜像 docker tag nginx:hugo sjtfreaks/hogo-nginx:v1 docker push sjtfreaks/hogo-nginx:v1 ","permalink":"https://test.jobcher.com/docker-image%E9%95%9C%E5%83%8F%E4%B8%8A%E4%BC%A0.html","summary":"docker image 镜像上传 登入 docker hub，在https://hub.docker.com上注册你的账号。\ndocker login username：#输入你的用户名 password：#输入你的密码 上传镜像 docker tag nginx:hugo sjtfreaks/hogo-nginx:v1 docker push sjtfreaks/hogo-nginx:v1 ","title":"docker image镜像上传"},{"content":"docker 进阶使用 dockerfile 和 docker compose 的配置\nDockerfile 使用 Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。\n例子：\nFROM nginx RUN echo \u0026amp;#39;这是一个本地构建的nginx镜像\u0026amp;#39; \u0026amp;gt; /usr/share/nginx/html/index.html 保存 Dockerfile 文件并在本地路径执行\ndocker build -t nginx:v1-test . docker run -name docker run --name nginx-test -d -p 8080:80 nginx:v1-test 浏览 nginx 页面确认更新内容\ncurl 127.0.0.1:8080 输出： 这是一个本地构建的nginx镜像 Docker 命令详解 COPY 复制指令，从上下文目录中复制文件或者目录到容器里指定路径。\nCOPY [--chown=\u0026amp;lt;user\u0026amp;gt;:\u0026amp;lt;group\u0026amp;gt;] \u0026amp;lt;源路径1\u0026amp;gt;... \u0026amp;lt;目标路径\u0026amp;gt; COPY [--chown=\u0026amp;lt;user\u0026amp;gt;:\u0026amp;lt;group\u0026amp;gt;] [\u0026amp;#34;\u0026amp;lt;源路径1\u0026amp;gt;\u0026amp;#34;,... \u0026amp;#34;\u0026amp;lt;目标路径\u0026amp;gt;\u0026amp;#34;] \u0026amp;lt;源路径\u0026amp;gt;：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如：\nCOPY hom* /mydir/ COPY hom?.txt /mydir/ FROM FROM：定制的镜像都是基于 FROM 的镜像\nFROM nginx RUN RUN：用于执行后面跟着的命令行命令\nshell：\nRUN \u0026amp;lt;命令行命令\u0026amp;gt; # \u0026amp;lt;命令行命令\u0026amp;gt; 等同于，在终端操作的 shell 命令。 exec：\nRUN [\u0026amp;#34;可执行文件\u0026amp;#34;, \u0026amp;#34;参数1\u0026amp;#34;, \u0026amp;#34;参数2\u0026amp;#34;] # 例如： # RUN [\u0026amp;#34;./test.php\u0026amp;#34;, \u0026amp;#34;dev\u0026amp;#34;, \u0026amp;#34;offline\u0026amp;#34;] 等价于 RUN ./test.php dev offline ADD ADD 指令和 COPY 的使用格类似\nADD 的优点：","permalink":"https://test.jobcher.com/docker%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8.html","summary":"docker 进阶使用 dockerfile 和 docker compose 的配置\nDockerfile 使用 Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。\n例子：\nFROM nginx RUN echo \u0026#39;这是一个本地构建的nginx镜像\u0026#39; \u0026gt; /usr/share/nginx/html/index.html 保存 Dockerfile 文件并在本地路径执行\ndocker build -t nginx:v1-test . docker run -name docker run --name nginx-test -d -p 8080:80 nginx:v1-test 浏览 nginx 页面确认更新内容\ncurl 127.0.0.1:8080 输出： 这是一个本地构建的nginx镜像 Docker 命令详解 COPY 复制指令，从上下文目录中复制文件或者目录到容器里指定路径。\nCOPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] \u0026lt;源路径1\u0026gt;... \u0026lt;目标路径\u0026gt; COPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] [\u0026#34;\u0026lt;源路径1\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;目标路径\u0026gt;\u0026#34;] \u0026lt;源路径\u0026gt;：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如：\nCOPY hom* /mydir/ COPY hom?.txt /mydir/ FROM FROM：定制的镜像都是基于 FROM 的镜像","title":"docker进阶使用"},{"content":"Kubernetes k8s 组件 控制平面组件（Control Plane Components） 控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。\nkube-apiserver API 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。 API 服务器是 Kubernetes 控制面的前端。\netcd etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。\nkube-scheduler 控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。\nkube-controller-manager 运行控制器进程的控制平面组件。\ncloud-controller-manager 云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。 云控制器管理器使得你可以将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。\nNode 组件 节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。\nkubelet 一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都 运行在 Pod 中。\nkube-proxy kube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。\n容器运行时（Container Runtime） 容器运行环境是负责运行容器的软件。\nKubernetes 支持多个容器运行环境: Docker、 containerd、CRI-O 以及任何实现 Kubernetes CRI (容器运行环境接口)。\n","permalink":"https://test.jobcher.com/kubernetes-k8s-%E7%BB%84%E4%BB%B6.html","summary":"Kubernetes k8s 组件 控制平面组件（Control Plane Components） 控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。\nkube-apiserver API 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。 API 服务器是 Kubernetes 控制面的前端。\netcd etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。\nkube-scheduler 控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。\nkube-controller-manager 运行控制器进程的控制平面组件。\ncloud-controller-manager 云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。 云控制器管理器使得你可以将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。\nNode 组件 节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。\nkubelet 一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都 运行在 Pod 中。\nkube-proxy kube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。\n容器运行时（Container Runtime） 容器运行环境是负责运行容器的软件。\nKubernetes 支持多个容器运行环境: Docker、 containerd、CRI-O 以及任何实现 Kubernetes CRI (容器运行环境接口)。","title":"Kubernetes k8s 组件"},{"content":"2021 年第 50 周周记 这周完成了以下任务\n搭建 hugo 博客 使用 docker 封装了 blog 搭建 k3s 环境 计划：\n学习 k8s 总结：没啥好总结，刚开始写周记，就随便写一点吧\n欢迎关注我的博客www.jobcher.com\n","permalink":"https://test.jobcher.com/2021%E5%B9%B4%E7%AC%AC50%E5%91%A8%E8%AE%B0.html","summary":"2021 年第 50 周周记 这周完成了以下任务\n搭建 hugo 博客 使用 docker 封装了 blog 搭建 k3s 环境 计划：\n学习 k8s 总结：没啥好总结，刚开始写周记，就随便写一点吧\n欢迎关注我的博客www.jobcher.com","title":"2021年第50周记"},{"content":"nginx 汇总 各类 nginx 问题汇总\n安装 nginx #centos yum install nginx #ubuntu apt install nginx http 代理 正向代理 server { listen 80; server_name www.nbtyfood.com; location / { proxy_pass http://127.0.0.1:8080; } } 反向代理 负载均衡 upstream mysvr { server 192.168.10.121:3333; server 192.168.10.122:3333; } server { .... location ~*^.+$ { proxy_pass http://mysvr; #请求转向mysvr 定义的服务器列表 } } 热备\n如果你有 2 台服务器，当一台服务器发生事故时，才启用第二台服务器给提供服务。服务器处理请求的顺序：AAAAAA 突然 A 挂啦，BBBBBBBBBBBBBB\u0026amp;hellip;.. upstream mysvr { server 127.0.0.1:7878; server 192.168.10.121:3333 backup; #热备 } 轮询\nnginx 默认就是轮询其权重都默认为 1，服务器处理请求的顺序：ABABABABAB\u0026amp;hellip;. upstream mysvr { server 127.0.0.1:7878; server 192.168.10.121:3333; } 加权轮询\n跟据配置的权重的大小而分发给不同服务器不同数量的请求。如果不设置，则默认为 1。下面服务器的请求顺序为：ABBABBABBABBABB\u0026amp;hellip;. upstream mysvr { server 127.0.0.1:7878 weight=1;w server 192.168.10.121:3333 weight=2; } ip_hash nginx 会让相同的客户端 ip 请求相同的服务器。 upstream mysvr { server 127.0.0.1:7878; server 192.168.10.121:3333; ip_hash; } web 缓存 location /images/ { proxy_cache my_cache; proxy_ignore_headers","permalink":"https://test.jobcher.com/nginx-%E6%B1%87%E6%80%BB.html","summary":"nginx 汇总 各类 nginx 问题汇总\n安装 nginx #centos yum install nginx #ubuntu apt install nginx http 代理 正向代理 server { listen 80; server_name www.nbtyfood.com; location / { proxy_pass http://127.0.0.1:8080; } } 反向代理 负载均衡 upstream mysvr { server 192.168.10.121:3333; server 192.168.10.122:3333; } server { .... location ~*^.+$ { proxy_pass http://mysvr; #请求转向mysvr 定义的服务器列表 } } 热备\n如果你有 2 台服务器，当一台服务器发生事故时，才启用第二台服务器给提供服务。服务器处理请求的顺序：AAAAAA 突然 A 挂啦，BBBBBBBBBBBBBB\u0026hellip;.. upstream mysvr { server 127.0.0.1:7878; server 192.168.10.121:3333 backup; #热备 } 轮询","title":"nginx 汇总"},{"content":"TCP/IP 协议 什么是 TCP/IP 协议 OSI 七层架构 TCP/IP 四层模型 协议 应用层 HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS 表示层 应用层 XDR、ASN.1、NCP、TLS、ASCII 会话层 sockets、SOCKS、PAP 传输层 传输层 TCP、UDP、RTP、SCTP 网络层 网络互连层 IP、ICMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP 数据链路层 网络访问（链接）层 以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11 物理层 调制解调器、无线电、光纤 报文结构 TCP 报文段首部格式\n源端口和目的端口：各占 2 个字节，分别写入源端口和目的端口。IP 地址 + 端口号就可以确定一个进程地址\n序号/序列号（Sequense Number，SN）：在一个 TCP 连接中传送的字节流中的每一个字节都按顺序编号。该字段表示本报文段所发送的数据的第一个字节的序号。初始序号称为 Init Sequense Number, ISN（序号/序列号这个字段很重要，大家留个印象，下文会详细讲解） 例如，一报文段的序号是 101，共有 100 字节的数据。这就表明：本报文段的数据的第一个字节的序号是 101，最后一个字节的序号是 200。显然，下一个报文段的数据序号应当从 201 开始，即下一个报文段的序号字段值应为 201。\n确认号 ack：期望收到对方下一个报文段的第一个数据字节的序号。若确认号为 N，则表明：到序号 N-1 为止的所有数据都已正确收到。\n数据偏移（首部长度）：它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。这个字段实际上是指出 TCP 报文段的首部长度。\n保留：占 6 位，应置为 0，保留为今后使用。\nTCP 三次握手 TCP 四次挥手 TCP/IP 其他问题 TCP 与 UDP 的区别\n（1）TCP：面向连接，可靠的，速度慢，效率低。\n（2）UDP：无连接、不可靠、速度快、效率高。 当进程需要传输可靠的数据时应使用 TCP，当进程需要高效传输数据，可以忽略可靠性时应使用 UDP 协议。\n","permalink":"https://test.jobcher.com/tcp/ip%E8%AF%A6%E8%A7%A3.html","summary":"TCP/IP 协议 什么是 TCP/IP 协议 OSI 七层架构 TCP/IP 四层模型 协议 应用层 HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS 表示层 应用层 XDR、ASN.1、NCP、TLS、ASCII 会话层 sockets、SOCKS、PAP 传输层 传输层 TCP、UDP、RTP、SCTP 网络层 网络互连层 IP、ICMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP 数据链路层 网络访问（链接）层 以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11 物理层 调制解调器、无线电、光纤 报文结构 TCP 报文段首部格式\n源端口和目的端口：各占 2 个字节，分别写入源端口和目的端口。IP 地址 + 端口号就可以确定一个进程地址\n序号/序列号（Sequense Number，SN）：在一个 TCP 连接中传送的字节流中的每一个字节都按顺序编号。该字段表示本报文段所发送的数据的第一个字节的序号。初始序号称为 Init Sequense Number, ISN（序号/序列号这个字段很重要，大家留个印象，下文会详细讲解） 例如，一报文段的序号是 101，共有 100 字节的数据。这就表明：本报文段的数据的第一个字节的序号是 101，最后一个字节的序号是 200。显然，下一个报文段的数据序号应当从 201 开始，即下一个报文段的序号字段值应为 201。\n确认号 ack：期望收到对方下一个报文段的第一个数据字节的序号。若确认号为 N，则表明：到序号 N-1 为止的所有数据都已正确收到。\n数据偏移（首部长度）：它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。这个字段实际上是指出 TCP 报文段的首部长度。\n保留：占 6 位，应置为 0，保留为今后使用。","title":"TCP/IP详解"},{"content":"内网穿透 文章中使用的内网穿透前提是必须具有公网 IP 的云服务器，不符合条件的同学可以跳过了。\nnps 内网穿透 nps 是一款轻量级、高性能、功能强大的内网穿透代理服务器。\n在公网服务器上安装 nps sever 端 wget https://github.com/ehang-io/nps/releases/download/v0.26.10/linux_amd64_server.tar.gz tar -zxvf linux_amd64_server.tar.gz sudo ./nps install sudo nps start 在控制端安装 npc client 端 wget https://github.com/ehang-io/nps/releases/download/v0.26.10/linux_amd64_client.tar.gz tar -zxvf linux_amd64_client.tar.gz sudo ./npc -server=ip:port -vkey=web界面中显示的密钥 sudo npc start npc 安装完成可以进入 web 页面穿透端口和域名\nhttp://localhost:8080\nfrps 内网穿透 frps 相对于 nps 的劣势是有断流的风险\nfrps 相对于 nps 的优势是对于高流量的媒体服务能够提供更可靠的支持\n安装 frps wget https://code.aliyun.com/MvsCode/frps-onekey/raw/master/install-frps.sh -O ./install-frps.sh chmod 700 ./install-frps.sh ./install-frps.sh install 卸载 frps 服务\n./install-frps.sh uninstall 更新 frps 服务\n./install-frps.sh update Server management（服务管理器）\nUsage: /etc/init.d/frps {start|stop|restart|status|config|version} ","permalink":"https://test.jobcher.com/%E8%87%AA%E5%BB%BA%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F.html","summary":"内网穿透 文章中使用的内网穿透前提是必须具有公网 IP 的云服务器，不符合条件的同学可以跳过了。\nnps 内网穿透 nps 是一款轻量级、高性能、功能强大的内网穿透代理服务器。\n在公网服务器上安装 nps sever 端 wget https://github.com/ehang-io/nps/releases/download/v0.26.10/linux_amd64_server.tar.gz tar -zxvf linux_amd64_server.tar.gz sudo ./nps install sudo nps start 在控制端安装 npc client 端 wget https://github.com/ehang-io/nps/releases/download/v0.26.10/linux_amd64_client.tar.gz tar -zxvf linux_amd64_client.tar.gz sudo ./npc -server=ip:port -vkey=web界面中显示的密钥 sudo npc start npc 安装完成可以进入 web 页面穿透端口和域名\nhttp://localhost:8080\nfrps 内网穿透 frps 相对于 nps 的劣势是有断流的风险\nfrps 相对于 nps 的优势是对于高流量的媒体服务能够提供更可靠的支持\n安装 frps wget https://code.aliyun.com/MvsCode/frps-onekey/raw/master/install-frps.sh -O ./install-frps.sh chmod 700 ./install-frps.sh ./install-frps.sh install 卸载 frps 服务\n./install-frps.sh uninstall 更新 frps 服务","title":"自建服务器内网穿透"},{"content":"树莓派安装 k3s 1.安装 k3s 控制节点 curl -sfL https://get.k3s.io | sh - cat /var/lib/rancher/k3s/server/node-token 工作节点 curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken sh - 树莓派特别要注意一个坑，就是关于内存的问题这个之后再讲\nk3s kubectl get nodes #显示正确的节点表示完成 卸载 k3s #server 节点 /usr/local/bin/k3s-uninstall.sh #agent 节点 /usr/local/bin/k3s-agent-uninstall.sh 2.安装 dashboard k3s 面板 部署 Kubernetes 仪表盘 GITHUB_URL=https://github.com/kubernetes/dashboard/releases VERSION_KUBE_DASHBOARD=$(curl -w \u0026amp;#39;%{url_effective}\u0026amp;#39; -I -L -s -S ${GITHUB_URL}/latest -o /dev/null | sed -e \u0026amp;#39;s|.*/||\u0026amp;#39;) sudo k3s kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/${VERSION_KUBE_DASHBOARD}/aio/deploy/recommended.yaml 仪表盘 RBAC 配置 创建以下资源清单文件：\ndashboard.admin-user.yml\napiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard dashboard.admin-user-role.yml\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup:","permalink":"https://test.jobcher.com/%E6%A0%91%E8%8E%93%E6%B4%BE%E6%90%AD%E5%BB%BAk3s.html","summary":"树莓派安装 k3s 1.安装 k3s 控制节点 curl -sfL https://get.k3s.io | sh - cat /var/lib/rancher/k3s/server/node-token 工作节点 curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken sh - 树莓派特别要注意一个坑，就是关于内存的问题这个之后再讲\nk3s kubectl get nodes #显示正确的节点表示完成 卸载 k3s #server 节点 /usr/local/bin/k3s-uninstall.sh #agent 节点 /usr/local/bin/k3s-agent-uninstall.sh 2.安装 dashboard k3s 面板 部署 Kubernetes 仪表盘 GITHUB_URL=https://github.com/kubernetes/dashboard/releases VERSION_KUBE_DASHBOARD=$(curl -w \u0026#39;%{url_effective}\u0026#39; -I -L -s -S ${GITHUB_URL}/latest -o /dev/null | sed -e \u0026#39;s|.*/||\u0026#39;) sudo k3s kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/${VERSION_KUBE_DASHBOARD}/aio/deploy/recommended.yaml 仪表盘 RBAC 配置 创建以下资源清单文件：\ndashboard.admin-user.yml\napiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard dashboard.","title":"树莓派搭建k3s"},{"content":"brew 安装配置 一.安装 1.在 ubuntu 上安装 brew /bin/bash -c \u0026amp;#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026amp;#34; 2.在 centos 上安装 brew /bin/bash -c \u0026amp;#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026amp;#34; 3.在 MacOS 上安装 brew /bin/bash -c \u0026amp;#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026amp;#34; 二、使用 1.安装 wget brew install wget Homebrew 会将软件包安装到独立目录，并将其文件软链接至 /usr/local\n$ cd /usr/local $ find Cellar Cellar/wget/1.16.1 Cellar/wget/1.16.1/bin/wget Cellar/wget/1.16.1/share/man/man1/wget.1 $ ls -l bin bin/wget -\u0026amp;gt; ../Cellar/wget/1.16.1/bin/wget 2.创建你自己的 Homebrew 包 $ brew create https://foo.com/bar-1.0.tgz Created /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core/Formula/bar.rb 3.撤销你的变更或与上游更新合并 $ brew edit wget # 使用 $EDITOR 编辑! ","permalink":"https://test.jobcher.com/brew-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE.html","summary":"brew 安装配置 一.安装 1.在 ubuntu 上安装 brew /bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 2.在 centos 上安装 brew /bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 3.在 MacOS 上安装 brew /bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 二、使用 1.安装 wget brew install wget Homebrew 会将软件包安装到独立目录，并将其文件软链接至 /usr/local\n$ cd /usr/local $ find Cellar Cellar/wget/1.16.1 Cellar/wget/1.16.1/bin/wget Cellar/wget/1.16.1/share/man/man1/wget.1 $ ls -l bin bin/wget -\u0026gt; ../Cellar/wget/1.16.1/bin/wget 2.创建你自己的 Homebrew 包 $ brew create https://foo.com/bar-1.0.tgz Created /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core/Formula/bar.rb 3.撤销你的变更或与上游更新合并 $ brew edit wget # 使用 $EDITOR 编辑!","title":"brew 安装配置"},{"content":"gitlab CI/CD 的使用 我将使用 gitlab 的流水线自动实现 hugo blog 文章的自动发布。\n一、基础知识 二、安装过程 1.安装 gitlab runner 首先需要安装 gitlab runner 进入服务器 A\n安装方法：\n容器部署\n手动二进制文件部署\n通过 rpm/deb 包部署\ndocker 方式安装\n安装文档：https://docs.gitlab.com/runne\u0026amp;hellip;\ndocker run -dit \\ --name gitlab-runner \\ --restart always \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner 1.1 设置信息\ndocker exec -it gitlab-runner gitlab-runner register 非 docker 方式安装 2.1 安装 GitLab Runner\n安装环境：Linux\n其他环境参考：https://docs.gitlab.com/runne\u0026amp;hellip;\n下载\ncurl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64 添加权限\nchmod +x /usr/local/bin/gitlab-runner 新建 gitlab-runner 用户\nsudo useradd --comment \u0026amp;#39;GitLab Runner\u0026amp;#39; --create-home gitlab-runner --shell /bin/bash 安装\n安装时需要指定我们上面新建的用户\ngitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner 启动\ngitlab-runner start # Download the binary for your system sudo curl -L --output","permalink":"https://test.jobcher.com/gitlab-ci/cd-%E7%9A%84%E4%BD%BF%E7%94%A8.html","summary":"gitlab CI/CD 的使用 我将使用 gitlab 的流水线自动实现 hugo blog 文章的自动发布。\n一、基础知识 二、安装过程 1.安装 gitlab runner 首先需要安装 gitlab runner 进入服务器 A\n安装方法：\n容器部署\n手动二进制文件部署\n通过 rpm/deb 包部署\ndocker 方式安装\n安装文档：https://docs.gitlab.com/runne\u0026hellip;\ndocker run -dit \\ --name gitlab-runner \\ --restart always \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner 1.1 设置信息\ndocker exec -it gitlab-runner gitlab-runner register 非 docker 方式安装 2.1 安装 GitLab Runner\n安装环境：Linux\n其他环境参考：https://docs.gitlab.com/runne\u0026hellip;\n下载\ncurl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64 添加权限\nchmod +x /usr/local/bin/gitlab-runner 新建 gitlab-runner 用户","title":"gitlab CI/CD 的使用"},{"content":"Markdown 教程 参考：https://www.runoob.com/markdown\n","permalink":"https://test.jobcher.com/markdown%E6%95%99%E7%A8%8B.html","summary":"Markdown 教程 参考：https://www.runoob.com/markdown","title":"Markdown教程"},{"content":"如果你觉得这个项目对你有帮助，并且情况允许的话，可以给我一点点支持，支持我维护下去 ","permalink":"https://test.jobcher.com/%E6%84%9F%E8%B0%A2%E6%89%93%E8%B5%8F.html","summary":"如果你觉得这个项目对你有帮助，并且情况允许的话，可以给我一点点支持，支持我维护下去 ","title":"感谢打赏"},{"content":"运维图谱 云原生平台基础 Docker、Docker Compose：容器化技术 Kubernetes：大规模容器编排 Helm：云原生应用商店 Rancher： 易用的容器管理平台 KubeSphere：一站式容器云平台 OpenTracing：云原生链路追踪标准 Jaeger：云原生链路追踪实现产品 Istio：ServiceMesh下的服务流量治理 Jenkins、JenkinsX、Jenkins-BlueOcean：老牌的CI/CD平台 Gtilab/hub-CICD：Gitlab/hub自带的CICD Argo：kubernetes声明式持续集成 Nexus：Maven私库 Harbor：Docker私库 Prometheus+Granfana：监控与可视化平台 ElasticSearch+Fluentd+Kibana：日志与可视化方案 Serverless：无服务器上云方案（不用去管服务器，不是不需要服务器） SpringCloud Kubernetes：微服务上云方案 熟练掌握docker和k8s技术 devops掌握jenkins和gitlab\n应用12要素 在现代，软件通常作为服务交付：称为Web 应用程序或软件即服务。十二因素应用程序是一种构建软件即服务应用程序的方法，它：\n使用声明格式进行设置自动化，以最大限度地减少新开发人员加入项目的时间和成本； 与底层操作系统有一个干净的合同，在执行环境之间提供最大的可移植性； 适合部署在现代云平台上，无需服务器和系统管理； 最大限度地减少开发和生产之间的差异，实现持续部署以获得最大的敏捷性； 并且可以在不对工具、架构或开发实践进行重大更改的情况下进行扩展。 名称 英文 描述 基准代码 codebase 一份基准代码，多份部署 依赖 Dependencies 显示声明依赖关系 配置 config 在环境中存储配置 后端服务 backing services 把后端服务当做附加资源 构建，发布，运行 build，release，run 严格分离构建和运行 进程 Processes 以一个或多个无状态进程运行应用 端口绑定 port binding 通过端口绑定来提供服务 并发 concurrency 通过进程模型进行扩展 易处理 disposability 快速启动和优雅终止可最大化健壮性 开发环境和线上环境等价 Dev/prod parity 尽可能保持","permalink":"https://test.jobcher.com/%E8%BF%90%E7%BB%B4%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1.html","summary":"运维图谱 云原生平台基础 Docker、Docker Compose：容器化技术 Kubernetes：大规模容器编排 Helm：云原生应用商店 Rancher： 易用的容器管理平台 KubeSphere：一站式容器云平台 OpenTracing：云原生链路追踪标准 Jaeger：云原生链路追踪实现产品 Istio：ServiceMesh下的服务流量治理 Jenkins、JenkinsX、Jenkins-BlueOcean：老牌的CI/CD平台 Gtilab/hub-CICD：Gitlab/hub自带的CICD Argo：kubernetes声明式持续集成 Nexus：Maven私库 Harbor：Docker私库 Prometheus+Granfana：监控与可视化平台 ElasticSearch+Fluentd+Kibana：日志与可视化方案 Serverless：无服务器上云方案（不用去管服务器，不是不需要服务器） SpringCloud Kubernetes：微服务上云方案 熟练掌握docker和k8s技术 devops掌握jenkins和gitlab\n应用12要素 在现代，软件通常作为服务交付：称为Web 应用程序或软件即服务。十二因素应用程序是一种构建软件即服务应用程序的方法，它：\n使用声明格式进行设置自动化，以最大限度地减少新开发人员加入项目的时间和成本； 与底层操作系统有一个干净的合同，在执行环境之间提供最大的可移植性； 适合部署在现代云平台上，无需服务器和系统管理； 最大限度地减少开发和生产之间的差异，实现持续部署以获得最大的敏捷性； 并且可以在不对工具、架构或开发实践进行重大更改的情况下进行扩展。 名称 英文 描述 基准代码 codebase 一份基准代码，多份部署 依赖 Dependencies 显示声明依赖关系 配置 config 在环境中存储配置 后端服务 backing services 把后端服务当做附加资源 构建，发布，运行 build，release，run 严格分离构建和运行 进程 Processes 以一个或多个无状态进程运行应用 端口绑定 port binding 通过端口绑定来提供服务 并发 concurrency 通过进程模型进行扩展 易处理 disposability 快速启动和优雅终止可最大化健壮性 开发环境和线上环境等价 Dev/prod parity 尽可能保持","title":"运维知识图谱"},{"content":"关于 后台就是花式curd工程师 前端就是抠图工程师 大数据就是sql工程师 算法就是调参工程师 中间件就是客服热线接线员 只有运维才能拯救世界！ 兴趣爱好： 游泳，干饭\n最近看的书： 《荒野求生》\n破窑赋 天有不测风云，人有旦夕祸福。蜈蚣百足，行不及蛇；雄鸡两翼，飞不过鸦。马有千里之程，无骑不能自往；人有冲天之志，非运不能自通。\n盖闻：人生在世，富贵不能淫，贫贱不能移。文章盖世，孔子厄于陈邦；武略超群，太公钓于渭水。颜渊命短，殊非凶恶之徒；盗跖年长，岂是善良之辈。尧帝明圣，却生不肖之儿；瞽叟愚顽，反生大孝之子。张良原是布衣，萧何称谓县吏。晏子身无五尺，封作齐国宰相；孔明卧居草庐，能作蜀汉军师。楚霸虽雄，败于乌江自刎；汉王虽弱，竟有万里江山。李广有射虎之威，到老无封；冯唐有乘龙之才，一生不遇。韩信未遇之时，无一日三餐，及至遇行，腰悬三尺玉印，一旦时衰，死于阴人之手。\n有先贫而后富，有老壮而少衰。满腹文章，白发竟然不中；才疏学浅，少年及第登科。深院宫娥，运退反为妓妾；风流妓女，时来配作夫人。\n青春美女，却招愚蠢之夫；俊秀郎君，反配粗丑之妇。蛟龙未遇，潜水于鱼鳖之间；君子失时，拱手于小人之下。衣服虽破，常存仪礼之容；面带忧愁，每抱怀安之量。时遭不遇，只宜安贫守份；心若不欺，必然扬眉吐气。初贫君子，天然骨骼生成；乍富小人，不脱贫寒肌体。\n天不得时，日月无光；地不得时，草木不生；水不得时，风浪不平；人不得时，利运不通。注福注禄，命里已安排定，富贵谁不欲？人若不依根基八字，岂能为卿为相？\n吾昔寓居洛阳，朝求僧餐，暮宿破窖，思衣不可遮其体，思食不可济其饥，上人憎，下人厌，人道我贱，非我不弃也。今居朝堂，官至极品，位置三公，身虽鞠躬于一人之下，而列职于千万人之上，有挞百僚之杖，有斩鄙吝之剑，思衣而有罗锦千箱，思食而有珍馐百味，出则壮士执鞭，入则佳人捧觞，上人宠，下人拥。人道我贵，非我之能也，此乃时也、运也、命也。\n嗟呼！人生在世，富贵不可尽用，贫贱不可自欺，听由天地循环，周而复始焉。\n","permalink":"https://test.jobcher.com/%E5%85%B3%E4%BA%8E%E6%88%91.html","summary":"关于 后台就是花式curd工程师 前端就是抠图工程师 大数据就是sql工程师 算法就是调参工程师 中间件就是客服热线接线员 只有运维才能拯救世界！ 兴趣爱好： 游泳，干饭\n最近看的书： 《荒野求生》\n破窑赋 天有不测风云，人有旦夕祸福。蜈蚣百足，行不及蛇；雄鸡两翼，飞不过鸦。马有千里之程，无骑不能自往；人有冲天之志，非运不能自通。\n盖闻：人生在世，富贵不能淫，贫贱不能移。文章盖世，孔子厄于陈邦；武略超群，太公钓于渭水。颜渊命短，殊非凶恶之徒；盗跖年长，岂是善良之辈。尧帝明圣，却生不肖之儿；瞽叟愚顽，反生大孝之子。张良原是布衣，萧何称谓县吏。晏子身无五尺，封作齐国宰相；孔明卧居草庐，能作蜀汉军师。楚霸虽雄，败于乌江自刎；汉王虽弱，竟有万里江山。李广有射虎之威，到老无封；冯唐有乘龙之才，一生不遇。韩信未遇之时，无一日三餐，及至遇行，腰悬三尺玉印，一旦时衰，死于阴人之手。\n有先贫而后富，有老壮而少衰。满腹文章，白发竟然不中；才疏学浅，少年及第登科。深院宫娥，运退反为妓妾；风流妓女，时来配作夫人。\n青春美女，却招愚蠢之夫；俊秀郎君，反配粗丑之妇。蛟龙未遇，潜水于鱼鳖之间；君子失时，拱手于小人之下。衣服虽破，常存仪礼之容；面带忧愁，每抱怀安之量。时遭不遇，只宜安贫守份；心若不欺，必然扬眉吐气。初贫君子，天然骨骼生成；乍富小人，不脱贫寒肌体。\n天不得时，日月无光；地不得时，草木不生；水不得时，风浪不平；人不得时，利运不通。注福注禄，命里已安排定，富贵谁不欲？人若不依根基八字，岂能为卿为相？\n吾昔寓居洛阳，朝求僧餐，暮宿破窖，思衣不可遮其体，思食不可济其饥，上人憎，下人厌，人道我贱，非我不弃也。今居朝堂，官至极品，位置三公，身虽鞠躬于一人之下，而列职于千万人之上，有挞百僚之杖，有斩鄙吝之剑，思衣而有罗锦千箱，思食而有珍馐百味，出则壮士执鞭，入则佳人捧觞，上人宠，下人拥。人道我贵，非我之能也，此乃时也、运也、命也。\n嗟呼！人生在世，富贵不可尽用，贫贱不可自欺，听由天地循环，周而复始焉。","title":"关于我"}]